{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "id": "ZOxrykeplsGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6AtM5mQJ0ce_"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "gensim.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cROYB2tvzHqx"
      },
      "outputs": [],
      "source": [
        "!pip install konlpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5yxwl5h1Urx"
      },
      "source": [
        "## 1. 영어 Word2Vec 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pp_FwXmF1Idl"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import urllib.request\n",
        "import zipfile\n",
        "from lxml import etree\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yju2w88q4zbY"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWGvf8D41aLU"
      },
      "outputs": [],
      "source": [
        "# 훈련데이터 다운로드 (ted talk script)\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/ukairia777/tensorflow-nlp-tutorial/main/09.%20Word%20Embedding/dataset/ted_en-20160408.xml\", filename=\"ted_en-20160408.xml\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targetXML = open('ted_en-20160408.xml', 'r', encoding='UTF8')\n",
        "target_text = etree.parse(targetXML)\n",
        "\n",
        "# xml 파일에서 추출한 text로부터 <content>와 </content> 사이의 내용만 가져온다.\n",
        "parse_text = '\\n'.join(target_text.xpath('//content/text()'))\n",
        "\n",
        "# 정규 표현식의 sub 모듈을 통해 content 중간에 등장하는 (Audio), (Laughter) 등의 배경음 부분을 제거.\n",
        "# 해당 코드는 괄호로 구성된 내용을 제거.\n",
        "content_text = re.sub(r'\\([^)]*\\)', '', parse_text)\n",
        "\n",
        "# 입력 코퍼스에 대해서 NLTK를 이용하여 '문장' 토큰화를 수행.\n",
        "sent_text = sent_tokenize(content_text)\n",
        "\n",
        "# 각 문장에 대해서 구두점을 제거하고, 대문자를 소문자로 변환.\n",
        "normalized_text = []\n",
        "for string in sent_text:\n",
        "     tokens = re.sub(r\"[^a-z0-9]+\", \" \", string.lower())\n",
        "     normalized_text.append(tokens)\n",
        "\n",
        "# 각 문장에 대해서 NLTK를 이용하여 '단어' 토큰화를 수행.\n",
        "result = [word_tokenize(sentence) for sentence in normalized_text]"
      ],
      "metadata": {
        "id": "eOqJ4oDL1TIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFDBew9S6Kgn"
      },
      "outputs": [],
      "source": [
        "print('총 샘플(문장)의 개수 : {}'.format(len(result)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGmRA6426KbQ"
      },
      "outputs": [],
      "source": [
        "# 샘플(문장) 3개만 출력해서 토큰화된 단어 확인\n",
        "for line in result[:3]:\n",
        "    print(line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oo0x7mYt6NIn"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOvzA5Gw6R4X"
      },
      "source": [
        "- `vector_size` = 임베딩 된 벡터의 차원.\n",
        "- `window` = 컨텍스트 윈도우 크기\n",
        "- `min_count` = 단어 최소 빈도 수 제한 (빈도가 적은 단어들은 학습하지 않는다.)\n",
        "- `workers` = 학습을 위한 프로세스 수\n",
        "- `sg` = 0은 CBOW, 1은 Skip-gram."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwcAC5ze6Wpx"
      },
      "source": [
        "CBOW는 target word 근처의 문맥을 파악하여 target word를 예측하는 방법이고, Skip-gram은 target word를 보고 문맥을 예측하는 방법입니다. `window`란 인자는 근처 문맥의 단어를 몇개로 할지 그 크기를 설정하는 인자입니다.\n",
        "\n",
        "![neural language model vs word2vec](https://user-images.githubusercontent.com/115082062/213910013-2c91f210-090d-47f7-b842-33f64a3b2c50.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZfLnwMn6OLA"
      },
      "outputs": [],
      "source": [
        "model = Word2Vec(sentences=result, vector_size=100, window=5, min_count=5, workers=4, sg=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JU3JNGkv6Rhg"
      },
      "source": [
        "`model.wv.most_similar()`를 통해 입력한 단어와 가장 유사한 단어를 출력할 수 있습니다. 코사인 유사도를 기반으로 출력해줍니다.\n",
        "원하는 단어를 input으로 넣어보세요!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3VZ4UYyMXKG"
      },
      "outputs": [],
      "source": [
        "model_result = model.wv.most_similar(\"ball\")\n",
        "print(model_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-XheG_HPWUm"
      },
      "source": [
        "유사도를 기반으로 산정된 벡터들이기 때문에 연산도 가능합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7O0HwRG-PWCG"
      },
      "outputs": [],
      "source": [
        "model.wv.most_similar(positive=['woman'], negative=['man'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LU19S5e8PJa-"
      },
      "outputs": [],
      "source": [
        "model.wv.save_word2vec_format('eng_w2v') # 모델 저장\n",
        "loaded_model = KeyedVectors.load_word2vec_format(\"eng_w2v\") # 모델 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dueavbctPPLH"
      },
      "outputs": [],
      "source": [
        "model_result = loaded_model.most_similar(\"ball\")\n",
        "print(model_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i67MhAgCRnl-"
      },
      "source": [
        "## 2. 한국어 Word2Vec 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBiF2_HzWfTj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "from konlpy.tag import Okt\n",
        "import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zK1qgWSLY7gK"
      },
      "outputs": [],
      "source": [
        "# 네이버 영화 리뷰 데이터 다운로드\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt\", filename=\"ratings.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hhWkKFcY-ff"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_table('ratings.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDraB-LJZJYu"
      },
      "outputs": [],
      "source": [
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q096bVzsZR3f"
      },
      "outputs": [],
      "source": [
        "print(len(train_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2N7Gpdx7ZWYF"
      },
      "outputs": [],
      "source": [
        "train_data.info() # 결측값이 존재하는 행 8개 있음"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmcO4DBYZev5"
      },
      "outputs": [],
      "source": [
        "train_data = train_data.dropna(how = 'any') # 결측 값 존재하는 행 제거"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wl_pQNfjZo1-"
      },
      "outputs": [],
      "source": [
        "print(len(train_data)) # 8개 행이 사라짐"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cyIYXRXRb6x0"
      },
      "outputs": [],
      "source": [
        "# 정규 표현식을 통한 한글 외 문자 제거\n",
        "train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8QixZimnb-Jz"
      },
      "outputs": [],
      "source": [
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRINbtQrbdQg"
      },
      "outputs": [],
      "source": [
        "from google import colab\n",
        "colab.drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDnOTdSCbsqj"
      },
      "outputs": [],
      "source": [
        "# 불용어 리스트 정의\n",
        "with open('/content/stopword.txt',  encoding='utf-8') as f:\n",
        "    list_file = f.readlines()\n",
        "    stopwords = list_file[0].split(\",\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "okt를 사용할 경우 20분 내외의 런타임이 소요됩니다."
      ],
      "metadata": {
        "id": "uZoD4oW_AJAG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "soa_jscCcDHi"
      },
      "outputs": [],
      "source": [
        "# using okt\n",
        "okt = Okt()\n",
        "\n",
        "tokenized_data = []\n",
        "for sentence in tqdm.tqdm(train_data['document']):\n",
        "    tokenized_sentence = okt.morphs(sentence, stem=True) # 토큰화\n",
        "    stopwords_removed_sentence = [word for word in tokenized_sentence if not word in stopwords] # 불용어 제거\n",
        "    tokenized_data.append(stopwords_removed_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KEoge0x7chaT"
      },
      "outputs": [],
      "source": [
        "# 리뷰 3개의 토큰화 결과만 출력\n",
        "print(tokenized_data[:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fA4MbVmyimE3"
      },
      "outputs": [],
      "source": [
        "# 리뷰 길이 분포 확인\n",
        "print('리뷰의 최대 길이 :',max(len(review) for review in tokenized_data))\n",
        "print('리뷰의 평균 길이 :',sum(map(len, tokenized_data))/len(tokenized_data))\n",
        "plt.hist([len(review) for review in tokenized_data], bins=50)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('freauency')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxVfA8R-iwFA"
      },
      "outputs": [],
      "source": [
        "model = Word2Vec(sentences = tokenized_data, vector_size = 100, window = 5, min_count = 5, workers = 4, sg = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-BiDqDSi1Ol"
      },
      "outputs": [],
      "source": [
        "model.wv.vectors.shape # 총 17806개의 단어가 100차원으로 구성되어있음."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PdfrOnPoi9aG"
      },
      "outputs": [],
      "source": [
        "print(model.wv.most_similar(\"이동진\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WqkPftHjGpM"
      },
      "outputs": [],
      "source": [
        "model.wv.most_similar(positive=['타짜'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsVGC-7gkksQ"
      },
      "outputs": [],
      "source": [
        "model.wv.most_similar(positive=['송강호'], negative=['주연'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzA-u_MZ4MmL"
      },
      "outputs": [],
      "source": [
        "model.wv.similarity('송강호', '하정우')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rp5RJR3K4WU0"
      },
      "outputs": [],
      "source": [
        "model.wv.similarity('송강호', '축구')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
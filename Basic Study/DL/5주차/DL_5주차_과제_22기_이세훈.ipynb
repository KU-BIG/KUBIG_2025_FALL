{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7b3c2e03",
      "metadata": {
        "id": "7b3c2e03"
      },
      "source": [
        "## 2025_Fall_DL_week5_Homework\n",
        "8/7 CNN 실습 예제코드입니다!\n",
        "\n",
        "이번 5주차 숙제는 총 2가지로 구성되어 있습니다.\n",
        "- 논문 리뷰 - ResNet : https://arxiv.org/abs/1512.03385\n",
        "\n",
        "\n",
        "    다음 논문을 읽고 4분이서 의견 공유 및 리뷰 발표를 준비해주시면 됩니다! (발표자, 자료, 시간 등 제약은 없으나, 1~2명이서 약 5분~10분정도로 notion이나 word를 이용하여 작성 후 pdf로 변환해서 깃허브에 제출해 주시는걸 추천합니다!)\n",
        "\n",
        "- 코드 구현 - CNN\n",
        "\n",
        "    아래 실습코드를 그대로 참고하셔도 좋고, 새롭게 짜셔도 좋습니다. 데이터셋은 CIFAR10이 아닌 벤치마크(MNIST, FFHQ, ImageNet)이나 다른 데이터셋을 사용하되, 학습 시간 및 리소스를 적절히 사용할 수 있는 화질을 사용하는 것을 추천 드립니다. 또한, 앞서 배운 regularization, initialization, optimizer 등등 기법을 추가해보시거나, layer를 변형하는 시도를 추가하여 결과를 분석해주세요. (스터디를 통해 각자한 시도가 겹치지 않으면 좋은 경험이 될 것 같습니다!)\n",
        "\n",
        "    example : Earlystopping 추가, Dropoutlayer 추가, batch nomalization 추가, stride 및 padding 변형, Conv layer 추가 및 삭제 등등"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "e30cac53",
      "metadata": {
        "id": "e30cac53"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim.adam import Adam\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "# SVHN 데이터 사용 (Street View House Numbers, 32×32 컬러, 숫자 10클래스 0–9)\n",
        "\n",
        "svhn_train = datasets.SVHN(root=\"./data\", split=\"train\", download=True)\n",
        "svhn_test  = datasets.SVHN(root=\"./data\", split=\"test\",  download=True)\n",
        "\n",
        "print(f\"Train set: {len(svhn_train)} samples\")\n",
        "print(f\"Test set: {len(svhn_test)} samples\")\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dsAW8p0Paqf",
        "outputId": "00068a58-3372-47b3-d1a7-6ac512afdaba"
      },
      "id": "-dsAW8p0Paqf",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set: 73257 samples\n",
            "Test set: 26032 samples\n",
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "c208f365",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c208f365",
        "outputId": "cdc66cf3-e59f-4cfd-8bb1-92f58d295b08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set: 73257 samples\n",
            "Test set: 26032 samples\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 128\n",
        "EPOCHS = 20\n",
        "LR = 1e-3\n",
        "\n",
        "SVHN_MEAN = (0.4377, 0.4438, 0.4728)\n",
        "SVHN_STD  = (0.1980, 0.2010, 0.1970)\n",
        "\n",
        "# 데이터셋 로드 및 변환 적용\n",
        "train_tf = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(SVHN_MEAN, SVHN_STD),\n",
        "])\n",
        "\n",
        "test_tf = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(SVHN_MEAN, SVHN_STD),\n",
        "])\n",
        "\n",
        "# Use datasets.SVHN directly and pass the transforms\n",
        "train_set = datasets.SVHN(root=\"./data\", split=\"train\", download=True, transform=train_tf)\n",
        "test_set  = datasets.SVHN(root=\"./data\", split=\"test\",  download=True, transform=test_tf)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
        "test_loader  = DataLoader(test_set,  batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "\n",
        "print(f\"Train set: {len(train_set)} samples\")\n",
        "print(f\"Test set: {len(test_set)} samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d26e28a5",
      "metadata": {
        "id": "d26e28a5"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "f05295d5",
      "metadata": {
        "id": "f05295d5"
      },
      "outputs": [],
      "source": [
        "class SmallCNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "        # CNN을 구성할 때 가장 먼저 입력 데이터 크기를 생각함 → SVHN은 (3, 32, 32) 컬러 이미지\n",
        "        # Conv → BN → ReLU를 반복하고, 중간에 MaxPool로 공간 크기를 절반씩 줄이는 구조\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            # 첫 번째 블록: 채널 3 → 32\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),  # 입력 크기 유지 (32x32)\n",
        "            nn.BatchNorm2d(32),                          # 학습 안정화 및 수렴 속도 향상\n",
        "            nn.ReLU(inplace=True),                       # 비선형성 추가\n",
        "\n",
        "            # 같은 크기에서 채널 확장 없이 한 번 더 Conv\n",
        "            nn.Conv2d(32, 32, kernel_size=3, padding=1), # 여전히 (32x32)\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),                             # 공간 크기 절반 → (16x16)\n",
        "\n",
        "            # 두 번째: 채널 32 → 64\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1), # (16x16)\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1), # (16x16)\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),                             # 공간 절반 → (8x8)\n",
        "\n",
        "            # 세 번째: 채널 64 → 128\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),# (8x8)\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),                             # 공간 절반 → (4x4)\n",
        "        )\n",
        "        # 여기까지 거치면 feature map 크기가 (128채널, 4, 4) → 총 2048개의 feature임!\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),                                # 2D feature map을 1D 벡터로\n",
        "            nn.Linear(128 * 4 * 4, 256),                 # 차원 축소\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.3),                           # 과적합 방지\n",
        "            nn.Linear(256, num_classes)                  # 최종 출력층 → 클래스 개수만큼\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 특징 추출 단계\n",
        "        x = self.features(x)\n",
        "        # 분류 단계\n",
        "        return self.classifier(x)\n",
        "\n",
        "# 모델 인스턴스 생성 → num_classes=10 (SVHN은 0~9 숫자니까)\n",
        "model = SmallCNN(num_classes=10).to(device)\n",
        "\n",
        "# 다중 클래스 분류 >> CrossEntropy\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 옵티마이저 Adam\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "# 학습률 스케줄러: 8에폭마다 학습률을 절반으로 → 후반부 세밀하게\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=8, gamma=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
        "    model.train()  # 학습 모드\n",
        "    total_loss, total_correct, total_samples = 0.0, 0, 0\n",
        "\n",
        "    for images, targets in loader:\n",
        "        images, targets = images.to(device), targets.to(device)  # GPU/CPU로 이동\n",
        "\n",
        "        optimizer.zero_grad()            # 기울기 초기화\n",
        "        outputs = model(images)          # 순전파\n",
        "        loss = criterion(outputs, targets)  # 손실 계산\n",
        "        loss.backward()                  # 역전파\n",
        "        optimizer.step()                  # 파라미터 업데이트\n",
        "\n",
        "        batch_size = targets.size(0)\n",
        "        total_loss += loss.item() * batch_size  # 배치별 손실 합산\n",
        "        total_correct += outputs.argmax(1).eq(targets).sum().item()  # 맞춘 개수\n",
        "        total_samples += batch_size\n",
        "\n",
        "    epoch_loss = total_loss / total_samples  # 평균 손실\n",
        "    epoch_acc  = total_correct / total_samples  # 정확도\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, criterion, device):\n",
        "    model.eval()  # 평가 모드\n",
        "    total_loss, total_correct, total_samples = 0.0, 0, 0\n",
        "\n",
        "    for images, targets in loader:\n",
        "        images, targets = images.to(device), targets.to(device)  # GPU/CPU로 이동\n",
        "        outputs = model(images)           # 순전파\n",
        "        loss = criterion(outputs, targets)  # 손실 계산\n",
        "\n",
        "        batch_size = targets.size(0)\n",
        "        total_loss += loss.item() * batch_size  # 손실 합산\n",
        "        total_correct += outputs.argmax(1).eq(targets).sum().item()  # 맞춘 개수\n",
        "        total_samples += batch_size\n",
        "\n",
        "    epoch_loss = total_loss / total_samples  # 평균 손실\n",
        "    epoch_acc  = total_correct / total_samples  # 정확도\n",
        "    return epoch_loss, epoch_acc"
      ],
      "metadata": {
        "id": "Z4RllXbj6xI-"
      },
      "id": "Z4RllXbj6xI-",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_acc = 0.0\n",
        "best_path = \"svhn_smallcnn_best.pt\"\n",
        "\n",
        "#베스트 모델 저장 후 해당 모델로 학습하는 코드 feat. gpt\n",
        "\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
        "    test_loss,  test_acc  = evaluate(model, test_loader, criterion, device)\n",
        "    scheduler.step()\n",
        "\n",
        "    print(f\"[{epoch:02d}/{EPOCHS}] \"\n",
        "          f\"train loss {train_loss:.4f} | acc {train_acc*100:.2f}% || \"\n",
        "          f\"test loss {test_loss:.4f} | acc {test_acc*100:.2f}%\")\n",
        "\n",
        "    if test_acc > best_acc:\n",
        "        best_acc = test_acc\n",
        "        torch.save(model.state_dict(), best_path)\n",
        "\n",
        "print(f\"Best test acc: {best_acc*100:.2f}% (saved to {best_path})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ermgoKK65yL",
        "outputId": "95967a92-4dce-4ee2-a30b-2495ebe86033"
      },
      "id": "-ermgoKK65yL",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[01/20] train loss 1.5757 | acc 43.72% || test loss 0.8519 | acc 70.95%\n",
            "[02/20] train loss 0.9261 | acc 67.97% || test loss 0.5944 | acc 80.57%\n",
            "[03/20] train loss 0.7695 | acc 74.32% || test loss 0.5349 | acc 83.19%\n",
            "[04/20] train loss 0.6914 | acc 76.97% || test loss 0.4295 | acc 86.72%\n",
            "[05/20] train loss 0.6396 | acc 78.74% || test loss 0.4120 | acc 87.88%\n",
            "[06/20] train loss 0.5987 | acc 80.20% || test loss 0.4151 | acc 87.77%\n",
            "[07/20] train loss 0.5689 | acc 81.34% || test loss 0.3807 | acc 88.71%\n",
            "[08/20] train loss 0.5477 | acc 82.05% || test loss 0.3428 | acc 89.66%\n",
            "[09/20] train loss 0.4886 | acc 84.47% || test loss 0.2932 | acc 91.65%\n",
            "[10/20] train loss 0.4704 | acc 85.03% || test loss 0.3019 | acc 91.37%\n",
            "[11/20] train loss 0.4539 | acc 85.61% || test loss 0.2953 | acc 91.32%\n",
            "[12/20] train loss 0.4445 | acc 85.86% || test loss 0.2982 | acc 91.45%\n",
            "[13/20] train loss 0.4256 | acc 86.84% || test loss 0.2911 | acc 91.64%\n",
            "[14/20] train loss 0.4201 | acc 87.24% || test loss 0.2866 | acc 91.78%\n",
            "[15/20] train loss 0.4048 | acc 87.55% || test loss 0.2824 | acc 91.94%\n",
            "[16/20] train loss 0.4071 | acc 87.46% || test loss 0.2798 | acc 91.97%\n",
            "[17/20] train loss 0.3863 | acc 88.27% || test loss 0.2575 | acc 92.85%\n",
            "[18/20] train loss 0.3798 | acc 88.44% || test loss 0.2517 | acc 93.06%\n",
            "[19/20] train loss 0.3667 | acc 88.89% || test loss 0.2549 | acc 92.91%\n",
            "[20/20] train loss 0.3634 | acc 88.97% || test loss 0.2517 | acc 93.07%\n",
            "Best test acc: 93.07% (saved to svhn_smallcnn_best.pt)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
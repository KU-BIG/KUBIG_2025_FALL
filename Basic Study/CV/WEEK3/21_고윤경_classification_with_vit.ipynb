{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "un0kSCKKPz_r"
      },
      "source": [
        "# ViT assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hYQBhItP4Em"
      },
      "source": [
        "colab의 경우, 런타임 유형을 GPU로 바꿔주세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCaKr-jb-RuF"
      },
      "source": [
        "# 0. Setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VGdid66o92_a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from einops import repeat\n",
        "from einops.layers.torch import Rearrange\n",
        "from torch import Tensor\n",
        "import math\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0FY_DkY-BOc"
      },
      "source": [
        "# 1. Project input to patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVBEFoV7-a1u",
        "outputId": "c0c45c47-38f7-4b24-adbc-d1e7bb69577a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([8, 3, 224, 224])\n",
            "Patch embeddings shape: torch.Size([8, 196, 768])\n",
            "Number of patches: 196\n"
          ]
        }
      ],
      "source": [
        "class PatchProjection(nn.Module):\n",
        "    def __init__(self, in_channels=3, patch_size=16, emb_size=768, img_size=224):\n",
        "        super().__init__()\n",
        "        self.patch_size = patch_size\n",
        "        # N = HW/P^2 (H,W는 이미지 해상도, P는 패치 크기)\n",
        "        # 224x224 이미지를 16x16 패치로 나누면 (224/16)^2 = 14^2 = 196개의 패치가 생성됨\n",
        "        self.num_patches = (img_size // patch_size) ** 2  # 이미지 크기와 패치 크기에 따른 총 패치 수 계산\n",
        "\n",
        "        self.projection = nn.Sequential(\n",
        "            # trainable linear projection을 Conv2d로 구현\n",
        "            # 입력: (batch, 3, 224, 224) -> 출력: (batch, 768, 14, 14)\n",
        "            nn.Conv2d(\n",
        "                in_channels=in_channels,     # RGB 채널 수 (3)\n",
        "                out_channels=emb_size,       # 임베딩 차원 (768)\n",
        "                kernel_size=patch_size,      # 16x16 패치 크기\n",
        "                stride=patch_size,           # 16픽셀씩 이동하여 겹치지 않게 함\n",
        "                bias=True                    # 선형 변환에 bias 포함\n",
        "            ),\n",
        "            # einops 사용해 공간 차원을 시퀀스 차원으로 재배치: (batch, emb_size, height, width) -> (batch, height*width, emb_size)\n",
        "            # (batch, 768, 14, 14) -> (batch, 196, 768)\n",
        "            Rearrange('b e h w -> b (h w) e')\n",
        "        )\n",
        "\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        # 입력 이미지를 patch embedding으로 변환\n",
        "        # 입력 이미지 텐서 (batch_size, channels, height, width) -> 패치 임베딩 텐서 (batch_size, num_patches, embedding_dim)\n",
        "        patch_embeddings = self.projection(x)\n",
        "        return patch_embeddings\n",
        "\n",
        "\n",
        "# Test\n",
        "if __name__ == \"__main__\":\n",
        "    x = torch.randn(8, 3, 224, 224)\n",
        "    patch_proj = PatchProjection()\n",
        "    out = patch_proj(x)\n",
        "    print(f'Input shape: {x.shape}')\n",
        "    print(f'Patch embeddings shape: {out.shape}')\n",
        "    print(f'Number of patches: {patch_proj.num_patches}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XXVMCsl-rP9"
      },
      "source": [
        "# 2. Patches embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5-Ulu9Z-n_W",
        "outputId": "50c3151b-d381-4714-a9eb-e7747359b1e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([8, 3, 224, 224])\n",
            "Output shape: torch.Size([8, 197, 768])\n",
            "Expected: (8, 197, 768)\n"
          ]
        }
      ],
      "source": [
        "class PatchEmbedding(nn.Module):\n",
        "    def __init__(self, in_channels=3, patch_size=16, emb_size=768, img_size=224):\n",
        "        super().__init__()\n",
        "        self.num_patches = (img_size // patch_size) ** 2\n",
        "\n",
        "        # Patch projection\n",
        "        self.projection = nn.Sequential(\n",
        "            # trainable linear projection을 Conv2d로 구현\n",
        "            # 입력: (batch, 3, 224, 224) -> 출력: (batch, 768, 14, 14)\n",
        "            nn.Conv2d(\n",
        "                in_channels=in_channels,     # RGB 채널 수 (3)\n",
        "                out_channels=emb_size,       # 임베딩 차원 (768)\n",
        "                kernel_size=patch_size,      # 16x16 패치 크기\n",
        "                stride=patch_size,           # 16픽셀씩 이동하여 겹치지 않게 함\n",
        "                bias=True                    # 선형 변환에 bias 포함\n",
        "            ),\n",
        "            # einops 사용해 공간 차원을 시퀀스 차원으로 재배치: (batch, emb_size, height, width) -> (batch, height*width, emb_size)\n",
        "            # (batch, 768, 14, 14) -> (batch, 196, 768)\n",
        "            Rearrange('b e h w -> b (h w) e')\n",
        "        )\n",
        "\n",
        "        # CLS token and positional encoding\n",
        "        # CLS token은 전체 이미지의 표현을 학습하는 특별한 토큰: (1, 1, emb_size) 크기로 생성하여 나중에 배치 크기에 맞게 확장\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, emb_size))\n",
        "\n",
        "        # 패치 196개 + CLS token 1개 = 총 197개 위치에 대한 positional embedding\n",
        "        # 학습 가능한 1D positional embedding 사용\n",
        "        self.positions = nn.Parameter(torch.randn(self.num_patches + 1, emb_size))\n",
        "\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        nn.init.trunc_normal_(self.cls_token, std=0.02)\n",
        "        nn.init.trunc_normal_(self.positions, std=0.02)\n",
        "\n",
        "\n",
        "    # 입력 이미지를 CLS token과 positional encoding이 포함된 임베딩으로 변환\n",
        "    # 입력 이미지 텐서 (batch_size, channels, height, width) -> 완전한 패치 임베딩 텐서 (batch_size, num_patches+1, embedding_dim)\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        B = x.shape[0]\n",
        "\n",
        "        # Project to patches\n",
        "        # 입력 이미지를 패치 임베딩으로 변환: (B, 3, 224, 224) -> (B, 196, 768)\n",
        "        x = self.projection(x)\n",
        "\n",
        "        # Add CLS token\n",
        "        # CLS token을 배치 크기에 맞게 확장: (1, 1, 768) -> (B, 1, 768)\n",
        "        # 그리고 패치 임베딩 앞에 연결: (B, 196, 768) -> (B, 197, 768)\n",
        "        cls_tokens = self.cls_token.expand(B, -1, -1)  # (B, 1, 768)\n",
        "        x = torch.cat([cls_tokens, x], dim=1)  # (B, 197, 768)\n",
        "\n",
        "\n",
        "        # Add positional encoding\n",
        "        # 위치 정보를 임베딩에 더해 각 패치와 CLS token의 위치를 학습 - 브로드캐스팅으로 모든 배치에 동일한 positional encoding 적용\n",
        "        x = x + self.positions\n",
        "\n",
        "        return x\n",
        "\n",
        "# Test\n",
        "if __name__ == \"__main__\":\n",
        "    x = torch.randn(8, 3, 224, 224)\n",
        "    patch_emb = PatchEmbedding()\n",
        "    out = patch_emb(x)\n",
        "    print(f'Input shape: {x.shape}')\n",
        "    print(f'Output shape: {out.shape}')\n",
        "    print(f'Expected: (8, 197, 768)') # 196 patches + 1 CLS token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhR6ukKj-zBJ"
      },
      "source": [
        "# 3. Multi Head Attention (MHA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBJTJmUN-yZW",
        "outputId": "d05bdfbb-8917-47c1-abe3-5cc42c014e19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([8, 197, 768])\n",
            "Output shape: torch.Size([8, 197, 768])\n",
            "Parameters: 2,360,064\n"
          ]
        }
      ],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, emb_size=768, num_heads=12, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.emb_size = emb_size\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = emb_size // num_heads\n",
        "        self.scale = self.head_dim ** -0.5\n",
        "\n",
        "        assert emb_size % num_heads == 0\n",
        "\n",
        "        # Q, K, V projections\n",
        "        # Q, K, V를 한 번에 계산하는 단일 선형 레이어 - 출력 차원: emb_size * 3 (Q, K, V 각각 emb_size 차원)\n",
        "        self.qkv = nn.Linear(emb_size, emb_size * 3, bias=False)\n",
        "        # 각 헤드의 출력을 연결한 후 최종 투영: MultiHead(Q,K,V) = Concat(head1, ..., headh) * WO\n",
        "        self.proj = nn.Linear(emb_size, emb_size, bias=True)\n",
        "        # 정규화를 위한 드롭아웃\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        nn.init.xavier_uniform_(self.qkv.weight)\n",
        "        nn.init.xavier_uniform_(self.proj.weight)\n",
        "        nn.init.constant_(self.proj.bias, 0)\n",
        "\n",
        "    # Multi-Head Self-Attention 계산\n",
        "    # 입력 텐서 (batch_size, sequence_length, embedding_dim) -> 어텐션 적용된 출력 텐서 (batch_size, sequence_length, embedding_dim)\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        B, N, C = x.shape    # B: 배치크기, N: 시퀀스길이(토큰수), C: 임베딩차원\n",
        "\n",
        "        # Generate Q, K, V\n",
        "        qkv = self.qkv(x)    # (B, N, C) -> (B, N, 3*C)\n",
        "\n",
        "        # multi-head 형태로 reshape: (B, N, 3*C) -> (B, N, 3, num_heads, head_dim) -> (3, B, num_heads, N, head_dim)\n",
        "        qkv = qkv.reshape(B, N, 3, self.num_heads, self.head_dim).permute(2, 0, 3, 1, 4)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2]  # 각각 (B, num_heads, N, head_dim)\n",
        "\n",
        "        # Attention computation: : Attention(Q,K,V) = softmax(QK^T/√dk)V\n",
        "        # Q와 K의 내적 계산: (B, num_heads, N, head_dim) @ (B, num_heads, head_dim, N) -> (B, num_heads, N, N) - 각 토큰 쌍 간의 유사도\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
        "        # Softmax로 어텐션 가중치 정규화 - 각 쿼리에 대해 모든 키의 가중치 합이 1\n",
        "        attn = attn.softmax(dim=-1)\n",
        "        # 학습 안정성을 위한 dropout 적용\n",
        "        attn = self.dropout(attn)\n",
        "\n",
        "        # Apply attention to values\n",
        "        # (B, num_heads, N, N) @ (B, num_heads, N, head_dim) -> (B, num_heads, N, head_dim)\n",
        "        x = attn @ v\n",
        "        # multi-head 결과들을 연결: (B, num_heads, N, head_dim) -> (B, N, num_heads * head_dim)\n",
        "        # = (B, N, C) - 원본 임베딩 차원으로 복원\n",
        "        x = x.transpose(1, 2).reshape(B, N, C)\n",
        "\n",
        "        # 최종 linear projection 및 dropout 적용\n",
        "        x = self.proj(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# Test\n",
        "if __name__ == \"__main__\":\n",
        "    x = torch.randn(8, 197, 768)  # (batch, patches+cls, emb_size)\n",
        "    mha = MultiHeadAttention()\n",
        "    out = mha(x)\n",
        "    print(f'Input shape: {x.shape}')\n",
        "    print(f'Output shape: {out.shape}')\n",
        "    print(f'Parameters: {sum(p.numel() for p in mha.parameters()):,}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91glGnw--8wB"
      },
      "source": [
        "# 4. Transformer Encoder Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-OZsyS_-60F",
        "outputId": "560bf786-3702-491e-e87e-267109031350"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([8, 197, 768])\n",
            "Output shape: torch.Size([8, 197, 768])\n",
            "Parameters: 7,085,568\n"
          ]
        }
      ],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, emb_size=768, mlp_ratio=4, dropout=0.1):\n",
        "        super().__init__()\n",
        "        hidden_size = int(emb_size * mlp_ratio)\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            # emb_size 768 -> hidden_size 3072 (mlp_ratio=4일 때)\n",
        "            nn.Linear(emb_size, hidden_size),\n",
        "            # GELU 활성화 함수 (ReLU보다 부드러운 곡선을 가져 gradient flow 개선)\n",
        "            nn.GELU(),\n",
        "            # 정규화 위한 dropout\n",
        "            nn.Dropout(dropout),\n",
        "            # hidden_size 3072 -> emb_size 768 (원본 차원으로 복원)\n",
        "            nn.Linear(hidden_size, emb_size),\n",
        "            # 최종 dropout\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, emb_size=768, num_heads=12, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.emb_size = emb_size\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = emb_size // num_heads\n",
        "        self.scale = self.head_dim ** -0.5\n",
        "\n",
        "        # [q, k, v] = z * Uqkv, where Uqkv ∈ R^(D×3Dh)\n",
        "        self.qkv = nn.Linear(emb_size, emb_size * 3, bias=False)\n",
        "        # 최종 출력 투영 레이어 MultiHead(Q,K,V) = Concat(head1, ..., headh) * WO\n",
        "        self.proj = nn.Linear(emb_size, emb_size, bias=True)\n",
        "        # 정규화 위한 dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        nn.init.xavier_uniform_(self.qkv.weight)\n",
        "        nn.init.xavier_uniform_(self.proj.weight)\n",
        "        nn.init.constant_(self.proj.bias, 0)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        B, N, C = x.shape\n",
        "\n",
        "        # QKV 생성 및 multi-head 형태로 분리\n",
        "        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, self.head_dim).permute(2, 0, 3, 1, 4)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "\n",
        "        # scaled dot-product attention 계산, softmax, dropout 적용\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
        "        attn = attn.softmax(dim=-1)\n",
        "        attn = self.dropout(attn)\n",
        "\n",
        "        # attention 가중치를 값에 적용하고 multi-head 결과 연결\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "\n",
        "        # 최종 linear proj 및 dropout\n",
        "        x = self.proj(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class TransformerEncoderBlock(nn.Module):\n",
        "    def __init__(self, emb_size=768, num_heads=12, mlp_ratio=4, dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        # Layernorm (LN) before every block, residual connections after every block\n",
        "        # 첫 번째 LayerNorm -> Multi-Head Self-Attention\n",
        "        self.norm1 = nn.LayerNorm(emb_size)\n",
        "        self.attention = MultiHeadAttention(emb_size, num_heads, dropout)\n",
        "\n",
        "        # 두 번째 LayerNorm -> Position-wise Feed-Forward Network (MLP)\n",
        "        self.norm2 = nn.LayerNorm(emb_size)\n",
        "        self.mlp = MLP(emb_size, mlp_ratio, dropout)\n",
        "\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        # Pre-norm + residual connection for attention\n",
        "        x = x + self.attention(self.norm1(x))\n",
        "\n",
        "        # Pre-norm + residual connection for MLP\n",
        "        x = x + self.mlp(self.norm2(x))\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# Test\n",
        "if __name__ == \"__main__\":\n",
        "    x = torch.randn(8, 197, 768)\n",
        "    block = TransformerEncoderBlock()\n",
        "    out = block(x)\n",
        "    print(f'Input shape: {x.shape}')\n",
        "    print(f'Output shape: {out.shape}')\n",
        "    print(f'Parameters: {sum(p.numel() for p in block.parameters()):,}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GQ4-g8m_Cae"
      },
      "source": [
        "# 5. Complete ViT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RWUlqVx_AY1",
        "outputId": "71dd0fd0-7efe-4ac6-bae3-0d637b40f0e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 3, 224, 224])\n",
            "Output shape: torch.Size([2, 1000])\n",
            "Total parameters: 86,540,008\n",
            "\n",
            "=== ViT Configurations ===\n",
            "ViT-Tiny: 5,710,504 parameters\n",
            "ViT-Small: 22,036,840 parameters\n",
            "ViT-Base: 86,540,008 parameters\n",
            "ViT-Large: 304,252,904 parameters\n"
          ]
        }
      ],
      "source": [
        "class VisionTransformer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        img_size=224,\n",
        "        patch_size=16,\n",
        "        in_channels=3,\n",
        "        num_classes=1000,\n",
        "        emb_size=768,\n",
        "        depth=12,\n",
        "        num_heads=12,\n",
        "        mlp_ratio=4,\n",
        "        dropout=0.1,\n",
        "        drop_path=0.0\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # Patch embedding (from Stage 2)\n",
        "        self.patch_embed = PatchEmbedding(in_channels, patch_size, emb_size, img_size)\n",
        "\n",
        "        # Transformer encoder blocks (from Stage 4)\n",
        "        self.blocks = nn.ModuleList([\n",
        "            TransformerEncoderBlock(emb_size, num_heads, mlp_ratio, dropout)\n",
        "            for _ in range(depth)\n",
        "        ])\n",
        "\n",
        "        # Classification head\n",
        "        self.norm = nn.LayerNorm(emb_size)\n",
        "        self.head = nn.Linear(emb_size, num_classes)\n",
        "\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        nn.init.trunc_normal_(self.head.weight, std=0.02)\n",
        "        nn.init.constant_(self.head.bias, 0)\n",
        "\n",
        "    # 입력 이미지 (batch_size, channels, height, width) -> 클래스 예측 logits (batch_size, num_classes)\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "\n",
        "        # patch embedding 적용: 이미지 -> 패치 시퀀스 변환\n",
        "        x = self.patch_embed(x)\n",
        "\n",
        "        # Transformer encoder blocks 순차 적용: 각 블록에서 Multi-Head Self-Attention과 MLP 수행하면서 모든 패치와 CLS 토큰 간 관계 학습\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "\n",
        "        # Classification head (use CLS token)\n",
        "        x = self.norm(x)\n",
        "        cls_token = x[:, 0]  # Extract CLS token: (batch_size, emb_size)\n",
        "        x = self.head(cls_token)  # (batch_size, num_classes)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# Test\n",
        "if __name__ == \"__main__\":\n",
        "    # ViT-Base configuration\n",
        "    model = VisionTransformer(\n",
        "        img_size=224,\n",
        "        patch_size=16,\n",
        "        in_channels=3,\n",
        "        num_classes=1000,\n",
        "        emb_size=768,\n",
        "        depth=12,\n",
        "        num_heads=12,\n",
        "        mlp_ratio=4,\n",
        "        dropout=0.1\n",
        "    )\n",
        "\n",
        "    x = torch.randn(2, 3, 224, 224)\n",
        "    out = model(x)\n",
        "\n",
        "    print(f'Input shape: {x.shape}')\n",
        "    print(f'Output shape: {out.shape}')\n",
        "    print(f'Total parameters: {sum(p.numel() for p in model.parameters()):,}')\n",
        "\n",
        "    # Different ViT configurations\n",
        "    print('\\n=== ViT Configurations ===')\n",
        "    configs = {\n",
        "        'ViT-Tiny': {'emb_size': 192, 'depth': 12, 'num_heads': 3},\n",
        "        'ViT-Small': {'emb_size': 384, 'depth': 12, 'num_heads': 6},\n",
        "        'ViT-Base': {'emb_size': 768, 'depth': 12, 'num_heads': 12},\n",
        "        'ViT-Large': {'emb_size': 1024, 'depth': 24, 'num_heads': 16},\n",
        "    }\n",
        "\n",
        "    for name, config in configs.items():\n",
        "        model = VisionTransformer(**config, num_classes=1000)\n",
        "        params = sum(p.numel() for p in model.parameters())\n",
        "        print(f'{name}: {params:,} parameters')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGSRZJkAEuIx"
      },
      "source": [
        "# 6. ViT for CIFAR-10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXOvWXfiO5fo"
      },
      "source": [
        "위의 코드를 완성했다면, 아래 코드를 실행하여 전체 모델을 테스트할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQerYjbvEt1T",
        "outputId": "e3d0dd89-381d-41f3-a7cc-475555f99c69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([4, 3, 32, 32])\n",
            "Output shape: torch.Size([4, 10])\n",
            "Parameters: 4,766,474\n",
            "\n",
            "Epoch 1/100\n",
            "Batch 0: Loss 2.3571, Acc 13.28%\n",
            "Batch 100: Loss 2.3376, Acc 10.44%\n",
            "Train Loss: 2.3660, Train Acc: 10.46%\n",
            "Test Loss: 2.3752, Test Acc: 10.52%\n",
            "LR: 0.000500, Epoch time: 11.11s\n",
            "\n",
            "Epoch 2/100\n",
            "Batch 0: Loss 2.3704, Acc 11.72%\n",
            "Batch 100: Loss 1.8758, Acc 26.73%\n",
            "Train Loss: 1.9316, Train Acc: 30.78%\n",
            "Test Loss: 1.7793, Test Acc: 39.29%\n",
            "LR: 0.000500, Epoch time: 11.16s\n",
            "\n",
            "Epoch 3/100\n",
            "Batch 0: Loss 1.7789, Acc 44.92%\n",
            "Batch 100: Loss 1.7709, Acc 40.53%\n",
            "Train Loss: 1.7214, Train Acc: 42.26%\n",
            "Test Loss: 1.6410, Test Acc: 46.75%\n",
            "LR: 0.000499, Epoch time: 11.09s\n",
            "\n",
            "Epoch 4/100\n",
            "Batch 0: Loss 1.7120, Acc 43.75%\n",
            "Batch 100: Loss 1.5628, Acc 46.77%\n",
            "Train Loss: 1.6200, Train Acc: 47.69%\n",
            "Test Loss: 1.6166, Test Acc: 48.21%\n",
            "LR: 0.000499, Epoch time: 11.09s\n",
            "\n",
            "Epoch 5/100\n",
            "Batch 0: Loss 1.5919, Acc 46.48%\n",
            "Batch 100: Loss 1.6283, Acc 50.16%\n",
            "Train Loss: 1.5615, Train Acc: 50.84%\n",
            "Test Loss: 1.4984, Test Acc: 53.74%\n",
            "LR: 0.000498, Epoch time: 11.11s\n",
            "\n",
            "Epoch 6/100\n",
            "Batch 0: Loss 1.5873, Acc 48.83%\n",
            "Batch 100: Loss 1.5418, Acc 52.53%\n",
            "Train Loss: 1.5209, Train Acc: 52.65%\n",
            "Test Loss: 1.5179, Test Acc: 53.37%\n",
            "LR: 0.000497, Epoch time: 11.16s\n",
            "\n",
            "Epoch 7/100\n",
            "Batch 0: Loss 1.4257, Acc 58.59%\n",
            "Batch 100: Loss 1.4343, Acc 54.14%\n",
            "Train Loss: 1.4848, Train Acc: 54.54%\n",
            "Test Loss: 1.4781, Test Acc: 55.12%\n",
            "LR: 0.000495, Epoch time: 11.24s\n",
            "\n",
            "Epoch 8/100\n",
            "Batch 0: Loss 1.4835, Acc 54.69%\n",
            "Batch 100: Loss 1.4091, Acc 54.95%\n",
            "Train Loss: 1.4564, Train Acc: 55.74%\n",
            "Test Loss: 1.4252, Test Acc: 57.06%\n",
            "LR: 0.000494, Epoch time: 11.22s\n",
            "\n",
            "Epoch 9/100\n",
            "Batch 0: Loss 1.3658, Acc 57.81%\n",
            "Batch 100: Loss 1.4095, Acc 57.30%\n",
            "Train Loss: 1.4325, Train Acc: 57.08%\n",
            "Test Loss: 1.4122, Test Acc: 57.98%\n",
            "LR: 0.000492, Epoch time: 11.11s\n",
            "\n",
            "Epoch 10/100\n",
            "Batch 0: Loss 1.4994, Acc 53.52%\n",
            "Batch 100: Loss 1.3735, Acc 58.16%\n",
            "Train Loss: 1.4152, Train Acc: 58.02%\n",
            "Test Loss: 1.4584, Test Acc: 56.24%\n",
            "LR: 0.000490, Epoch time: 11.14s\n",
            "\n",
            "Epoch 11/100\n",
            "Batch 0: Loss 1.4004, Acc 58.20%\n",
            "Batch 100: Loss 1.3675, Acc 58.99%\n",
            "Train Loss: 1.3900, Train Acc: 58.85%\n",
            "Test Loss: 1.4449, Test Acc: 56.87%\n",
            "LR: 0.000488, Epoch time: 11.16s\n",
            "\n",
            "Epoch 12/100\n",
            "Batch 0: Loss 1.4210, Acc 57.81%\n",
            "Batch 100: Loss 1.4024, Acc 59.15%\n",
            "Train Loss: 1.3757, Train Acc: 59.75%\n",
            "Test Loss: 1.3874, Test Acc: 59.29%\n",
            "LR: 0.000485, Epoch time: 11.11s\n",
            "\n",
            "Epoch 13/100\n",
            "Batch 0: Loss 1.3085, Acc 64.84%\n",
            "Batch 100: Loss 1.3901, Acc 60.50%\n",
            "Train Loss: 1.3626, Train Acc: 60.28%\n",
            "Test Loss: 1.3809, Test Acc: 60.23%\n",
            "LR: 0.000482, Epoch time: 11.16s\n",
            "\n",
            "Epoch 14/100\n",
            "Batch 0: Loss 1.3260, Acc 64.84%\n",
            "Batch 100: Loss 1.2850, Acc 61.39%\n",
            "Train Loss: 1.3414, Train Acc: 61.38%\n",
            "Test Loss: 1.3744, Test Acc: 60.18%\n",
            "LR: 0.000479, Epoch time: 11.11s\n",
            "\n",
            "Epoch 15/100\n",
            "Batch 0: Loss 1.3649, Acc 60.55%\n",
            "Batch 100: Loss 1.3285, Acc 61.64%\n",
            "Train Loss: 1.3303, Train Acc: 61.92%\n",
            "Test Loss: 1.4537, Test Acc: 57.22%\n",
            "LR: 0.000476, Epoch time: 11.08s\n",
            "\n",
            "Epoch 16/100\n",
            "Batch 0: Loss 1.3039, Acc 62.50%\n",
            "Batch 100: Loss 1.3520, Acc 62.32%\n",
            "Train Loss: 1.3155, Train Acc: 62.56%\n",
            "Test Loss: 1.3070, Test Acc: 62.76%\n",
            "LR: 0.000472, Epoch time: 11.12s\n",
            "\n",
            "Epoch 17/100\n",
            "Batch 0: Loss 1.2844, Acc 66.02%\n",
            "Batch 100: Loss 1.4181, Acc 63.13%\n",
            "Train Loss: 1.3030, Train Acc: 63.12%\n",
            "Test Loss: 1.3449, Test Acc: 61.79%\n",
            "LR: 0.000468, Epoch time: 11.10s\n",
            "\n",
            "Epoch 18/100\n",
            "Batch 0: Loss 1.3245, Acc 60.94%\n",
            "Batch 100: Loss 1.3084, Acc 64.53%\n",
            "Train Loss: 1.2842, Train Acc: 64.21%\n",
            "Test Loss: 1.3095, Test Acc: 62.73%\n",
            "LR: 0.000464, Epoch time: 11.05s\n",
            "\n",
            "Epoch 19/100\n",
            "Batch 0: Loss 1.2429, Acc 62.89%\n",
            "Batch 100: Loss 1.1463, Acc 64.52%\n",
            "Train Loss: 1.2738, Train Acc: 64.58%\n",
            "Test Loss: 1.2792, Test Acc: 64.70%\n",
            "LR: 0.000460, Epoch time: 11.09s\n",
            "\n",
            "Epoch 20/100\n",
            "Batch 0: Loss 1.2397, Acc 65.62%\n",
            "Batch 100: Loss 1.2156, Acc 64.80%\n",
            "Train Loss: 1.2601, Train Acc: 65.15%\n",
            "Test Loss: 1.3135, Test Acc: 62.83%\n",
            "LR: 0.000456, Epoch time: 11.10s\n",
            "\n",
            "Epoch 21/100\n",
            "Batch 0: Loss 1.2741, Acc 65.23%\n",
            "Batch 100: Loss 1.1591, Acc 65.73%\n",
            "Train Loss: 1.2489, Train Acc: 65.79%\n",
            "Test Loss: 1.2693, Test Acc: 65.09%\n",
            "LR: 0.000451, Epoch time: 11.06s\n",
            "\n",
            "Epoch 22/100\n",
            "Batch 0: Loss 1.3109, Acc 63.28%\n",
            "Batch 100: Loss 1.2967, Acc 66.08%\n",
            "Train Loss: 1.2408, Train Acc: 66.12%\n",
            "Test Loss: 1.2532, Test Acc: 65.56%\n",
            "LR: 0.000447, Epoch time: 11.06s\n",
            "\n",
            "Epoch 23/100\n",
            "Batch 0: Loss 1.2313, Acc 66.80%\n",
            "Batch 100: Loss 1.2121, Acc 66.85%\n",
            "Train Loss: 1.2261, Train Acc: 66.86%\n",
            "Test Loss: 1.2718, Test Acc: 64.92%\n",
            "LR: 0.000442, Epoch time: 11.04s\n",
            "\n",
            "Epoch 24/100\n",
            "Batch 0: Loss 1.2089, Acc 67.58%\n",
            "Batch 100: Loss 1.1662, Acc 67.21%\n",
            "Train Loss: 1.2166, Train Acc: 67.19%\n",
            "Test Loss: 1.2740, Test Acc: 64.43%\n",
            "LR: 0.000436, Epoch time: 11.09s\n",
            "\n",
            "Epoch 25/100\n",
            "Batch 0: Loss 1.2075, Acc 69.53%\n",
            "Batch 100: Loss 1.1887, Acc 68.17%\n",
            "Train Loss: 1.2061, Train Acc: 67.72%\n",
            "Test Loss: 1.2503, Test Acc: 66.12%\n",
            "LR: 0.000431, Epoch time: 11.10s\n",
            "\n",
            "Epoch 26/100\n",
            "Batch 0: Loss 1.1150, Acc 73.44%\n",
            "Batch 100: Loss 1.2489, Acc 68.49%\n",
            "Train Loss: 1.1870, Train Acc: 68.71%\n",
            "Test Loss: 1.2497, Test Acc: 65.96%\n",
            "LR: 0.000425, Epoch time: 11.11s\n",
            "\n",
            "Epoch 27/100\n",
            "Batch 0: Loss 1.1605, Acc 68.75%\n",
            "Batch 100: Loss 1.2434, Acc 69.46%\n",
            "Train Loss: 1.1778, Train Acc: 69.05%\n",
            "Test Loss: 1.2590, Test Acc: 66.11%\n",
            "LR: 0.000420, Epoch time: 11.08s\n",
            "\n",
            "Epoch 28/100\n",
            "Batch 0: Loss 1.1787, Acc 68.75%\n",
            "Batch 100: Loss 1.2293, Acc 69.84%\n",
            "Train Loss: 1.1656, Train Acc: 69.54%\n",
            "Test Loss: 1.2594, Test Acc: 65.71%\n",
            "LR: 0.000414, Epoch time: 11.09s\n",
            "\n",
            "Epoch 29/100\n",
            "Batch 0: Loss 1.2118, Acc 67.97%\n",
            "Batch 100: Loss 1.2397, Acc 69.57%\n",
            "Train Loss: 1.1591, Train Acc: 69.68%\n",
            "Test Loss: 1.2335, Test Acc: 66.80%\n",
            "LR: 0.000408, Epoch time: 11.09s\n",
            "\n",
            "Epoch 30/100\n",
            "Batch 0: Loss 1.2184, Acc 69.53%\n",
            "Batch 100: Loss 1.1385, Acc 70.69%\n",
            "Train Loss: 1.1444, Train Acc: 70.51%\n",
            "Test Loss: 1.2254, Test Acc: 67.50%\n",
            "LR: 0.000401, Epoch time: 11.10s\n",
            "\n",
            "Epoch 31/100\n",
            "Batch 0: Loss 1.1887, Acc 66.80%\n",
            "Batch 100: Loss 1.1702, Acc 71.51%\n",
            "Train Loss: 1.1322, Train Acc: 71.10%\n",
            "Test Loss: 1.2294, Test Acc: 67.10%\n",
            "LR: 0.000395, Epoch time: 11.13s\n",
            "\n",
            "Epoch 32/100\n",
            "Batch 0: Loss 1.1095, Acc 73.05%\n",
            "Batch 100: Loss 1.1419, Acc 71.72%\n",
            "Train Loss: 1.1220, Train Acc: 71.60%\n",
            "Test Loss: 1.2260, Test Acc: 67.37%\n",
            "LR: 0.000388, Epoch time: 11.10s\n",
            "\n",
            "Epoch 33/100\n",
            "Batch 0: Loss 1.0126, Acc 73.05%\n",
            "Batch 100: Loss 1.2320, Acc 72.52%\n",
            "Train Loss: 1.1082, Train Acc: 72.20%\n",
            "Test Loss: 1.2195, Test Acc: 68.12%\n",
            "LR: 0.000382, Epoch time: 11.11s\n",
            "\n",
            "Epoch 34/100\n",
            "Batch 0: Loss 1.1030, Acc 72.27%\n",
            "Batch 100: Loss 1.1608, Acc 73.31%\n",
            "Train Loss: 1.0959, Train Acc: 72.83%\n",
            "Test Loss: 1.2230, Test Acc: 67.79%\n",
            "LR: 0.000375, Epoch time: 11.16s\n",
            "\n",
            "Epoch 35/100\n",
            "Batch 0: Loss 1.0681, Acc 72.27%\n",
            "Batch 100: Loss 1.0889, Acc 73.87%\n",
            "Train Loss: 1.0901, Train Acc: 73.35%\n",
            "Test Loss: 1.2019, Test Acc: 68.77%\n",
            "LR: 0.000368, Epoch time: 11.24s\n",
            "\n",
            "Epoch 36/100\n",
            "Batch 0: Loss 1.0699, Acc 73.44%\n",
            "Batch 100: Loss 1.0860, Acc 74.06%\n",
            "Train Loss: 1.0750, Train Acc: 73.82%\n",
            "Test Loss: 1.2352, Test Acc: 67.78%\n",
            "LR: 0.000361, Epoch time: 11.25s\n",
            "\n",
            "Epoch 37/100\n",
            "Batch 0: Loss 0.9944, Acc 75.00%\n",
            "Batch 100: Loss 1.0926, Acc 74.39%\n",
            "Train Loss: 1.0625, Train Acc: 74.26%\n",
            "Test Loss: 1.2331, Test Acc: 68.05%\n",
            "LR: 0.000354, Epoch time: 11.16s\n",
            "\n",
            "Epoch 38/100\n",
            "Batch 0: Loss 1.0985, Acc 73.83%\n",
            "Batch 100: Loss 1.0148, Acc 75.26%\n",
            "Train Loss: 1.0512, Train Acc: 75.05%\n",
            "Test Loss: 1.2020, Test Acc: 68.97%\n",
            "LR: 0.000347, Epoch time: 11.21s\n",
            "\n",
            "Epoch 39/100\n",
            "Batch 0: Loss 1.0190, Acc 75.00%\n",
            "Batch 100: Loss 1.0755, Acc 75.05%\n",
            "Train Loss: 1.0422, Train Acc: 75.19%\n",
            "Test Loss: 1.2066, Test Acc: 68.94%\n",
            "LR: 0.000339, Epoch time: 11.10s\n",
            "\n",
            "Epoch 40/100\n",
            "Batch 0: Loss 1.0348, Acc 75.39%\n",
            "Batch 100: Loss 1.0543, Acc 76.50%\n",
            "Train Loss: 1.0260, Train Acc: 76.00%\n",
            "Test Loss: 1.1874, Test Acc: 70.14%\n",
            "LR: 0.000332, Epoch time: 11.19s\n",
            "\n",
            "Epoch 41/100\n",
            "Batch 0: Loss 1.0955, Acc 74.61%\n",
            "Batch 100: Loss 1.0100, Acc 76.43%\n",
            "Train Loss: 1.0206, Train Acc: 76.36%\n",
            "Test Loss: 1.1785, Test Acc: 70.13%\n",
            "LR: 0.000324, Epoch time: 11.11s\n",
            "\n",
            "Epoch 42/100\n",
            "Batch 0: Loss 0.9387, Acc 82.42%\n",
            "Batch 100: Loss 0.9994, Acc 77.39%\n",
            "Train Loss: 1.0024, Train Acc: 77.21%\n",
            "Test Loss: 1.2020, Test Acc: 69.56%\n",
            "LR: 0.000317, Epoch time: 11.07s\n",
            "\n",
            "Epoch 43/100\n",
            "Batch 0: Loss 1.0205, Acc 76.95%\n",
            "Batch 100: Loss 0.9717, Acc 77.46%\n",
            "Train Loss: 0.9873, Train Acc: 77.71%\n",
            "Test Loss: 1.2062, Test Acc: 69.92%\n",
            "LR: 0.000309, Epoch time: 11.12s\n",
            "\n",
            "Epoch 44/100\n",
            "Batch 0: Loss 0.9705, Acc 76.95%\n",
            "Batch 100: Loss 1.0226, Acc 78.46%\n",
            "Train Loss: 0.9796, Train Acc: 78.28%\n",
            "Test Loss: 1.1829, Test Acc: 70.66%\n",
            "LR: 0.000301, Epoch time: 11.07s\n",
            "\n",
            "Epoch 45/100\n",
            "Batch 0: Loss 0.9286, Acc 80.47%\n",
            "Batch 100: Loss 0.9686, Acc 78.90%\n",
            "Train Loss: 0.9686, Train Acc: 78.72%\n",
            "Test Loss: 1.1696, Test Acc: 70.96%\n",
            "LR: 0.000293, Epoch time: 11.07s\n",
            "\n",
            "Epoch 46/100\n",
            "Batch 0: Loss 0.9462, Acc 80.47%\n",
            "Batch 100: Loss 1.0169, Acc 79.69%\n",
            "Train Loss: 0.9583, Train Acc: 79.31%\n",
            "Test Loss: 1.1851, Test Acc: 70.47%\n",
            "LR: 0.000286, Epoch time: 11.09s\n",
            "\n",
            "Epoch 47/100\n",
            "Batch 0: Loss 1.0425, Acc 78.12%\n",
            "Batch 100: Loss 0.9632, Acc 80.63%\n",
            "Train Loss: 0.9373, Train Acc: 80.21%\n",
            "Test Loss: 1.1988, Test Acc: 70.88%\n",
            "LR: 0.000278, Epoch time: 11.08s\n",
            "\n",
            "Epoch 48/100\n",
            "Batch 0: Loss 0.9875, Acc 77.34%\n",
            "Batch 100: Loss 1.0663, Acc 80.91%\n",
            "Train Loss: 0.9355, Train Acc: 80.26%\n",
            "Test Loss: 1.1725, Test Acc: 71.41%\n",
            "LR: 0.000270, Epoch time: 11.06s\n",
            "\n",
            "Epoch 49/100\n",
            "Batch 0: Loss 0.8925, Acc 84.38%\n",
            "Batch 100: Loss 0.9014, Acc 81.63%\n",
            "Train Loss: 0.9172, Train Acc: 81.18%\n",
            "Test Loss: 1.1939, Test Acc: 70.98%\n",
            "LR: 0.000262, Epoch time: 11.10s\n",
            "\n",
            "Epoch 50/100\n",
            "Batch 0: Loss 0.8515, Acc 85.16%\n",
            "Batch 100: Loss 0.9116, Acc 81.69%\n",
            "Train Loss: 0.9056, Train Acc: 81.52%\n",
            "Test Loss: 1.1890, Test Acc: 71.47%\n",
            "LR: 0.000254, Epoch time: 11.08s\n",
            "\n",
            "Epoch 51/100\n",
            "Batch 0: Loss 0.9254, Acc 82.03%\n",
            "Batch 100: Loss 0.9633, Acc 82.31%\n",
            "Train Loss: 0.8947, Train Acc: 82.17%\n",
            "Test Loss: 1.1739, Test Acc: 71.93%\n",
            "LR: 0.000246, Epoch time: 11.08s\n",
            "\n",
            "Epoch 52/100\n",
            "Batch 0: Loss 0.8542, Acc 83.59%\n",
            "Batch 100: Loss 0.8195, Acc 83.51%\n",
            "Train Loss: 0.8772, Train Acc: 83.09%\n",
            "Test Loss: 1.1858, Test Acc: 71.75%\n",
            "LR: 0.000238, Epoch time: 11.09s\n",
            "\n",
            "Epoch 53/100\n",
            "Batch 0: Loss 0.8685, Acc 83.59%\n",
            "Batch 100: Loss 0.8515, Acc 83.33%\n",
            "Train Loss: 0.8718, Train Acc: 83.01%\n",
            "Test Loss: 1.1877, Test Acc: 71.42%\n",
            "LR: 0.000230, Epoch time: 11.11s\n",
            "\n",
            "Epoch 54/100\n",
            "Batch 0: Loss 0.7565, Acc 87.89%\n",
            "Batch 100: Loss 0.8097, Acc 84.57%\n",
            "Train Loss: 0.8558, Train Acc: 83.99%\n",
            "Test Loss: 1.2017, Test Acc: 71.47%\n",
            "LR: 0.000222, Epoch time: 11.09s\n",
            "\n",
            "Epoch 55/100\n",
            "Batch 0: Loss 0.8480, Acc 83.98%\n",
            "Batch 100: Loss 0.8219, Acc 85.05%\n",
            "Train Loss: 0.8441, Train Acc: 84.57%\n",
            "Test Loss: 1.1999, Test Acc: 71.16%\n",
            "LR: 0.000214, Epoch time: 11.08s\n",
            "\n",
            "Epoch 56/100\n",
            "Batch 0: Loss 0.8728, Acc 85.16%\n",
            "Batch 100: Loss 0.8355, Acc 85.11%\n",
            "Train Loss: 0.8344, Train Acc: 84.88%\n",
            "Test Loss: 1.2153, Test Acc: 71.74%\n",
            "LR: 0.000207, Epoch time: 11.11s\n",
            "\n",
            "Epoch 57/100\n",
            "Batch 0: Loss 0.7975, Acc 86.72%\n",
            "Batch 100: Loss 0.8214, Acc 85.65%\n",
            "Train Loss: 0.8220, Train Acc: 85.59%\n",
            "Test Loss: 1.1994, Test Acc: 72.13%\n",
            "LR: 0.000199, Epoch time: 11.09s\n",
            "\n",
            "Epoch 58/100\n",
            "Batch 0: Loss 0.7783, Acc 87.89%\n",
            "Batch 100: Loss 0.8076, Acc 86.10%\n",
            "Train Loss: 0.8120, Train Acc: 85.83%\n",
            "Test Loss: 1.1776, Test Acc: 72.74%\n",
            "LR: 0.000191, Epoch time: 11.09s\n",
            "\n",
            "Epoch 59/100\n",
            "Batch 0: Loss 0.7812, Acc 87.11%\n",
            "Batch 100: Loss 0.7457, Acc 86.61%\n",
            "Train Loss: 0.8014, Train Acc: 86.59%\n",
            "Test Loss: 1.2220, Test Acc: 71.51%\n",
            "LR: 0.000183, Epoch time: 11.12s\n",
            "\n",
            "Epoch 60/100\n",
            "Batch 0: Loss 0.7780, Acc 87.50%\n",
            "Batch 100: Loss 0.8485, Acc 87.26%\n",
            "Train Loss: 0.7956, Train Acc: 86.77%\n",
            "Test Loss: 1.1981, Test Acc: 72.60%\n",
            "LR: 0.000176, Epoch time: 11.11s\n",
            "\n",
            "Epoch 61/100\n",
            "Batch 0: Loss 0.7406, Acc 89.06%\n",
            "Batch 100: Loss 0.7904, Acc 87.86%\n",
            "Train Loss: 0.7805, Train Acc: 87.63%\n",
            "Test Loss: 1.2092, Test Acc: 72.43%\n",
            "LR: 0.000168, Epoch time: 11.13s\n",
            "\n",
            "Epoch 62/100\n",
            "Batch 0: Loss 0.8141, Acc 84.38%\n",
            "Batch 100: Loss 0.7399, Acc 88.12%\n",
            "Train Loss: 0.7702, Train Acc: 87.86%\n",
            "Test Loss: 1.2002, Test Acc: 72.19%\n",
            "LR: 0.000161, Epoch time: 11.08s\n",
            "\n",
            "Epoch 63/100\n",
            "Batch 0: Loss 0.7423, Acc 89.45%\n",
            "Batch 100: Loss 0.7826, Acc 88.64%\n",
            "Train Loss: 0.7606, Train Acc: 88.30%\n",
            "Test Loss: 1.2163, Test Acc: 72.51%\n",
            "LR: 0.000153, Epoch time: 11.11s\n",
            "\n",
            "Epoch 64/100\n",
            "Batch 0: Loss 0.7130, Acc 90.62%\n",
            "Batch 100: Loss 0.8214, Acc 88.93%\n",
            "Train Loss: 0.7531, Train Acc: 88.79%\n",
            "Test Loss: 1.2302, Test Acc: 71.77%\n",
            "LR: 0.000146, Epoch time: 11.13s\n",
            "\n",
            "Epoch 65/100\n",
            "Batch 0: Loss 0.7388, Acc 89.45%\n",
            "Batch 100: Loss 0.7595, Acc 89.34%\n",
            "Train Loss: 0.7415, Train Acc: 89.21%\n",
            "Test Loss: 1.2250, Test Acc: 72.68%\n",
            "LR: 0.000139, Epoch time: 11.17s\n",
            "\n",
            "Epoch 66/100\n",
            "Batch 0: Loss 0.7186, Acc 89.45%\n",
            "Batch 100: Loss 0.7590, Acc 89.91%\n",
            "Train Loss: 0.7315, Train Acc: 89.68%\n",
            "Test Loss: 1.2217, Test Acc: 73.06%\n",
            "LR: 0.000132, Epoch time: 11.14s\n",
            "\n",
            "Epoch 67/100\n",
            "Batch 0: Loss 0.6684, Acc 94.14%\n",
            "Batch 100: Loss 0.6884, Acc 89.96%\n",
            "Train Loss: 0.7247, Train Acc: 90.00%\n",
            "Test Loss: 1.2260, Test Acc: 72.72%\n",
            "LR: 0.000125, Epoch time: 11.12s\n",
            "\n",
            "Epoch 68/100\n",
            "Batch 0: Loss 0.6783, Acc 91.80%\n",
            "Batch 100: Loss 0.6835, Acc 91.11%\n",
            "Train Loss: 0.7131, Train Acc: 90.66%\n",
            "Test Loss: 1.2437, Test Acc: 72.04%\n",
            "LR: 0.000118, Epoch time: 11.10s\n",
            "\n",
            "Epoch 69/100\n",
            "Batch 0: Loss 0.6773, Acc 91.02%\n",
            "Batch 100: Loss 0.7753, Acc 90.93%\n",
            "Train Loss: 0.7110, Train Acc: 90.79%\n",
            "Test Loss: 1.2308, Test Acc: 72.60%\n",
            "LR: 0.000112, Epoch time: 11.09s\n",
            "\n",
            "Epoch 70/100\n",
            "Batch 0: Loss 0.6543, Acc 93.75%\n",
            "Batch 100: Loss 0.7331, Acc 91.36%\n",
            "Train Loss: 0.7026, Train Acc: 91.12%\n",
            "Test Loss: 1.2218, Test Acc: 73.23%\n",
            "LR: 0.000105, Epoch time: 11.08s\n",
            "\n",
            "Epoch 71/100\n",
            "Batch 0: Loss 0.6440, Acc 92.97%\n",
            "Batch 100: Loss 0.7368, Acc 91.70%\n",
            "Train Loss: 0.6924, Train Acc: 91.55%\n",
            "Test Loss: 1.2322, Test Acc: 73.25%\n",
            "LR: 0.000099, Epoch time: 11.10s\n",
            "\n",
            "Epoch 72/100\n",
            "Batch 0: Loss 0.6757, Acc 92.19%\n",
            "Batch 100: Loss 0.6771, Acc 91.82%\n",
            "Train Loss: 0.6883, Train Acc: 91.69%\n",
            "Test Loss: 1.2428, Test Acc: 72.76%\n",
            "LR: 0.000092, Epoch time: 11.08s\n",
            "\n",
            "Epoch 73/100\n",
            "Batch 0: Loss 0.6685, Acc 91.02%\n",
            "Batch 100: Loss 0.6757, Acc 92.33%\n",
            "Train Loss: 0.6787, Train Acc: 92.15%\n",
            "Test Loss: 1.2439, Test Acc: 72.80%\n",
            "LR: 0.000086, Epoch time: 11.06s\n",
            "\n",
            "Epoch 74/100\n",
            "Batch 0: Loss 0.6257, Acc 95.31%\n",
            "Batch 100: Loss 0.6582, Acc 92.40%\n",
            "Train Loss: 0.6770, Train Acc: 92.26%\n",
            "Test Loss: 1.2464, Test Acc: 72.75%\n",
            "LR: 0.000080, Epoch time: 11.07s\n",
            "\n",
            "Epoch 75/100\n",
            "Batch 0: Loss 0.6740, Acc 93.36%\n",
            "Batch 100: Loss 0.6393, Acc 93.01%\n",
            "Train Loss: 0.6637, Train Acc: 92.80%\n",
            "Test Loss: 1.2569, Test Acc: 72.91%\n",
            "LR: 0.000075, Epoch time: 11.05s\n",
            "\n",
            "Epoch 76/100\n",
            "Batch 0: Loss 0.6500, Acc 93.75%\n",
            "Batch 100: Loss 0.6413, Acc 93.27%\n",
            "Train Loss: 0.6575, Train Acc: 93.08%\n",
            "Test Loss: 1.2507, Test Acc: 73.25%\n",
            "LR: 0.000069, Epoch time: 11.09s\n",
            "\n",
            "Epoch 77/100\n",
            "Batch 0: Loss 0.6353, Acc 94.14%\n",
            "Batch 100: Loss 0.6852, Acc 93.44%\n",
            "Train Loss: 0.6557, Train Acc: 93.25%\n",
            "Test Loss: 1.2581, Test Acc: 72.73%\n",
            "LR: 0.000064, Epoch time: 11.10s\n",
            "\n",
            "Epoch 78/100\n",
            "Batch 0: Loss 0.6514, Acc 94.14%\n",
            "Batch 100: Loss 0.6593, Acc 93.59%\n",
            "Train Loss: 0.6481, Train Acc: 93.63%\n",
            "Test Loss: 1.2643, Test Acc: 72.49%\n",
            "LR: 0.000058, Epoch time: 11.09s\n",
            "\n",
            "Epoch 79/100\n",
            "Batch 0: Loss 0.6985, Acc 91.80%\n",
            "Batch 100: Loss 0.5820, Acc 93.75%\n",
            "Train Loss: 0.6419, Train Acc: 93.82%\n",
            "Test Loss: 1.2652, Test Acc: 73.10%\n",
            "LR: 0.000053, Epoch time: 11.12s\n",
            "\n",
            "Epoch 80/100\n",
            "Batch 0: Loss 0.7119, Acc 89.84%\n",
            "Batch 100: Loss 0.6652, Acc 93.85%\n",
            "Train Loss: 0.6423, Train Acc: 93.77%\n",
            "Test Loss: 1.2707, Test Acc: 72.57%\n",
            "LR: 0.000049, Epoch time: 11.09s\n",
            "\n",
            "Epoch 81/100\n",
            "Batch 0: Loss 0.6266, Acc 94.92%\n",
            "Batch 100: Loss 0.6250, Acc 94.30%\n",
            "Train Loss: 0.6349, Train Acc: 94.15%\n",
            "Test Loss: 1.2646, Test Acc: 72.92%\n",
            "LR: 0.000044, Epoch time: 11.07s\n",
            "\n",
            "Epoch 82/100\n",
            "Batch 0: Loss 0.6120, Acc 96.09%\n",
            "Batch 100: Loss 0.6177, Acc 94.36%\n",
            "Train Loss: 0.6306, Train Acc: 94.32%\n",
            "Test Loss: 1.2763, Test Acc: 72.70%\n",
            "LR: 0.000040, Epoch time: 11.09s\n",
            "\n",
            "Epoch 83/100\n",
            "Batch 0: Loss 0.6542, Acc 92.97%\n",
            "Batch 100: Loss 0.6031, Acc 94.52%\n",
            "Train Loss: 0.6293, Train Acc: 94.41%\n",
            "Test Loss: 1.2706, Test Acc: 72.76%\n",
            "LR: 0.000036, Epoch time: 11.07s\n",
            "\n",
            "Epoch 84/100\n",
            "Batch 0: Loss 0.5805, Acc 97.27%\n",
            "Batch 100: Loss 0.6417, Acc 94.65%\n",
            "Train Loss: 0.6265, Train Acc: 94.61%\n",
            "Test Loss: 1.2662, Test Acc: 73.26%\n",
            "LR: 0.000032, Epoch time: 11.05s\n",
            "\n",
            "Epoch 85/100\n",
            "Batch 0: Loss 0.6235, Acc 94.92%\n",
            "Batch 100: Loss 0.5932, Acc 94.84%\n",
            "Train Loss: 0.6194, Train Acc: 94.84%\n",
            "Test Loss: 1.2718, Test Acc: 73.23%\n",
            "LR: 0.000028, Epoch time: 11.07s\n",
            "\n",
            "Epoch 86/100\n",
            "Batch 0: Loss 0.5851, Acc 97.27%\n",
            "Batch 100: Loss 0.5926, Acc 95.35%\n",
            "Train Loss: 0.6157, Train Acc: 95.09%\n",
            "Test Loss: 1.2647, Test Acc: 73.45%\n",
            "LR: 0.000024, Epoch time: 11.09s\n",
            "\n",
            "Epoch 87/100\n",
            "Batch 0: Loss 0.6374, Acc 94.14%\n",
            "Batch 100: Loss 0.5899, Acc 95.10%\n",
            "Train Loss: 0.6155, Train Acc: 95.06%\n",
            "Test Loss: 1.2738, Test Acc: 73.01%\n",
            "LR: 0.000021, Epoch time: 11.07s\n",
            "\n",
            "Epoch 88/100\n",
            "Batch 0: Loss 0.5996, Acc 96.88%\n",
            "Batch 100: Loss 0.6046, Acc 95.26%\n",
            "Train Loss: 0.6132, Train Acc: 95.16%\n",
            "Test Loss: 1.2784, Test Acc: 73.29%\n",
            "LR: 0.000018, Epoch time: 11.09s\n",
            "\n",
            "Epoch 89/100\n",
            "Batch 0: Loss 0.6017, Acc 94.92%\n",
            "Batch 100: Loss 0.5716, Acc 95.42%\n",
            "Train Loss: 0.6096, Train Acc: 95.32%\n",
            "Test Loss: 1.2867, Test Acc: 72.96%\n",
            "LR: 0.000015, Epoch time: 11.10s\n",
            "\n",
            "Epoch 90/100\n",
            "Batch 0: Loss 0.5846, Acc 96.09%\n",
            "Batch 100: Loss 0.5912, Acc 95.37%\n",
            "Train Loss: 0.6064, Train Acc: 95.42%\n",
            "Test Loss: 1.2880, Test Acc: 73.01%\n",
            "LR: 0.000012, Epoch time: 11.09s\n",
            "\n",
            "Epoch 91/100\n",
            "Batch 0: Loss 0.5916, Acc 96.09%\n",
            "Batch 100: Loss 0.6445, Acc 95.38%\n",
            "Train Loss: 0.6049, Train Acc: 95.58%\n",
            "Test Loss: 1.2848, Test Acc: 72.87%\n",
            "LR: 0.000010, Epoch time: 11.08s\n",
            "\n",
            "Epoch 92/100\n",
            "Batch 0: Loss 0.5617, Acc 97.66%\n",
            "Batch 100: Loss 0.5934, Acc 95.72%\n",
            "Train Loss: 0.6013, Train Acc: 95.82%\n",
            "Test Loss: 1.2921, Test Acc: 72.90%\n",
            "LR: 0.000008, Epoch time: 11.10s\n",
            "\n",
            "Epoch 93/100\n",
            "Batch 0: Loss 0.6076, Acc 95.70%\n",
            "Batch 100: Loss 0.5716, Acc 95.77%\n",
            "Train Loss: 0.5998, Train Acc: 95.87%\n",
            "Test Loss: 1.2886, Test Acc: 72.96%\n",
            "LR: 0.000006, Epoch time: 11.16s\n",
            "\n",
            "Epoch 94/100\n",
            "Batch 0: Loss 0.5815, Acc 95.70%\n",
            "Batch 100: Loss 0.6242, Acc 95.93%\n",
            "Train Loss: 0.6006, Train Acc: 95.75%\n",
            "Test Loss: 1.2861, Test Acc: 73.14%\n",
            "LR: 0.000005, Epoch time: 11.12s\n",
            "\n",
            "Epoch 95/100\n",
            "Batch 0: Loss 0.5813, Acc 96.88%\n",
            "Batch 100: Loss 0.5772, Acc 95.88%\n",
            "Train Loss: 0.6006, Train Acc: 95.80%\n",
            "Test Loss: 1.2850, Test Acc: 73.11%\n",
            "LR: 0.000003, Epoch time: 11.10s\n",
            "\n",
            "Epoch 96/100\n",
            "Batch 0: Loss 0.6370, Acc 94.92%\n",
            "Batch 100: Loss 0.6214, Acc 96.01%\n",
            "Train Loss: 0.5981, Train Acc: 95.90%\n",
            "Test Loss: 1.2856, Test Acc: 73.24%\n",
            "LR: 0.000002, Epoch time: 11.14s\n",
            "\n",
            "Epoch 97/100\n",
            "Batch 0: Loss 0.5972, Acc 96.09%\n",
            "Batch 100: Loss 0.5706, Acc 96.09%\n",
            "Train Loss: 0.5982, Train Acc: 95.99%\n",
            "Test Loss: 1.2867, Test Acc: 73.13%\n",
            "LR: 0.000001, Epoch time: 11.07s\n",
            "\n",
            "Epoch 98/100\n",
            "Batch 0: Loss 0.5720, Acc 96.88%\n",
            "Batch 100: Loss 0.5920, Acc 95.87%\n",
            "Train Loss: 0.6009, Train Acc: 95.77%\n",
            "Test Loss: 1.2858, Test Acc: 73.22%\n",
            "LR: 0.000001, Epoch time: 11.08s\n",
            "\n",
            "Epoch 99/100\n",
            "Batch 0: Loss 0.5761, Acc 96.88%\n",
            "Batch 100: Loss 0.5855, Acc 96.09%\n",
            "Train Loss: 0.5959, Train Acc: 96.09%\n",
            "Test Loss: 1.2850, Test Acc: 73.27%\n",
            "LR: 0.000000, Epoch time: 11.12s\n",
            "\n",
            "Epoch 100/100\n",
            "Batch 0: Loss 0.6120, Acc 94.53%\n",
            "Batch 100: Loss 0.5698, Acc 95.80%\n",
            "Train Loss: 0.5988, Train Acc: 95.86%\n",
            "Test Loss: 1.2852, Test Acc: 73.23%\n",
            "LR: 0.000000, Epoch time: 11.06s\n",
            "\n",
            "Best Test Accuracy: 73.45%\n"
          ]
        }
      ],
      "source": [
        "class ViTCIFAR10(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        img_size=32,\n",
        "        patch_size=4,\n",
        "        in_channels=3,\n",
        "        num_classes=10,\n",
        "        emb_size=256,\n",
        "        depth=6,\n",
        "        num_heads=8,\n",
        "        mlp_ratio=4,\n",
        "        dropout=0.1\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.patch_embed = PatchEmbedding(in_channels, patch_size, emb_size, img_size)\n",
        "\n",
        "        self.blocks = nn.ModuleList([\n",
        "            TransformerEncoderBlock(emb_size, num_heads, mlp_ratio, dropout)\n",
        "            for _ in range(depth)\n",
        "        ])\n",
        "\n",
        "        self.norm = nn.LayerNorm(emb_size)\n",
        "        self.head = nn.Linear(emb_size, num_classes)\n",
        "\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.trunc_normal_(m.weight, std=0.02)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.LayerNorm):\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "                nn.init.constant_(m.weight, 1.0)\n",
        "            elif isinstance(m, nn.Conv2d):\n",
        "                nn.init.trunc_normal_(m.weight, std=0.02)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        if hasattr(self.patch_embed, 'cls_token'):\n",
        "            nn.init.trunc_normal_(self.patch_embed.cls_token, std=0.02)\n",
        "        if hasattr(self.patch_embed, 'positions'):\n",
        "            nn.init.trunc_normal_(self.patch_embed.positions, std=0.02)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        x = self.patch_embed(x)\n",
        "\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "\n",
        "        x = self.norm(x)\n",
        "        cls_token = x[:, 0]\n",
        "        x = self.head(cls_token)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(dataloader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = output.max(1)\n",
        "        total += target.size(0)\n",
        "        correct += predicted.eq(target).sum().item()\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "            print(f'Batch {batch_idx}: Loss {loss.item():.4f}, Acc {100.*correct/total:.2f}%')\n",
        "\n",
        "    return running_loss / len(dataloader), 100. * correct / total\n",
        "\n",
        "\n",
        "def test(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in dataloader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target).item()\n",
        "\n",
        "            _, predicted = output.max(1)\n",
        "            total += target.size(0)\n",
        "            correct += predicted.eq(target).sum().item()\n",
        "\n",
        "    test_loss /= len(dataloader)\n",
        "    accuracy = 100. * correct / total\n",
        "\n",
        "    return test_loss, accuracy\n",
        "\n",
        "\n",
        "def get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps):\n",
        "    def lr_lambda(current_step):\n",
        "        if current_step < num_warmup_steps:\n",
        "            return float(current_step) / float(max(1, num_warmup_steps))\n",
        "        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
        "        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * progress)))\n",
        "\n",
        "    return optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
        "\n",
        "\n",
        "def main():\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(32, scale=(0.8, 1.0)),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "    ])\n",
        "\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "    ])\n",
        "\n",
        "    train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "    test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True, num_workers=4, pin_memory=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "    model = ViTCIFAR10(\n",
        "        img_size=32,\n",
        "        patch_size=4,\n",
        "        num_classes=10,\n",
        "        emb_size=256,\n",
        "        depth=6,\n",
        "        num_heads=4,\n",
        "        dropout=0.1\n",
        "    ).to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "    optimizer = optim.AdamW(\n",
        "        model.parameters(),\n",
        "        lr=5e-4,\n",
        "        weight_decay=0.03,\n",
        "        betas=(0.9, 0.999)\n",
        "    )\n",
        "\n",
        "    num_epochs = 100\n",
        "    warmup_epochs = 1\n",
        "    total_steps = len(train_loader) * num_epochs\n",
        "    warmup_steps = len(train_loader) * warmup_epochs\n",
        "    scheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
        "\n",
        "    best_acc = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
        "\n",
        "        start_time = time.time()\n",
        "        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
        "        test_loss, test_acc = test(model, test_loader, criterion, device)\n",
        "\n",
        "        for _ in range(len(train_loader)):\n",
        "            scheduler.step()\n",
        "\n",
        "        epoch_time = time.time() - start_time\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
        "        print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%')\n",
        "        print(f'LR: {current_lr:.6f}, Epoch time: {epoch_time:.2f}s')\n",
        "\n",
        "        if test_acc > best_acc:\n",
        "            best_acc = test_acc\n",
        "            torch.save(model.state_dict(), 'vit_cifar10_best.pth')\n",
        "\n",
        "        if test_acc > 90.0:\n",
        "            print(f\"Reached target accuracy!\")\n",
        "            break\n",
        "\n",
        "    print(f'\\nBest Test Accuracy: {best_acc:.2f}%')\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    model = ViTCIFAR10(emb_size=256, depth=6, num_heads=4)\n",
        "    x = torch.randn(4, 3, 32, 32)\n",
        "    out = model(x)\n",
        "\n",
        "    print(f'Input shape: {x.shape}')\n",
        "    print(f'Output shape: {out.shape}')\n",
        "    print(f'Parameters: {sum(p.numel() for p in model.parameters()):,}')\n",
        "\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWvZXNO8Q_-Q"
      },
      "source": [
        "ViT는 일반적으로 대규모 데이터셋에서 사전 학습된(pretrained) 모델을 활용하는 경우가 많기 때문에, 하이퍼파라미터를 조정하거나 학습 epoch을 늘리면 성능이 개선될 수는 있지만, 소규모 데이터셋에서 처음부터 학습한 ViT의 성능이 낮은 것은 구조적 한계에 가깝습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wM3TeYu8Gm8x"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
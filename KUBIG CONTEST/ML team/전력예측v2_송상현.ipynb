{"cells":[{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w9iF1UI0iF_l","executionInfo":{"status":"ok","timestamp":1755679761358,"user_tz":-540,"elapsed":111,"user":{"displayName":"송상현","userId":"05825752637342282552"}},"outputId":"ac305299-9679-4037-f5d2-83a55a1a6970"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Aug 20 08:49:19 2025       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n","| N/A   67C    P8             11W /   70W |       0MiB /  15360MiB |      0%      Default |\n","|                                         |                        |                  N/A |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","|  No running processes found                                                             |\n","+-----------------------------------------------------------------------------------------+\n"]}]},{"cell_type":"markdown","source":["### 전처리"],"metadata":{"id":"msoYAXqSdccA"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"-FbCgQDrYrvA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756115813619,"user_tz":-540,"elapsed":18346,"user":{"displayName":"송상현","userId":"05825752637342282552"}},"outputId":"93a78345-57bd-44a3-c031-539d75340269"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2025-07-19T16:15:15.047836Z","iopub.status.busy":"2025-07-19T16:15:15.047301Z","iopub.status.idle":"2025-07-19T16:15:15.054775Z","shell.execute_reply":"2025-07-19T16:15:15.053895Z","shell.execute_reply.started":"2025-07-19T16:15:15.047790Z"},"trusted":true,"id":"ee_SW4l6YeMN","executionInfo":{"status":"ok","timestamp":1756115830798,"user_tz":-540,"elapsed":10823,"user":{"displayName":"송상현","userId":"05825752637342282552"}}},"outputs":[],"source":["import pandas as pd\n","import seaborn as sns\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib\n","import sklearn\n","import xgboost as xgb\n","from sklearn.model_selection import TimeSeriesSplit\n","from sklearn.preprocessing import LabelEncoder\n","import random as rn\n","RANDOM_SEED = 42\n","np.random.seed(RANDOM_SEED)\n","rn.seed(RANDOM_SEED)\n","from datetime import datetime\n","import warnings\n","import lightgbm as lgb\n","import pickle\n","import os\n","import json\n","\n","warnings.filterwarnings('ignore')\n","pd.set_option('display.max_columns', None)\n","\n","os.makedirs('models', exist_ok=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-07-19T16:15:15.567554Z","iopub.status.busy":"2025-07-19T16:15:15.567226Z","iopub.status.idle":"2025-07-19T16:15:15.871841Z","shell.execute_reply":"2025-07-19T16:15:15.870998Z","shell.execute_reply.started":"2025-07-19T16:15:15.567533Z"},"trusted":true,"id":"zcXlsnGUYeMO"},"outputs":[],"source":["train = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/electric/train.csv\", parse_dates=['일시'])\n","test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/electric/test.csv', parse_dates=['일시'])\n","building_info = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/electric/building_info.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-07-19T16:15:15.873082Z","iopub.status.busy":"2025-07-19T16:15:15.872814Z","iopub.status.idle":"2025-07-19T16:15:15.970782Z","shell.execute_reply":"2025-07-19T16:15:15.969888Z","shell.execute_reply.started":"2025-07-19T16:15:15.873055Z"},"trusted":true,"id":"Veqw2siJYeMO"},"outputs":[],"source":["train = train.rename(columns={\n","    '건물번호': 'building_number',\n","    '일시': 'date_time',\n","    '기온(°C)': 'temp',\n","    '강수량(mm)': 'rainfall',\n","    '풍속(m/s)': 'wind',\n","    '습도(%)': 'hum',\n","    '일조(hr)': 'sunshine',\n","    '일사(MJ/m2)': 'solar_radiation',\n","    '전력소비량(kWh)': 'power_consumption'\n","})\n","\n","test = test.rename(columns={\n","    '건물번호': 'building_number',\n","    '일시': 'date_time',\n","    '기온(°C)': 'temp',\n","    '강수량(mm)': 'rainfall',\n","    '풍속(m/s)': 'wind',\n","    '습도(%)': 'hum',\n","    '일조(hr)': 'sunshine',\n","    '일사(MJ/m2)': 'solar_radiation',\n","    '전력소비량(kWh)': 'power_consumption'\n","})\n","\n","\n","building_info = building_info.rename(columns={\n","    '건물번호': 'building_number',\n","    '건물유형': 'building',\n","    '연면적(m2)': 'total_area',\n","    '냉방면적(m2)': 'cooling_area',\n","    '태양광용량(kW)': 'solar_power_capacity',\n","    'ESS저장용량(kWh)': 'ess_capacity',\n","    'PCS용량(kW)': 'pcs_capacity'\n","})\n","\n","translation_dict = {\n","    '건물기타': 'Other Buildings',\n","    '공공': 'Public',\n","    '학교': 'University',\n","    '백화점': 'Department Store',\n","    '병원': 'Hospital',\n","    '상용': 'Commercial',\n","    '아파트': 'Apartment',\n","    '연구소': 'Research Institute',\n","    'IDC(전화국)': 'IDC',\n","    '호텔': 'Hotel'\n","}\n","\n","building_info['building'] = building_info['building'].replace(translation_dict)\n","\n","building_info['solar_power_utility'] = np.where(building_info.solar_power_capacity !='-',1,0)\n","building_info['ess_utility'] = np.where(building_info.ess_capacity !='-',1,0)\n","\n","train = pd.merge(train, building_info, on='building_number', how='left')\n","test = pd.merge(test, building_info, on='building_number', how='left')"]},{"cell_type":"code","source":["# 로그 변환: 전력 사용량에 log1p 적용 (모델 입력용 별도 컬럼 유지)\n","train['power_consumption_log'] = np.log1p(train['power_consumption'])\n","\n","# 2. 날짜/시간 관련 기본 특성 생성\n","train['date'] = train['date_time'].dt.date         # 날짜 (연-월-일)\n","test['date'] = test['date_time'].dt.date\n","\n","train['dow'] = train['date_time'].dt.weekday       # 요일 (0=월, ..., 6=일)\n","test['dow'] = test['date_time'].dt.weekday\n","\n","train['day'] = train['date_time'].dt.day           # 일 추가\n","test['day'] = test['date_time'].dt.day\n","\n","train['month'] = train['date_time'].dt.month       # 월\n","test['month'] = test['date_time'].dt.month\n","\n","# 주차 (연 기준 주 번호)\n","train['week'] = train['date_time'].dt.isocalendar().week.astype(int)\n","test['week'] = test['date_time'].dt.isocalendar().week.astype(int)\n","\n","# 월 내 몇째주(n_week) 특성 (휴일 패턴 인식용)\n","train['n_week'] = train['date_time'].dt.day.map(lambda x: (x-1)//7 + 1)\n","test['n_week'] = test['date_time'].dt.day.map(lambda x: (x-1)//7 + 1)\n","\n","# 시간 관련 주기 특성: 시간 (hour), 일간 주기 사이클\n","train['hour'] = train['date_time'].dt.hour\n","test['hour'] = test['date_time'].dt.hour\n","\n","# 주기성 인코딩 - 첫 번째 베이스라인 방식 적용\n","# 시간 (24시간 주기, 수정된 버전)\n","train['sin_hour'] = np.sin(2 * np.pi * train['hour'] / 24.0)\n","train['cos_hour'] = np.cos(2 * np.pi * train['hour'] / 24.0)\n","test['sin_hour'] = np.sin(2 * np.pi * test['hour'] / 24.0)\n","test['cos_hour'] = np.cos(2 * np.pi * test['hour'] / 24.0)\n","\n","# 월 주기성 (12개월 주기)\n","train['sin_month'] = np.sin(2 * np.pi * train['month'] / 12.0)\n","train['cos_month'] = np.cos(2 * np.pi * train['month'] / 12.0)\n","test['sin_month'] = np.sin(2 * np.pi * test['month'] / 12.0)\n","test['cos_month'] = np.cos(2 * np.pi * test['month'] / 12.0)\n","\n","# 요일 주기성 (7일 주기)\n","train['sin_dayofweek'] = np.sin(2 * np.pi * train['dow'] / 7.0)\n","train['cos_dayofweek'] = np.cos(2 * np.pi * train['dow'] / 7.0)\n","test['sin_dayofweek'] = np.sin(2 * np.pi * test['dow'] / 7.0)\n","test['cos_dayofweek'] = np.cos(2 * np.pi * test['dow'] / 7.0)\n","\n","# 날짜 복합 주기성\n","train['sin_date'] = np.sin(2 * np.pi * (train['month'] + train['day'] / 31) / 12)\n","train['cos_date'] = np.cos(2 * np.pi * (train['month'] + train['day'] / 31) / 12)\n","test['sin_date'] = np.sin(2 * np.pi * (test['month'] + test['day'] / 31) / 12)\n","test['cos_date'] = np.cos(2 * np.pi * (test['month'] + test['day'] / 31) / 12)\n","\n","# 연간 주기 특성\n","train['day_of_year'] = train['date_time'].dt.dayofyear.astype(float)\n","test['day_of_year'] = test['date_time'].dt.dayofyear.astype(float)\n","train['summer_sin'] = np.sin(2 * np.pi * train['day_of_year'] / 365.0)\n","train['summer_cos'] = np.cos(2 * np.pi * train['day_of_year'] / 365.0)\n","test['summer_sin'] = np.sin(2 * np.pi * test['day_of_year'] / 365.0)\n","test['summer_cos'] = np.cos(2 * np.pi * test['day_of_year'] / 365.0)"],"metadata":{"id":"byPzhUo-L7J9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train['date'] = pd.to_datetime(train['date'])\n","test['date'] = pd.to_datetime(test['date'])\n","\n","# 여름 기간 진행률 사이클릭 특성\n","year = train['date'].dt.year.iloc[0]\n","summer_start = pd.to_datetime(f\"{year}-06-01\")\n","summer_end = pd.to_datetime(f\"{year}-08-31\")\n","train['day_of_summer'] = (train['date'] - summer_start).dt.days.clip(lower=0)\n","test['day_of_summer'] = (test['date'] - summer_start).dt.days.clip(lower=0)\n","total_summer_days = (summer_end - summer_start).days + 1\n","train['summer_progress_sin'] = np.sin(2 * np.pi * train['day_of_summer'] / total_summer_days)\n","train['summer_progress_cos'] = np.cos(2 * np.pi * train['day_of_summer'] / total_summer_days)\n","test['summer_progress_sin'] = np.sin(2 * np.pi * test['day_of_summer'] / total_summer_days)\n","test['summer_progress_cos'] = np.cos(2 * np.pi * test['day_of_summer'] / total_summer_days)\n","\n","# 전일(Previous-day) 일별 온도 통계 ===\n","def attach_prevday_temp_features(train: pd.DataFrame, test: pd.DataFrame):\n","    # 1) 일별 요약\n","    tmp = pd.concat(\n","        [train[['building_number','date','temp']],\n","         test[['building_number','date','temp']]],\n","        axis=0, ignore_index=True\n","    )\n","    daily = (tmp.groupby(['building_number','date'])['temp']\n","               .agg(['max','mean','min'])\n","               .rename(columns={'max':'max_temp','mean':'mean_temp','min':'min_temp'})\n","             )\n","\n","    # 2) 건물별 날짜순 전일 시프트\n","    daily = daily.sort_index()\n","    prev = daily.groupby(level=0)[['max_temp','mean_temp','min_temp']].shift(1)\n","    prev = prev.rename(columns={\n","        'max_temp':'prevday_max_temperature',\n","        'mean_temp':'prevday_mean_temperature',\n","        'min_temp':'prevday_min_temperature'\n","    })\n","\n","    # 3) 전일 일교차\n","    prev['prevday_temperature_range'] = (\n","        prev['prevday_max_temperature'] - prev['prevday_min_temperature']\n","    )\n","\n","    # 4) merge\n","    prev = prev.reset_index()\n","    train_out = train.merge(prev, on=['building_number','date'], how='left')\n","    test_out  = test.merge(prev,  on=['building_number','date'], how='left')\n","    return train_out, test_out\n","\n","train, test = attach_prevday_temp_features(train, test)"],"metadata":{"id":"vrruqfWMyeKA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 냉방면적 비율\n","train['cooling_ratio'] = train['cooling_area'] / train['total_area']\n","train['cooling_ratio'] = train['cooling_ratio'].fillna(0)\n","test['cooling_ratio'] = test['cooling_area'] / test['total_area']\n","test['cooling_ratio'] = test['cooling_ratio'].fillna(0)"],"metadata":{"id":"jN14KgoHqlsJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 기상 지표 특성 생성 (THI: 온습도지수, WC: 체감온도, CDH: 불쾌지수)\n","def calc_THI(temp, hum):\n","    # 온습도지수 (Temperature-Humidity Index)\n","    return (1.8 * temp + 32) - (0.55 - 0.0055 * hum) * (1.8 * temp - 26.8)\n","\n","def calc_discomfort_index(temp, hum):\n","    # 불쾌지수 (Discomfort Index)\n","    return 0.81 * temp + 0.01 * hum * (0.99 * temp - 14.3) + 46.3\n","\n","def calc_heat_index(temp, hum):\n","    \"\"\"열지수 (Heat Index) - 여름철 체감온도\"\"\"\n","    # 화씨 변환\n","    temp_f = temp * 9/5 + 32\n","    hi = -42.379 + 2.04901523 * temp_f + 10.14333127 * hum\n","    hi += -0.22475541 * temp_f * hum - 6.83783e-3 * temp_f**2\n","    hi += -5.481717e-2 * hum**2 + 1.22874e-3 * temp_f**2 * hum\n","    hi += 8.5282e-4 * temp_f * hum**2 - 1.99e-6 * temp_f**2 * hum**2\n","    # 섭씨 변환\n","    return (hi - 32) * 5/9\n","\n","train['THI'] = calc_THI(train['temp'], train['hum'])\n","train['CDH'] = calc_discomfort_index(train['temp'], train['hum'])\n","train['HI'] = calc_heat_index(train['temp'], train['hum'])\n","test['THI'] = calc_THI(test['temp'], test['hum'])\n","test['CDH'] = calc_discomfort_index(test['temp'], test['hum'])\n","test['HI'] = calc_heat_index(test['temp'], test['hum'])\n"],"metadata":{"id":"lU1HUsZ1Mgx8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 휴일 처리\n","official_holidays = ['2024-06-06', '2024-08-15']  # 공식 공휴일\n","train['holiday'] = (\n","    (train['dow'] >= 5) |\n","    (train['date'].dt.strftime('%Y-%m-%d').isin(official_holidays))\n",").astype(int)\n","test['holiday'] = (\n","    (test['dow'] >= 5) |\n","    (test['date'].dt.strftime('%Y-%m-%d').isin(official_holidays))\n",").astype(int)"],"metadata":{"id":"xFVi7q8MNTcn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 각 폴드별 통계 피처 생성 (모든 데이터에 대해서 통계 피처를 생성해버리면 누수 발생)\n","\n","def _build_time_stats(df_sub):\n","    \"\"\"df_sub: '해당 폴드의 train 구간'만 들어온 부분 데이터프레임\"\"\"\n","    # building_number × hour × dow\n","    power_mean = (pd.pivot_table(df_sub, values='power_consumption',\n","                                 index=['building_number','hour','dow'], aggfunc=np.mean)\n","                    .reset_index()\n","                    .rename(columns={'power_consumption':'day_hour_mean'}))\n","    power_std  = (pd.pivot_table(df_sub, values='power_consumption',\n","                                 index=['building_number','hour','dow'], aggfunc=np.std)\n","                    .reset_index()\n","                    .rename(columns={'power_consumption':'day_hour_std'}))\n","    # building_number × hour\n","    power_hour_mean = (pd.pivot_table(df_sub, values='power_consumption',\n","                                      index=['building_number','hour'], aggfunc=np.mean)\n","                         .reset_index()\n","                         .rename(columns={'power_consumption':'hour_mean'}))\n","    power_hour_std  = (pd.pivot_table(df_sub, values='power_consumption',\n","                                      index=['building_number','hour'], aggfunc=np.std)\n","                         .reset_index()\n","                         .rename(columns={'power_consumption':'hour_std'}))\n","    return power_mean, power_std, power_hour_mean, power_hour_std\n","\n","\n","def attach_time_stats(df_target, stats):\n","    \"\"\"df_target: 머지 대상(폴드 train 또는 valid 또는 test)\n","       stats: _build_time_stats() 결과 튜플\n","    \"\"\"\n","    power_mean, power_std, power_hour_mean, power_hour_std = stats\n","    out = (df_target\n","           .merge(power_mean, on=['building_number','hour','dow'], how='left')\n","           .merge(power_std,  on=['building_number','hour','dow'], how='left')\n","           .merge(power_hour_mean, on=['building_number','hour'], how='left')\n","           .merge(power_hour_std,  on=['building_number','hour'], how='left'))\n","\n","    for c in ('day_hour_std','hour_std'):\n","        if c in out.columns:\n","            out[c] = out[c].fillna(0.0)\n","    return out\n"],"metadata":{"id":"beSo7TPTzlMA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":617},"id":"MfCItCifwBoN","executionInfo":{"status":"ok","timestamp":1756059453335,"user_tz":-540,"elapsed":108,"user":{"displayName":"송상현","userId":"05825752637342282552"}},"outputId":"3c66600e-fb78-421c-eea0-cb03d82c9d11"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["          num_date_time  building_number           date_time  temp  rainfall  \\\n","0         1_20240601 00                1 2024-06-01 00:00:00  18.3       0.0   \n","1         1_20240601 01                1 2024-06-01 01:00:00  18.3       0.0   \n","2         1_20240601 02                1 2024-06-01 02:00:00  18.1       0.0   \n","3         1_20240601 03                1 2024-06-01 03:00:00  18.0       0.0   \n","4         1_20240601 04                1 2024-06-01 04:00:00  17.8       0.0   \n","...                 ...              ...                 ...   ...       ...   \n","203995  100_20240824 19              100 2024-08-24 19:00:00  29.1       0.0   \n","203996  100_20240824 20              100 2024-08-24 20:00:00  28.6       0.0   \n","203997  100_20240824 21              100 2024-08-24 21:00:00  28.3       0.0   \n","203998  100_20240824 22              100 2024-08-24 22:00:00  28.0       0.0   \n","203999  100_20240824 23              100 2024-08-24 23:00:00  28.0       0.0   \n","\n","        wind   hum  sunshine  solar_radiation  power_consumption building  \\\n","0        2.6  82.0       0.0             0.00            5794.80    Hotel   \n","1        2.7  82.0       0.0             0.00            5591.85    Hotel   \n","2        2.6  80.0       0.0             0.00            5338.17    Hotel   \n","3        2.6  81.0       0.0             0.00            4554.42    Hotel   \n","4        1.3  81.0       0.0             0.00            3602.25    Hotel   \n","...      ...   ...       ...              ...                ...      ...   \n","203995   4.4  76.0       0.4             0.18            3276.00    Hotel   \n","203996   3.7  74.0       0.0             0.00            3197.52    Hotel   \n","203997   2.9  74.0       0.0             0.00            3006.60    Hotel   \n","203998   1.7  76.0       0.0             0.00            2649.72    Hotel   \n","203999   2.1  75.0       0.0             0.00            2929.32    Hotel   \n","\n","        total_area  cooling_area solar_power_capacity ess_capacity  \\\n","0         82912.71       77586.0                    -            -   \n","1         82912.71       77586.0                    -            -   \n","2         82912.71       77586.0                    -            -   \n","3         82912.71       77586.0                    -            -   \n","4         82912.71       77586.0                    -            -   \n","...            ...           ...                  ...          ...   \n","203995   162070.24      152943.0                    -            -   \n","203996   162070.24      152943.0                    -            -   \n","203997   162070.24      152943.0                    -            -   \n","203998   162070.24      152943.0                    -            -   \n","203999   162070.24      152943.0                    -            -   \n","\n","       pcs_capacity  solar_power_utility  ess_utility  power_consumption_log  \\\n","0                 -                    0            0               8.664889   \n","1                 -                    0            0               8.629244   \n","2                 -                    0            0               8.582825   \n","3                 -                    0            0               8.424073   \n","4                 -                    0            0               8.189591   \n","...             ...                  ...          ...                    ...   \n","203995            -                    0            0               8.094684   \n","203996            -                    0            0               8.070443   \n","203997            -                    0            0               8.008898   \n","203998            -                    0            0               7.882587   \n","203999            -                    0            0               7.982867   \n","\n","             date  dow  day  month  week  n_week  hour  sin_hour  cos_hour  \\\n","0      2024-06-01    5    1      6    22       1     0  0.000000  1.000000   \n","1      2024-06-01    5    1      6    22       1     1  0.258819  0.965926   \n","2      2024-06-01    5    1      6    22       1     2  0.500000  0.866025   \n","3      2024-06-01    5    1      6    22       1     3  0.707107  0.707107   \n","4      2024-06-01    5    1      6    22       1     4  0.866025  0.500000   \n","...           ...  ...  ...    ...   ...     ...   ...       ...       ...   \n","203995 2024-08-24    5   24      8    34       4    19 -0.965926  0.258819   \n","203996 2024-08-24    5   24      8    34       4    20 -0.866025  0.500000   \n","203997 2024-08-24    5   24      8    34       4    21 -0.707107  0.707107   \n","203998 2024-08-24    5   24      8    34       4    22 -0.500000  0.866025   \n","203999 2024-08-24    5   24      8    34       4    23 -0.258819  0.965926   \n","\n","           sin_month  cos_month  sin_dayofweek  cos_dayofweek  sin_date  \\\n","0       1.224647e-16       -1.0      -0.974928      -0.222521 -0.016889   \n","1       1.224647e-16       -1.0      -0.974928      -0.222521 -0.016889   \n","2       1.224647e-16       -1.0      -0.974928      -0.222521 -0.016889   \n","3       1.224647e-16       -1.0      -0.974928      -0.222521 -0.016889   \n","4       1.224647e-16       -1.0      -0.974928      -0.222521 -0.016889   \n","...              ...        ...            ...            ...       ...   \n","203995 -8.660254e-01       -0.5      -0.974928      -0.222521 -0.993019   \n","203996 -8.660254e-01       -0.5      -0.974928      -0.222521 -0.993019   \n","203997 -8.660254e-01       -0.5      -0.974928      -0.222521 -0.993019   \n","203998 -8.660254e-01       -0.5      -0.974928      -0.222521 -0.993019   \n","203999 -8.660254e-01       -0.5      -0.974928      -0.222521 -0.993019   \n","\n","        cos_date  day_of_year  summer_sin  summer_cos  day_of_summer  \\\n","0      -0.999857        153.0    0.486273   -0.873807              0   \n","1      -0.999857        153.0    0.486273   -0.873807              0   \n","2      -0.999857        153.0    0.486273   -0.873807              0   \n","3      -0.999857        153.0    0.486273   -0.873807              0   \n","4      -0.999857        153.0    0.486273   -0.873807              0   \n","...          ...          ...         ...         ...            ...   \n","203995 -0.117957        237.0   -0.806480   -0.591261             84   \n","203996 -0.117957        237.0   -0.806480   -0.591261             84   \n","203997 -0.117957        237.0   -0.806480   -0.591261             84   \n","203998 -0.117957        237.0   -0.806480   -0.591261             84   \n","203999 -0.117957        237.0   -0.806480   -0.591261             84   \n","\n","        summer_progress_sin  summer_progress_cos  prevday_max_temperature  \\\n","0                  0.000000             1.000000                      NaN   \n","1                  0.000000             1.000000                      NaN   \n","2                  0.000000             1.000000                      NaN   \n","3                  0.000000             1.000000                      NaN   \n","4                  0.000000             1.000000                      NaN   \n","...                     ...                  ...                      ...   \n","203995            -0.519584             0.854419                     32.1   \n","203996            -0.519584             0.854419                     32.1   \n","203997            -0.519584             0.854419                     32.1   \n","203998            -0.519584             0.854419                     32.1   \n","203999            -0.519584             0.854419                     32.1   \n","\n","        prevday_mean_temperature  prevday_min_temperature  \\\n","0                            NaN                      NaN   \n","1                            NaN                      NaN   \n","2                            NaN                      NaN   \n","3                            NaN                      NaN   \n","4                            NaN                      NaN   \n","...                          ...                      ...   \n","203995                 29.266667                     26.9   \n","203996                 29.266667                     26.9   \n","203997                 29.266667                     26.9   \n","203998                 29.266667                     26.9   \n","203999                 29.266667                     26.9   \n","\n","        prevday_temperature_range  cooling_ratio       THI       CDH  \\\n","0                             NaN       0.935755  64.33214  64.25294   \n","1                             NaN       0.935755  64.33214  64.25294   \n","2                             NaN       0.935755  63.94420  63.85620   \n","3                             NaN       0.935755  63.81480  63.73120   \n","4                             NaN       0.935755  63.49242  63.40882   \n","...                           ...            ...       ...       ...   \n","203995                        5.2       0.943683  81.00344  80.89784   \n","203996                        5.2       0.943683  79.95076  79.83636   \n","203997                        5.2       0.943683  79.48798  79.37358   \n","203998                        5.2       0.943683  79.28480  79.17920   \n","203999                        5.2       0.943683  79.15500  79.04500   \n","\n","               HI  holiday  \n","0       20.578330        1  \n","1       20.578330        1  \n","2       21.231987        1  \n","3       20.960120        1  \n","4       21.026653        1  \n","...           ...      ...  \n","203995  34.151872        1  \n","203996  32.550503        1  \n","203997  31.870187        1  \n","203998  31.500110        1  \n","203999  31.355768        1  \n","\n","[204000 rows x 49 columns]"],"text/html":["\n","  <div id=\"df-4ec97329-b28a-4376-a8c6-15865f8ed320\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>num_date_time</th>\n","      <th>building_number</th>\n","      <th>date_time</th>\n","      <th>temp</th>\n","      <th>rainfall</th>\n","      <th>wind</th>\n","      <th>hum</th>\n","      <th>sunshine</th>\n","      <th>solar_radiation</th>\n","      <th>power_consumption</th>\n","      <th>building</th>\n","      <th>total_area</th>\n","      <th>cooling_area</th>\n","      <th>solar_power_capacity</th>\n","      <th>ess_capacity</th>\n","      <th>pcs_capacity</th>\n","      <th>solar_power_utility</th>\n","      <th>ess_utility</th>\n","      <th>power_consumption_log</th>\n","      <th>date</th>\n","      <th>dow</th>\n","      <th>day</th>\n","      <th>month</th>\n","      <th>week</th>\n","      <th>n_week</th>\n","      <th>hour</th>\n","      <th>sin_hour</th>\n","      <th>cos_hour</th>\n","      <th>sin_month</th>\n","      <th>cos_month</th>\n","      <th>sin_dayofweek</th>\n","      <th>cos_dayofweek</th>\n","      <th>sin_date</th>\n","      <th>cos_date</th>\n","      <th>day_of_year</th>\n","      <th>summer_sin</th>\n","      <th>summer_cos</th>\n","      <th>day_of_summer</th>\n","      <th>summer_progress_sin</th>\n","      <th>summer_progress_cos</th>\n","      <th>prevday_max_temperature</th>\n","      <th>prevday_mean_temperature</th>\n","      <th>prevday_min_temperature</th>\n","      <th>prevday_temperature_range</th>\n","      <th>cooling_ratio</th>\n","      <th>THI</th>\n","      <th>CDH</th>\n","      <th>HI</th>\n","      <th>holiday</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1_20240601 00</td>\n","      <td>1</td>\n","      <td>2024-06-01 00:00:00</td>\n","      <td>18.3</td>\n","      <td>0.0</td>\n","      <td>2.6</td>\n","      <td>82.0</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>5794.80</td>\n","      <td>Hotel</td>\n","      <td>82912.71</td>\n","      <td>77586.0</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>8.664889</td>\n","      <td>2024-06-01</td>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>22</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>1.224647e-16</td>\n","      <td>-1.0</td>\n","      <td>-0.974928</td>\n","      <td>-0.222521</td>\n","      <td>-0.016889</td>\n","      <td>-0.999857</td>\n","      <td>153.0</td>\n","      <td>0.486273</td>\n","      <td>-0.873807</td>\n","      <td>0</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.935755</td>\n","      <td>64.33214</td>\n","      <td>64.25294</td>\n","      <td>20.578330</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1_20240601 01</td>\n","      <td>1</td>\n","      <td>2024-06-01 01:00:00</td>\n","      <td>18.3</td>\n","      <td>0.0</td>\n","      <td>2.7</td>\n","      <td>82.0</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>5591.85</td>\n","      <td>Hotel</td>\n","      <td>82912.71</td>\n","      <td>77586.0</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>8.629244</td>\n","      <td>2024-06-01</td>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>22</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.258819</td>\n","      <td>0.965926</td>\n","      <td>1.224647e-16</td>\n","      <td>-1.0</td>\n","      <td>-0.974928</td>\n","      <td>-0.222521</td>\n","      <td>-0.016889</td>\n","      <td>-0.999857</td>\n","      <td>153.0</td>\n","      <td>0.486273</td>\n","      <td>-0.873807</td>\n","      <td>0</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.935755</td>\n","      <td>64.33214</td>\n","      <td>64.25294</td>\n","      <td>20.578330</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1_20240601 02</td>\n","      <td>1</td>\n","      <td>2024-06-01 02:00:00</td>\n","      <td>18.1</td>\n","      <td>0.0</td>\n","      <td>2.6</td>\n","      <td>80.0</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>5338.17</td>\n","      <td>Hotel</td>\n","      <td>82912.71</td>\n","      <td>77586.0</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>8.582825</td>\n","      <td>2024-06-01</td>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>22</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0.500000</td>\n","      <td>0.866025</td>\n","      <td>1.224647e-16</td>\n","      <td>-1.0</td>\n","      <td>-0.974928</td>\n","      <td>-0.222521</td>\n","      <td>-0.016889</td>\n","      <td>-0.999857</td>\n","      <td>153.0</td>\n","      <td>0.486273</td>\n","      <td>-0.873807</td>\n","      <td>0</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.935755</td>\n","      <td>63.94420</td>\n","      <td>63.85620</td>\n","      <td>21.231987</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1_20240601 03</td>\n","      <td>1</td>\n","      <td>2024-06-01 03:00:00</td>\n","      <td>18.0</td>\n","      <td>0.0</td>\n","      <td>2.6</td>\n","      <td>81.0</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>4554.42</td>\n","      <td>Hotel</td>\n","      <td>82912.71</td>\n","      <td>77586.0</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>8.424073</td>\n","      <td>2024-06-01</td>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>22</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0.707107</td>\n","      <td>0.707107</td>\n","      <td>1.224647e-16</td>\n","      <td>-1.0</td>\n","      <td>-0.974928</td>\n","      <td>-0.222521</td>\n","      <td>-0.016889</td>\n","      <td>-0.999857</td>\n","      <td>153.0</td>\n","      <td>0.486273</td>\n","      <td>-0.873807</td>\n","      <td>0</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.935755</td>\n","      <td>63.81480</td>\n","      <td>63.73120</td>\n","      <td>20.960120</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1_20240601 04</td>\n","      <td>1</td>\n","      <td>2024-06-01 04:00:00</td>\n","      <td>17.8</td>\n","      <td>0.0</td>\n","      <td>1.3</td>\n","      <td>81.0</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>3602.25</td>\n","      <td>Hotel</td>\n","      <td>82912.71</td>\n","      <td>77586.0</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>8.189591</td>\n","      <td>2024-06-01</td>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>22</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>0.866025</td>\n","      <td>0.500000</td>\n","      <td>1.224647e-16</td>\n","      <td>-1.0</td>\n","      <td>-0.974928</td>\n","      <td>-0.222521</td>\n","      <td>-0.016889</td>\n","      <td>-0.999857</td>\n","      <td>153.0</td>\n","      <td>0.486273</td>\n","      <td>-0.873807</td>\n","      <td>0</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.935755</td>\n","      <td>63.49242</td>\n","      <td>63.40882</td>\n","      <td>21.026653</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>203995</th>\n","      <td>100_20240824 19</td>\n","      <td>100</td>\n","      <td>2024-08-24 19:00:00</td>\n","      <td>29.1</td>\n","      <td>0.0</td>\n","      <td>4.4</td>\n","      <td>76.0</td>\n","      <td>0.4</td>\n","      <td>0.18</td>\n","      <td>3276.00</td>\n","      <td>Hotel</td>\n","      <td>162070.24</td>\n","      <td>152943.0</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>8.094684</td>\n","      <td>2024-08-24</td>\n","      <td>5</td>\n","      <td>24</td>\n","      <td>8</td>\n","      <td>34</td>\n","      <td>4</td>\n","      <td>19</td>\n","      <td>-0.965926</td>\n","      <td>0.258819</td>\n","      <td>-8.660254e-01</td>\n","      <td>-0.5</td>\n","      <td>-0.974928</td>\n","      <td>-0.222521</td>\n","      <td>-0.993019</td>\n","      <td>-0.117957</td>\n","      <td>237.0</td>\n","      <td>-0.806480</td>\n","      <td>-0.591261</td>\n","      <td>84</td>\n","      <td>-0.519584</td>\n","      <td>0.854419</td>\n","      <td>32.1</td>\n","      <td>29.266667</td>\n","      <td>26.9</td>\n","      <td>5.2</td>\n","      <td>0.943683</td>\n","      <td>81.00344</td>\n","      <td>80.89784</td>\n","      <td>34.151872</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>203996</th>\n","      <td>100_20240824 20</td>\n","      <td>100</td>\n","      <td>2024-08-24 20:00:00</td>\n","      <td>28.6</td>\n","      <td>0.0</td>\n","      <td>3.7</td>\n","      <td>74.0</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>3197.52</td>\n","      <td>Hotel</td>\n","      <td>162070.24</td>\n","      <td>152943.0</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>8.070443</td>\n","      <td>2024-08-24</td>\n","      <td>5</td>\n","      <td>24</td>\n","      <td>8</td>\n","      <td>34</td>\n","      <td>4</td>\n","      <td>20</td>\n","      <td>-0.866025</td>\n","      <td>0.500000</td>\n","      <td>-8.660254e-01</td>\n","      <td>-0.5</td>\n","      <td>-0.974928</td>\n","      <td>-0.222521</td>\n","      <td>-0.993019</td>\n","      <td>-0.117957</td>\n","      <td>237.0</td>\n","      <td>-0.806480</td>\n","      <td>-0.591261</td>\n","      <td>84</td>\n","      <td>-0.519584</td>\n","      <td>0.854419</td>\n","      <td>32.1</td>\n","      <td>29.266667</td>\n","      <td>26.9</td>\n","      <td>5.2</td>\n","      <td>0.943683</td>\n","      <td>79.95076</td>\n","      <td>79.83636</td>\n","      <td>32.550503</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>203997</th>\n","      <td>100_20240824 21</td>\n","      <td>100</td>\n","      <td>2024-08-24 21:00:00</td>\n","      <td>28.3</td>\n","      <td>0.0</td>\n","      <td>2.9</td>\n","      <td>74.0</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>3006.60</td>\n","      <td>Hotel</td>\n","      <td>162070.24</td>\n","      <td>152943.0</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>8.008898</td>\n","      <td>2024-08-24</td>\n","      <td>5</td>\n","      <td>24</td>\n","      <td>8</td>\n","      <td>34</td>\n","      <td>4</td>\n","      <td>21</td>\n","      <td>-0.707107</td>\n","      <td>0.707107</td>\n","      <td>-8.660254e-01</td>\n","      <td>-0.5</td>\n","      <td>-0.974928</td>\n","      <td>-0.222521</td>\n","      <td>-0.993019</td>\n","      <td>-0.117957</td>\n","      <td>237.0</td>\n","      <td>-0.806480</td>\n","      <td>-0.591261</td>\n","      <td>84</td>\n","      <td>-0.519584</td>\n","      <td>0.854419</td>\n","      <td>32.1</td>\n","      <td>29.266667</td>\n","      <td>26.9</td>\n","      <td>5.2</td>\n","      <td>0.943683</td>\n","      <td>79.48798</td>\n","      <td>79.37358</td>\n","      <td>31.870187</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>203998</th>\n","      <td>100_20240824 22</td>\n","      <td>100</td>\n","      <td>2024-08-24 22:00:00</td>\n","      <td>28.0</td>\n","      <td>0.0</td>\n","      <td>1.7</td>\n","      <td>76.0</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>2649.72</td>\n","      <td>Hotel</td>\n","      <td>162070.24</td>\n","      <td>152943.0</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>7.882587</td>\n","      <td>2024-08-24</td>\n","      <td>5</td>\n","      <td>24</td>\n","      <td>8</td>\n","      <td>34</td>\n","      <td>4</td>\n","      <td>22</td>\n","      <td>-0.500000</td>\n","      <td>0.866025</td>\n","      <td>-8.660254e-01</td>\n","      <td>-0.5</td>\n","      <td>-0.974928</td>\n","      <td>-0.222521</td>\n","      <td>-0.993019</td>\n","      <td>-0.117957</td>\n","      <td>237.0</td>\n","      <td>-0.806480</td>\n","      <td>-0.591261</td>\n","      <td>84</td>\n","      <td>-0.519584</td>\n","      <td>0.854419</td>\n","      <td>32.1</td>\n","      <td>29.266667</td>\n","      <td>26.9</td>\n","      <td>5.2</td>\n","      <td>0.943683</td>\n","      <td>79.28480</td>\n","      <td>79.17920</td>\n","      <td>31.500110</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>203999</th>\n","      <td>100_20240824 23</td>\n","      <td>100</td>\n","      <td>2024-08-24 23:00:00</td>\n","      <td>28.0</td>\n","      <td>0.0</td>\n","      <td>2.1</td>\n","      <td>75.0</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>2929.32</td>\n","      <td>Hotel</td>\n","      <td>162070.24</td>\n","      <td>152943.0</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>7.982867</td>\n","      <td>2024-08-24</td>\n","      <td>5</td>\n","      <td>24</td>\n","      <td>8</td>\n","      <td>34</td>\n","      <td>4</td>\n","      <td>23</td>\n","      <td>-0.258819</td>\n","      <td>0.965926</td>\n","      <td>-8.660254e-01</td>\n","      <td>-0.5</td>\n","      <td>-0.974928</td>\n","      <td>-0.222521</td>\n","      <td>-0.993019</td>\n","      <td>-0.117957</td>\n","      <td>237.0</td>\n","      <td>-0.806480</td>\n","      <td>-0.591261</td>\n","      <td>84</td>\n","      <td>-0.519584</td>\n","      <td>0.854419</td>\n","      <td>32.1</td>\n","      <td>29.266667</td>\n","      <td>26.9</td>\n","      <td>5.2</td>\n","      <td>0.943683</td>\n","      <td>79.15500</td>\n","      <td>79.04500</td>\n","      <td>31.355768</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>204000 rows × 49 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4ec97329-b28a-4376-a8c6-15865f8ed320')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-4ec97329-b28a-4376-a8c6-15865f8ed320 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-4ec97329-b28a-4376-a8c6-15865f8ed320');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-a21c51f2-640f-45b9-995e-b992e4968bb5\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a21c51f2-640f-45b9-995e-b992e4968bb5')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-a21c51f2-640f-45b9-995e-b992e4968bb5 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_d6ab25f1-a59b-446d-823e-d1b453a934cc\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_d6ab25f1-a59b-446d-823e-d1b453a934cc button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('train');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"train"}},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["### 건물별 전력 시계열 확인"],"metadata":{"id":"Mb_toKylzSLd"}},{"cell_type":"code","source":["def plot_buildings_by_type_with_fold_mark(train, tscv):\n","    # 건물 유형 리스트 만들기\n","    building_types = train['building'].unique()\n","    # 각 건물번호에 해당하는 유형 딕셔너리 생성\n","    building_type_map = train[['building_number', 'building']].drop_duplicates().set_index('building_number')['building'].to_dict()\n","    # 건물 번호를 건물 유형별로 정렬\n","    sorted_building_nums = []\n","    for btype in building_types:\n","        nums = train[train['building'] == btype]['building_number'].unique()\n","        sorted_building_nums.extend(nums)\n","\n","    n_buildings = len(sorted_building_nums)\n","    plt.figure(figsize=(15, 4 * n_buildings))\n","\n","    # 각 건물마다 시각화\n","    for i, bld_num in enumerate(sorted_building_nums, 1):\n","        plt.subplot(n_buildings, 1, i)\n","        bld_data = train[train['building_number'] == bld_num].sort_values('date_time')\n","        dates = bld_data['date_time']\n","        y = bld_data['power_consumption']\n","        btype = building_type_map[bld_num]\n","\n","        plt.plot(dates, y, label=f'Building {bld_num}', color='blue')\n","        plt.title(f'Building {bld_num} ({btype})', fontsize=11, loc='left')\n","        plt.xlabel('Date Time')\n","        plt.ylabel('Power Consumption')\n","        plt.xticks(rotation=45)\n","        plt.grid(alpha=0.3)\n","\n","        # TSCV fold마다 val 영역 마킹\n","        X = bld_data.reset_index(drop=True)\n","        n_samples = len(X)\n","        split_indices = []\n","        for fold, (train_idx, val_idx) in enumerate(tscv.split(X)):\n","            # val 시작~끝 horizontal line 마킹\n","            val_start = X['date_time'].iloc[val_idx[0]]\n","            val_end = X['date_time'].iloc[val_idx[-1]]\n","            plt.axvspan(val_start, val_end, color='red', alpha=0.10)\n","            # fold 번호 텍스트로 표시\n","            plt.text(val_start, max(y)*0.95, f'val {fold+1}', color='red', fontsize=8)\n","\n","    plt.suptitle('Power Consumption Time Series: 각 건물 유형별, fold 검증 마킹 포함', fontsize=17, y=1.01)\n","    plt.subplots_adjust(top=0.97, hspace=0.7)\n","    plt.show()\n","\n","tscv = TimeSeriesSplit(n_splits=5, test_size=24*7, gap=24)\n","plot_buildings_by_type_with_fold_mark(train, tscv)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1fVvCeL1QhA_hECeBwRAhoIiHpb_279vV"},"id":"ggVXkgxHzVVX","executionInfo":{"status":"ok","timestamp":1755870926869,"user_tz":-540,"elapsed":19950,"user":{"displayName":"송상현","userId":"05825752637342282552"}},"outputId":"a62a293d-34b1-4b00-de00-9d10f7e410bf"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["### 건물개별 학습"],"metadata":{"id":"KI6j0S04xgLl"}},{"cell_type":"code","source":["feature_cols = [\n","    # 기본 식별 정보\n","    'building_number',\n","\n","    # 기상 정보 (공통)\n","    'temp', 'rainfall', 'wind', 'hum',\n","\n","    # 시간 특성\n","    'dow', 'month', 'day', 'hour', 'week', 'n_week',\n","\n","    # 주기성, 사이클릭 인코딩\n","    'sin_hour', 'cos_hour',\n","    'sin_month', 'cos_month',\n","    'sin_dayofweek', 'cos_dayofweek',\n","    'sin_date', 'cos_date',\n","    'summer_sin', 'summer_cos',\n","    'summer_progress_sin', 'summer_progress_cos',\n","\n","    # 일별/건물별 온도 통계\n","    'prevday_max_temperature', 'prevday_min_temperature', 'prevday_mean_temperature', 'prevday_temperature_range',\n","\n","    # 기상지수\n","    'THI', 'CDH', 'HI',\n","\n","    # 휴일 특성 (간단한 주말/공휴일 플래그)\n","    'holiday',\n","\n","    # 건물 속성 (유형: 숫자코드로 변환, 면적 등)\n","    'total_area', 'cooling_area', 'cooling_ratio',\n","    'solar_power_utility', 'ess_utility',\n","\n","    # 통계 피처 (이름을 전처리에서 생성된 대로 일치)\n","    'day_hour_mean', 'day_hour_std',\n","    'hour_mean', 'hour_std'\n","]"],"metadata":{"id":"3e4HVk2nNzm4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def smape(y_true, y_pred):\n","    \"\"\"개선된 sMAPE 계산 함수\"\"\"\n","    y_true = np.maximum(y_true, 0)\n","    y_pred = np.maximum(y_pred, 0)\n","\n","    denominator = np.abs(y_true) + np.abs(y_pred)\n","    mask = denominator > 1e-8\n","\n","    if np.sum(mask) == 0:\n","        return 0.0\n","\n","    numerator = 2 * np.abs(y_pred - y_true)[mask]\n","    return 100 * np.mean(numerator / denominator[mask])\n","\n","\n","def smape_eval(y_pred, y_true):\n","    \"\"\"XGBoost용 sMAPE 평가 함수 (log1p 변환 대응)\"\"\"\n","    y_true_val = y_true.get_label()\n","\n","    # log1p 변환의 역함수는 expm1 (exp(x) - 1)\n","    y_true_orig = np.expm1(y_true_val)\n","    y_pred_orig = np.expm1(y_pred)\n","\n","    # 전력 소비량 음수 방지\n","    y_true_orig = np.maximum(y_true_orig, 0)\n","    y_pred_orig = np.maximum(y_pred_orig, 0)\n","\n","    smape_score = smape(y_true_orig, y_pred_orig)\n","    return 'smape', smape_score\n","\n","\n","def weighted_mse(alpha=3.0):\n","    \"\"\"가중 MSE 목적함수 (과소예측 페널티)\"\"\"\n","    def objective(y_pred, y_true):\n","        y_true_val = y_true.get_label()\n","        residual = y_true_val - y_pred\n","\n","        # 과소예측(residual > 0)에 더 큰 페널티\n","        weights = np.where(residual > 0, alpha, 1.0)\n","\n","        # 수치적 안정성을 위한 가중치 클리핑\n","        weights = np.clip(weights, 0.1, 10.0)\n","\n","        grad = -2 * weights * residual\n","        hess = 2 * weights\n","\n","        return grad, hess\n","    return objective\n"],"metadata":{"id":"_faOz1LNWsBH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["PROJECT_PATH = '/content/drive/MyDrive/power_prediction_project'\n","MODEL_PATH_INDIVIDUAL = f'{PROJECT_PATH}/models/individual_buildings'\n","\n","os.makedirs(PROJECT_PATH, exist_ok=True)\n","os.makedirs(MODEL_PATH_INDIVIDUAL, exist_ok=True)\n","\n","\n","print(f\"✅ 프로젝트 경로: {PROJECT_PATH}\")\n","print(f\"✅ 건물유형별 모델 경로: {MODEL_PATH_INDIVIDUAL}\")\n","\n","# 작업 디렉토리 변경\n","%cd {PROJECT_PATH}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BCmbsOF3Ws4J","executionInfo":{"status":"ok","timestamp":1756059460729,"user_tz":-540,"elapsed":456,"user":{"displayName":"송상현","userId":"05825752637342282552"}},"outputId":"4bcdd713-43a3-4497-f4bd-7e843e0c0cc0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ 프로젝트 경로: /content/drive/MyDrive/power_prediction_project\n","✅ 건물유형별 모델 경로: /content/drive/MyDrive/power_prediction_project/models/individual_buildings\n","/content/drive/MyDrive/power_prediction_project\n"]}]},{"cell_type":"code","source":["#========================================\n","# Utility for model check & load\n","#========================================\n","def check_building_completion(building_num, n_folds=5):\n","    \"\"\"해당 건물의 모든 fold 모델이 존재하는지 확인\"\"\"\n","    safe_building_name = str(building_num).replace(' ', '_').replace('/', '_')\n","    for fold in range(n_folds):\n","        json_path = f\"{MODEL_PATH_INDIVIDUAL}/xgb_building_{safe_building_name}_fold{fold}.json\"\n","        pkl_path = f\"{MODEL_PATH_INDIVIDUAL}/xgb_building_{safe_building_name}_fold{fold}.pkl\"\n","        if not (os.path.exists(json_path) or os.path.exists(pkl_path)):\n","            return False, fold  # 해당 fold부터 재시작\n","    return True, -1\n","\n","\n","def load_existing_models(building_num, n_folds=5):\n","    \"\"\"저장된 모델들 로드\"\"\"\n","    safe_building_name = str(building_num).replace(' ', '_').replace('/', '_')\n","    models = []\n","    for fold in range(n_folds):\n","        json_path = f\"{MODEL_PATH_INDIVIDUAL}/xgb_building_{safe_building_name}_fold{fold}.json\"\n","        pkl_path = f\"{MODEL_PATH_INDIVIDUAL}/xgb_building_{safe_building_name}_fold{fold}.pkl\"\n","        if os.path.exists(json_path):\n","            model = xgb.Booster()\n","            model.load_model(json_path)\n","            models.append(model)\n","        elif os.path.exists(pkl_path):\n","            with open(pkl_path, 'rb') as f:\n","                model = pickle.load(f)\n","            models.append(model)\n","        else:\n","            raise FileNotFoundError(f\"모델 파일이 없습니다: {json_path}, {pkl_path}\")\n","    return models\n","\n","\n","def regenerate_oof_and_cv_results(building_data, models, feature_cols, tscv):\n","    \"\"\"저장된 모델로 OOF 및 CV 결과 재계산\"\"\"\n","    n_samples = len(building_data)\n","    oof_preds = np.zeros(n_samples)\n","    fold_results = []\n","\n","    for fold, (train_idx, val_idx) in enumerate(tscv.split(building_data)):\n","        tr_df = building_data.iloc[train_idx].copy()\n","        va_df = building_data.iloc[val_idx].copy()\n","        stats = _build_time_stats(tr_df)\n","        va_df = attach_time_stats(va_df, stats)\n","        X_val_cv = va_df[feature_cols].copy().drop(columns=['building_number'], errors='ignore')\n","        dvalid = xgb.DMatrix(X_val_cv, feature_names=X_val_cv.columns.tolist())\n","\n","        # OOF 예측\n","        val_pred_log = models[fold].predict(dvalid)\n","        val_pred = np.expm1(val_pred_log)\n","        oof_preds[val_idx] = val_pred\n","\n","        # SMAPE 계산 및 CV 결과 저장\n","        y_val = building_data.iloc[val_idx]['power_consumption'].values\n","        smape_score = smape(y_val, val_pred)\n","        rmse_score = np.sqrt(np.mean((val_pred - y_val) ** 2))\n","\n","        fold_results.append({\n","            'fold': fold + 1,\n","            'smape': smape_score,\n","            'rmse': rmse_score,\n","            'val_size': len(val_idx),\n","            'building_type': building_data['building'].iloc[0]\n","        })\n","\n","    return oof_preds, fold_results\n","\n","\n","#========================================\n","# 최근성 가중 smape 함수 그대로 유지\n","def recent_weighted_score(fold_smape_list, decay=0.5):\n","    K = len(fold_smape_list)\n","    weights = [decay ** (K - 1 - i) for i in range(K)]\n","    weights = np.array(weights) / sum(weights)\n","    weighted_mean = np.sum(weights * np.array(fold_smape_list))\n","    weighted_std = np.sqrt(np.sum(weights * (np.array(fold_smape_list) - weighted_mean) ** 2))\n","    lambda_penalty = 1.0\n","    score = weighted_mean + lambda_penalty * weighted_std\n","    return score, weighted_mean, weighted_std, weights\n"],"metadata":{"id":"Bal7mbw2k4z5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#========================================\n","# 하이퍼파라미터 및 설정\n","individual_building_params = {\n","    \"max_depth\": 10,\n","    \"learning_rate\": 0.005,\n","    \"subsample\": 0.8,\n","    \"colsample_bytree\": 0.6,\n","    \"min_child_weight\": 4,\n","    \"gamma\": 0.05,\n","    \"lambda\": 1.2,\n","    \"alpha\": 0.4,\n","    \"tree_method\": \"hist\",\n","    \"device\": \"cuda\",\n","    \"max_bin\": 256,\n","    \"verbosity\": 0,\n","    \"random_state\": RANDOM_SEED,\n","    \"eval_metric\": \"mae\",\n","}\n","\n","N_BOOST_ROUND = 8000\n","ES_ROUNDS = 600\n","\n","print(f\"\\n건물별 개별 모델 학습/복원 시작... (총 {len(train['building_number'].unique())}개 건물)\")\n","\n","tscv = TimeSeriesSplit(n_splits=5, test_size=24*7, gap=24)\n","individual_models = {}\n","individual_cv_results = {}\n","oof_preds_per_building = {}\n","\n","for bld_idx, building_num in enumerate(train['building_number'].unique()):\n","    building_data = train[train['building_number'] == building_num].copy()\n","    building_type = building_data['building'].iloc[0]\n","    building_data = building_data.sort_values('date_time').reset_index(drop=True)\n","    n_samples = len(building_data)\n","\n","    if n_samples < 500:\n","        print(f\"  데이터가 부족합니다 ({n_samples}행). 건물 개별 학습 스킵.\")\n","        continue\n","\n","    is_complete, resume_fold = check_building_completion(building_num)\n","    fold_results = []\n","    safe_building_name = str(building_num).replace(' ', '_').replace('/', '_')\n","\n","    if is_complete:\n","        print(f\"  Building {building_num} ({building_type}): 모델 모두 존재, OOF 및 CV 결과 재계산\")\n","        models = load_existing_models(building_num)\n","        individual_models[building_num] = models\n","        # ✅ 수정: OOF와 CV 결과를 함께 계산\n","        oof_preds, fold_results = regenerate_oof_and_cv_results(building_data, models, feature_cols, tscv)\n","        oof_preds_per_building[building_num] = oof_preds\n","        individual_cv_results[building_num] = fold_results  # ✅ 추가: CV 결과 저장\n","\n","        # CV 결과 요약 출력\n","        smape_values = [r['smape'] for r in fold_results]\n","        print(f\"    → 복원된 CV SMAPE: {' → '.join([f'{s:.3f}' for s in smape_values])} (평균: {np.mean(smape_values):.3f})\")\n","        continue\n","\n","    print(f\"  Building {building_num} ({building_type}): fold {resume_fold}부터 학습 재개\")\n","    models = []\n","    oof_preds = np.zeros(n_samples)  # 전체 fold oof\n","\n","    for fold, (train_idx, val_idx) in enumerate(tscv.split(building_data)):\n","        if fold < resume_fold:\n","            # 이미 저장된 모델 불러오기\n","            model = None\n","            json_path = f\"{MODEL_PATH_INDIVIDUAL}/xgb_building_{safe_building_name}_fold{fold}.json\"\n","            pkl_path = f\"{MODEL_PATH_INDIVIDUAL}/xgb_building_{safe_building_name}_fold{fold}.pkl\"\n","            if os.path.exists(json_path):\n","                model = xgb.Booster()\n","                model.load_model(json_path)\n","            elif os.path.exists(pkl_path):\n","                with open(pkl_path, 'rb') as f:\n","                    model = pickle.load(f)\n","            if model is not None:\n","                models.append(model)\n","                print(f\"    Fold {fold+1}: 이미 저장된 모델 사용\")\n","            else:\n","                raise FileNotFoundError(f\"Fold {fold} 모델 파일이 없습니다.\")\n","            continue\n","\n","        print(f\"    Fold {fold+1}/{tscv.n_splits} 학습 중... \", end=\"\")\n","        tr_df = building_data.iloc[train_idx].copy()\n","        va_df = building_data.iloc[val_idx].copy()\n","        stats = _build_time_stats(tr_df)\n","        tr_df = attach_time_stats(tr_df, stats)\n","        va_df = attach_time_stats(va_df, stats)\n","        X_train_cv = tr_df[feature_cols].copy().drop(columns=['building_number'], errors='ignore')\n","        X_val_cv = va_df[feature_cols].copy().drop(columns=['building_number'], errors='ignore')\n","        y_train_cv = tr_df['power_consumption_log']\n","        y_val_cv = va_df['power_consumption_log']\n","\n","        dtrain = xgb.DMatrix(X_train_cv, label=y_train_cv, feature_names=X_train_cv.columns.tolist())\n","        dvalid = xgb.DMatrix(X_val_cv, label=y_val_cv, feature_names=X_train_cv.columns.tolist())\n","        evals_result = {}\n","        model = xgb.train(\n","            params=individual_building_params,\n","            dtrain=dtrain,\n","            num_boost_round=N_BOOST_ROUND,\n","            evals=[(dtrain, \"train\"), (dvalid, \"valid\")],\n","            obj=weighted_mse(alpha=3.0),\n","            custom_metric=smape_eval,\n","            early_stopping_rounds=ES_ROUNDS,\n","            verbose_eval=False,\n","            evals_result=evals_result\n","        )\n","        models.append(model)\n","        val_pred_log = model.predict(dvalid, iteration_range=(0, model.best_iteration+1))\n","        val_pred = np.expm1(val_pred_log)\n","        oof_preds[val_idx] = val_pred\n","        y_val = np.expm1(y_val_cv)\n","        smape_score = smape(y_val, val_pred)\n","        rmse_score = np.sqrt(np.mean((val_pred - y_val) ** 2))\n","        fold_results.append({\n","            'fold': fold + 1,\n","            'smape': smape_score,\n","            'rmse': rmse_score,\n","            'best_iteration': model.best_iteration,\n","            'train_size': len(train_idx),\n","            'val_size': len(val_idx),\n","            'train_mae_final': evals_result['train']['mae'][model.best_iteration],\n","            'valid_mae_final': evals_result['valid']['mae'][model.best_iteration],\n","            'train_smape_final': evals_result['train']['smape'][model.best_iteration],\n","            'valid_smape_final': evals_result['valid']['smape'][model.best_iteration],\n","            'train_val_gap': evals_result['valid']['mae'][model.best_iteration] - evals_result['train']['mae'][model.best_iteration],\n","            'building_type': building_type\n","        })\n","        print(f\"SMAPE: {smape_score:.4f}, best_iter: {model.best_iteration}, \"\n","              f\"train_mae: {evals_result['train']['mae'][model.best_iteration]:.4f}, \"\n","              f\"valid_mae: {evals_result['valid']['mae'][model.best_iteration]:.4f}\")\n","        # 모델 저장\n","        model_file = f\"{MODEL_PATH_INDIVIDUAL}/xgb_building_{safe_building_name}_fold{fold}.json\"\n","        try:\n","            model.save_model(model_file)\n","        except Exception as e:\n","            print(f\"\\n    JSON 저장 실패 (Fold {fold}), Pickle로 저장: {e}\")\n","            pickle_file = f\"{MODEL_PATH_INDIVIDUAL}/xgb_building_{safe_building_name}_fold{fold}.pkl\"\n","            with open(pickle_file, 'wb') as f:\n","                pickle.dump(model, f)\n","\n","    # fold loop 종료 후 결과 저장\n","    individual_models[building_num] = models\n","    oof_preds_per_building[building_num] = oof_preds\n","    individual_cv_results[building_num] = fold_results\n","\n","print(f\"\\n=== 건물별 개별 모델 학습/복원 완료 ===\")\n","\n","#========================================\n","# 디버깅용 완료 상태 확인 및 요약\n","#========================================\n","print(f\"\\n=== 개별 모델 학습/복원 완료 상태 확인 ===\")\n","print(f\"총 학습 대상 건물 수: {len(train['building_number'].unique())}\")\n","print(f\"실제 학습 완료 건물 수: {len(individual_models)}\")\n","print(f\"OOF 예측값 저장된 건물 수: {len(oof_preds_per_building)}\")\n","print(f\"CV 결과 저장된 건물 수: {len(individual_cv_results)}\")\n","\n","# 각 딕셔너리의 키가 일치하는지 확인\n","models_keys = set(individual_models.keys())\n","oof_keys = set(oof_preds_per_building.keys())\n","cv_keys = set(individual_cv_results.keys())\n","\n","print(f\"\\n=== 데이터 일관성 확인 ===\")\n","if models_keys == oof_keys == cv_keys:\n","    print(\"✅ 모든 딕셔너리의 건물 키가 일치합니다\")\n","else:\n","    print(\"❌ 딕셔너리 간 건물 키 불일치 발견:\")\n","    print(f\"  models만 있는 키: {models_keys - oof_keys - cv_keys}\")\n","    print(f\"  oof만 있는 키: {oof_keys - models_keys - cv_keys}\")\n","    print(f\"  cv만 있는 키: {cv_keys - models_keys - oof_keys}\")\n","\n","# CV 결과 샘플 확인\n","print(f\"\\n=== CV 결과 샘플 확인 ===\")\n","sample_buildings = list(individual_cv_results.keys())[:3]\n","for building_num in sample_buildings:\n","    results = individual_cv_results[building_num]\n","    if results:\n","        smape_values = [r['smape'] for r in results]\n","        print(f\"건물 {building_num}: {len(results)}개 fold, SMAPE = {smape_values}\")\n","    else:\n","        print(f\"건물 {building_num}: CV 결과 없음\")\n","\n","# 전체 성능 요약\n","print(f\"\\n=== 전체 개별 모델 성능 요약 ===\")\n","all_smapes = []\n","building_type_counts = {}\n","\n","for building_num, results in individual_cv_results.items():\n","    if results:\n","        building_type = results[0]['building_type']\n","        smape_values = [r['smape'] for r in results]\n","        avg_smape = np.mean(smape_values)\n","        all_smapes.append(avg_smape)\n","\n","        if building_type not in building_type_counts:\n","            building_type_counts[building_type] = []\n","        building_type_counts[building_type].append(avg_smape)\n","\n","if all_smapes:\n","    print(f\"전체 개별 모델 SMAPE: 평균 {np.mean(all_smapes):.3f} ± {np.std(all_smapes):.3f}\")\n","    print(f\"                    범위: {np.min(all_smapes):.3f} ~ {np.max(all_smapes):.3f}\")\n","\n","    print(f\"\\n=== 건물 유형별 개별 모델 성능 ===\")\n","    for building_type, smapes in building_type_counts.items():\n","        print(f\"{building_type:>15}: {len(smapes):>2}개 건물, 평균 SMAPE {np.mean(smapes):.3f} ± {np.std(smapes):.3f}\")\n","\n","print(f\"\\n=== OOF 데이터 크기 확인 ===\")\n","oof_sizes = {building_num: len(oof_pred) for building_num, oof_pred in oof_preds_per_building.items()}\n","unique_sizes = set(oof_sizes.values())\n","print(f\"OOF 예측값 크기 분포: {dict(zip(*np.unique(list(oof_sizes.values()), return_counts=True)[::-1]))}\")\n","if len(unique_sizes) == 1:\n","    print(f\"✅ 모든 건물의 OOF 크기가 동일합니다: {list(unique_sizes)[0]}개\")\n","else:\n","    print(f\"❌ 건물별 OOF 크기가 다릅니다: {unique_sizes}\")\n","\n","print(f\"\\n=== 개별 모델 준비 완료 ===\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FM0fL0BlKIRy","executionInfo":{"status":"ok","timestamp":1756064202742,"user_tz":-540,"elapsed":106879,"user":{"displayName":"송상현","userId":"05825752637342282552"}},"outputId":"ed9b0b74-0e02-4321-a738-93177a109717"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","건물별 개별 모델 학습/복원 시작... (총 100개 건물)\n","  Building 1 (Hotel): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 12.017 → 8.981 → 9.040 → 8.852 → 9.991 (평균: 9.776)\n","  Building 2 (Commercial): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 5.383 → 7.231 → 5.916 → 7.032 → 5.506 (평균: 6.214)\n","  Building 3 (Hospital): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 4.686 → 3.107 → 3.095 → 4.570 → 4.614 (평균: 4.014)\n","  Building 4 (Hotel): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 5.951 → 5.382 → 4.936 → 5.035 → 5.860 (평균: 5.433)\n","  Building 5 (University): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 3.218 → 3.118 → 3.870 → 2.388 → 4.531 (평균: 3.425)\n","  Building 6 (Commercial): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 10.424 → 8.772 → 7.635 → 16.614 → 12.678 (평균: 11.224)\n","  Building 7 (Other Buildings): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 14.161 → 13.348 → 85.953 → 7.901 → 3.586 (평균: 24.990)\n","  Building 8 (University): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 8.152 → 16.346 → 9.497 → 12.862 → 10.347 (평균: 11.441)\n","  Building 9 (Hotel): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 6.056 → 18.901 → 6.263 → 4.822 → 6.711 (평균: 8.551)\n","  Building 10 (Hotel): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 5.321 → 19.230 → 5.833 → 6.129 → 33.745 (평균: 14.052)\n","  Building 11 (Apartment): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 14.825 → 7.720 → 6.572 → 4.268 → 4.474 (평균: 7.572)\n","  Building 12 (University): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 7.102 → 5.754 → 2.420 → 4.477 → 4.365 (평균: 4.824)\n","  Building 13 (Research Institute): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 5.838 → 3.836 → 5.371 → 11.087 → 7.784 (평균: 6.783)\n","  Building 14 (University): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 7.147 → 4.535 → 3.003 → 4.738 → 4.368 (평균: 4.758)\n","  Building 15 (Research Institute): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 6.960 → 4.670 → 4.245 → 7.487 → 7.998 (평균: 6.272)\n","  Building 16 (Commercial): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 3.605 → 2.904 → 4.467 → 7.226 → 5.124 (평균: 4.665)\n","  Building 17 (Hospital): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 9.146 → 5.196 → 3.360 → 4.535 → 3.202 (평균: 5.088)\n","  Building 18 (Department Store): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 4.307 → 6.428 → 5.530 → 4.502 → 5.312 (평균: 5.216)\n","  Building 19 (Department Store): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 28.684 → 6.127 → 7.148 → 7.503 → 13.655 (평균: 12.623)\n","  Building 20 (Commercial): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 1.705 → 1.591 → 1.447 → 2.550 → 2.644 (평균: 1.987)\n","  Building 21 (Hospital): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 5.143 → 2.877 → 2.240 → 4.343 → 2.756 (평균: 3.472)\n","  Building 22 (University): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 8.179 → 5.545 → 5.706 → 8.784 → 4.477 (평균: 6.538)\n","  Building 23 (Research Institute): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 18.974 → 10.070 → 12.397 → 31.493 → 27.333 (평균: 20.053)\n","  Building 24 (University): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 7.000 → 4.202 → 3.661 → 7.433 → 6.457 (평균: 5.750)\n","  Building 25 (Apartment): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 29.217 → 19.892 → 10.078 → 9.427 → 6.963 (평균: 15.115)\n","  Building 26 (Other Buildings): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 20.537 → 11.187 → 12.732 → 13.102 → 13.784 (평균: 14.269)\n","  Building 27 (Department Store): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 13.325 → 18.218 → 12.186 → 15.155 → 11.017 (평균: 13.980)\n","  Building 28 (Hotel): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 8.166 → 12.300 → 5.840 → 7.151 → 4.854 (평균: 7.662)\n","  Building 29 (Department Store): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 6.378 → 13.016 → 11.785 → 3.073 → 13.937 (평균: 9.638)\n","  Building 30 (IDC): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 0.913 → 1.465 → 2.108 → 1.014 → 0.452 (평균: 1.190)\n","  Building 31 (Apartment): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 8.217 → 7.215 → 8.504 → 3.812 → 4.365 (평균: 6.423)\n","  Building 32 (Department Store): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 15.358 → 17.897 → 6.192 → 13.671 → 12.819 (평균: 13.187)\n","  Building 33 (Public): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 11.873 → 9.248 → 10.464 → 9.376 → 14.635 (평균: 11.119)\n","  Building 34 (Department Store): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 5.517 → 3.324 → 3.655 → 3.730 → 2.601 (평균: 3.765)\n","  Building 35 (IDC): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 1.088 → 0.795 → 0.563 → 0.649 → 0.625 (평균: 0.744)\n","  Building 36 (IDC): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 2.119 → 0.728 → 0.586 → 0.909 → 0.679 (평균: 1.004)\n","  Building 37 (Research Institute): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 7.051 → 7.850 → 5.832 → 10.299 → 10.838 (평균: 8.374)\n","  Building 38 (Public): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 5.128 → 2.910 → 3.443 → 6.180 → 4.270 (평균: 4.386)\n","  Building 39 (Hospital): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 6.283 → 4.997 → 3.413 → 3.795 → 3.374 (평균: 4.372)\n","  Building 40 (Department Store): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 9.445 → 12.917 → 6.613 → 9.694 → 7.060 (평균: 9.146)\n","  Building 41 (Commercial): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 3.220 → 2.479 → 1.101 → 1.533 → 1.933 (평균: 2.053)\n","  Building 42 (Hospital): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 5.280 → 3.457 → 3.260 → 3.681 → 3.297 (평균: 3.795)\n","  Building 43 (IDC): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 2.510 → 1.593 → 1.677 → 3.134 → 3.547 (평균: 2.492)\n","  Building 44 (Hospital): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 6.039 → 5.057 → 2.742 → 3.775 → 5.343 (평균: 4.591)\n","  Building 45 (Department Store): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 29.143 → 8.307 → 5.574 → 3.908 → 7.897 (평균: 10.966)\n","  Building 46 (University): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 4.943 → 5.219 → 4.072 → 9.968 → 9.619 (평균: 6.764)\n","  Building 47 (Other Buildings): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 4.518 → 2.799 → 2.904 → 6.632 → 7.461 (평균: 4.863)\n","  Building 48 (Hospital): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 4.654 → 3.201 → 3.266 → 6.054 → 6.981 (평균: 4.831)\n","  Building 49 (Research Institute): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 6.220 → 5.658 → 4.491 → 13.605 → 16.212 (평균: 9.237)\n","  Building 50 (Public): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 5.362 → 6.453 → 6.002 → 8.264 → 9.398 (평균: 7.096)\n","  Building 51 (Commercial): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 1.829 → 1.336 → 1.033 → 1.362 → 0.953 (평균: 1.302)\n","  Building 52 (IDC): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 1.961 → 2.644 → 4.633 → 3.749 → 5.872 (평균: 3.772)\n","  Building 53 (Research Institute): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 5.055 → 5.577 → 5.251 → 5.230 → 9.700 (평균: 6.162)\n","  Building 54 (Department Store): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 9.652 → 15.315 → 15.433 → 9.518 → 18.617 (평균: 13.707)\n","  Building 55 (University): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 4.741 → 2.685 → 1.806 → 2.422 → 1.637 (평균: 2.658)\n","  Building 56 (Commercial): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 0.923 → 0.998 → 1.186 → 1.204 → 1.186 (평균: 1.100)\n","  Building 57 (IDC): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 2.809 → 2.227 → 1.259 → 0.984 → 0.788 (평균: 1.614)\n","  Building 58 (Other Buildings): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 6.765 → 5.654 → 5.151 → 4.915 → 5.341 (평균: 5.565)\n","  Building 59 (Department Store): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 18.569 → 14.224 → 18.216 → 15.897 → 11.132 (평균: 15.608)\n","  Building 60 (University): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 3.926 → 4.686 → 3.149 → 3.951 → 2.738 (평균: 3.690)\n","  Building 61 (Other Buildings): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 8.232 → 15.810 → 5.701 → 4.446 → 20.297 (평균: 10.897)\n","  Building 62 (Research Institute): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 4.834 → 2.893 → 2.429 → 4.545 → 3.591 (평균: 3.658)\n","  Building 63 (Department Store): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 11.761 → 14.976 → 7.618 → 13.631 → 12.725 (평균: 12.142)\n","  Building 64 (IDC): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 4.776 → 2.762 → 3.012 → 2.267 → 2.407 (평균: 3.045)\n","  Building 65 (Apartment): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 6.128 → 7.875 → 4.349 → 5.696 → 7.810 (평균: 6.371)\n","  Building 66 (Public): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 5.722 → 3.807 → 4.706 → 4.904 → 7.584 (평균: 5.344)\n","  Building 67 (IDC): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 20.163 → 56.466 → 3.022 → 2.476 → 2.002 (평균: 16.826)\n","  Building 68 (Public): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 6.934 → 27.461 → 8.911 → 10.403 → 12.557 (평균: 13.253)\n","  Building 69 (Other Buildings): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 2.936 → 2.448 → 3.163 → 3.152 → 3.574 (평균: 3.055)\n","  Building 70 (Apartment): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 15.751 → 13.273 → 4.803 → 6.920 → 3.983 (평균: 8.946)\n","  Building 71 (Apartment): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 14.796 → 7.465 → 5.349 → 4.150 → 5.355 (평균: 7.423)\n","  Building 72 (Public): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 7.594 → 8.979 → 5.981 → 9.839 → 9.207 (평균: 8.320)\n","  Building 73 (Department Store): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 7.191 → 7.632 → 6.729 → 5.829 → 5.789 (평균: 6.634)\n","  Building 74 (Department Store): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 6.359 → 8.822 → 6.199 → 7.391 → 6.230 (평균: 7.000)\n","  Building 75 (Hospital): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 4.566 → 4.658 → 4.316 → 2.103 → 3.209 (평균: 3.770)\n","  Building 76 (Commercial): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 7.572 → 1.405 → 8.973 → 1.969 → 1.398 (평균: 4.263)\n","  Building 77 (Hotel): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 17.011 → 12.330 → 10.608 → 7.292 → 14.561 (평균: 12.360)\n","  Building 78 (Other Buildings): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 14.205 → 6.982 → 6.378 → 4.168 → 4.571 (평균: 7.261)\n","  Building 79 (Department Store): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 6.759 → 8.843 → 5.373 → 4.295 → 12.084 (평균: 7.471)\n","  Building 80 (Public): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 18.645 → 10.224 → 13.630 → 7.367 → 6.128 (평균: 11.199)\n","  Building 81 (IDC): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 3.490 → 4.735 → 10.226 → 6.815 → 4.619 (평균: 5.977)\n","  Building 82 (Other Buildings): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 6.268 → 6.205 → 3.513 → 5.547 → 5.359 (평균: 5.378)\n","  Building 83 (Research Institute): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 3.477 → 2.483 → 2.160 → 3.106 → 2.969 (평균: 2.839)\n","  Building 84 (Hotel): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 5.581 → 6.886 → 3.250 → 4.492 → 5.112 (평균: 5.064)\n","  Building 85 (Apartment): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 6.256 → 10.769 → 5.452 → 7.597 → 6.553 (평균: 7.325)\n","  Building 86 (Commercial): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 3.369 → 3.405 → 3.417 → 7.504 → 11.061 (평균: 5.751)\n","  Building 87 (University): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 7.343 → 17.411 → 9.005 → 11.569 → 21.383 (평균: 13.342)\n","  Building 88 (Department Store): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 7.457 → 8.411 → 4.837 → 4.523 → 8.049 (평균: 6.655)\n","  Building 89 (Hotel): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 4.987 → 1.893 → 3.293 → 3.794 → 3.178 (평균: 3.429)\n","  Building 90 (Hospital): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 4.992 → 6.352 → 5.381 → 4.977 → 4.658 (평균: 5.272)\n","  Building 91 (Apartment): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 12.469 → 6.807 → 5.275 → 4.425 → 3.742 (평균: 6.544)\n","  Building 92 (Public): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 7.639 → 4.782 → 3.701 → 4.714 → 4.123 (평균: 4.992)\n","  Building 93 (Apartment): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 9.014 → 7.382 → 5.228 → 4.149 → 6.189 (평균: 6.392)\n","  Building 94 (Research Institute): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 21.761 → 20.730 → 46.129 → 15.832 → 31.713 (평균: 27.233)\n","  Building 95 (Department Store): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 5.021 → 6.664 → 18.098 → 6.411 → 12.951 (평균: 9.829)\n","  Building 96 (Other Buildings): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 7.205 → 6.469 → 5.473 → 5.268 → 4.993 (평균: 5.882)\n","  Building 97 (Other Buildings): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 24.007 → 5.805 → 5.051 → 4.699 → 5.064 (평균: 8.925)\n","  Building 98 (Hotel): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 7.331 → 8.741 → 6.907 → 4.799 → 4.581 (평균: 6.472)\n","  Building 99 (Commercial): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 2.568 → 3.384 → 4.318 → 2.717 → 2.790 (평균: 3.156)\n","  Building 100 (Hotel): 모델 모두 존재, OOF 및 CV 결과 재계산\n","    → 복원된 CV SMAPE: 26.589 → 19.115 → 20.294 → 21.549 → 16.429 (평균: 20.795)\n","\n","=== 건물별 개별 모델 학습/복원 완료 ===\n","\n","=== 개별 모델 학습/복원 완료 상태 확인 ===\n","총 학습 대상 건물 수: 100\n","실제 학습 완료 건물 수: 100\n","OOF 예측값 저장된 건물 수: 100\n","CV 결과 저장된 건물 수: 100\n","\n","=== 데이터 일관성 확인 ===\n","✅ 모든 딕셔너리의 건물 키가 일치합니다\n","\n","=== CV 결과 샘플 확인 ===\n","건물 1: 5개 fold, SMAPE = [np.float64(12.016554025386032), np.float64(8.981184400045706), np.float64(9.040249644685161), np.float64(8.851524264930905), np.float64(9.990750977221907)]\n","건물 2: 5개 fold, SMAPE = [np.float64(5.382990197676587), np.float64(7.230877744236556), np.float64(5.915924690870395), np.float64(7.031583012141805), np.float64(5.506443895164112)]\n","건물 3: 5개 fold, SMAPE = [np.float64(4.685948309775358), np.float64(3.1068620841348973), np.float64(3.0946431427756984), np.float64(4.570259107411792), np.float64(4.614497852428189)]\n","\n","=== 전체 개별 모델 성능 요약 ===\n","전체 개별 모델 SMAPE: 평균 7.515 ± 4.910\n","                    범위: 0.744 ~ 27.233\n","\n","=== 건물 유형별 개별 모델 성능 ===\n","          Hotel: 10개 건물, 평균 SMAPE 9.359 ± 4.928\n","     Commercial: 10개 건물, 평균 SMAPE 4.172 ± 2.909\n","       Hospital:  9개 건물, 평균 SMAPE 4.356 ± 0.597\n","     University: 10개 건물, 평균 SMAPE 6.319 ± 3.309\n","Other Buildings: 10개 건물, 평균 SMAPE 9.108 ± 6.140\n","      Apartment:  9개 건물, 평균 SMAPE 8.012 ± 2.632\n","Research Institute:  9개 건물, 평균 SMAPE 10.068 ± 7.686\n","Department Store: 16개 건물, 평균 SMAPE 9.848 ± 3.389\n","            IDC:  9개 건물, 평균 SMAPE 4.074 ± 4.770\n","         Public:  8개 건물, 평균 SMAPE 8.214 ± 3.108\n","\n","=== OOF 데이터 크기 확인 ===\n","OOF 예측값 크기 분포: {np.int64(100): np.int64(2040)}\n","✅ 모든 건물의 OOF 크기가 동일합니다: 2040개\n","\n","=== 개별 모델 준비 완료 ===\n"]}]},{"cell_type":"markdown","source":["### 건물 유형별 학습"],"metadata":{"id":"nLlSPzwEWQjw"}},{"cell_type":"code","source":["# 유형별 모델 저장 경로 설정\n","MODEL_PATH_BUILDING_TYPE = f'{PROJECT_PATH}/models/building_types'\n","os.makedirs(MODEL_PATH_BUILDING_TYPE, exist_ok=True)"],"metadata":{"id":"FYZcKx-quJIm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#========================================\n","# 건물 유형별 모델용 유틸리티 함수들\n","#========================================\n","def check_building_type_completion(building_type, n_folds=5):\n","    \"\"\"해당 건물 유형의 모든 fold 모델이 존재하는지 확인\"\"\"\n","    safe_type_name = str(building_type).replace(' ', '_').replace('/', '_').replace('(', '').replace(')', '')\n","    for fold in range(n_folds):\n","        json_path = f\"{MODEL_PATH_BUILDING_TYPE}/xgb_type_{safe_type_name}_fold{fold}.json\"\n","        pkl_path = f\"{MODEL_PATH_BUILDING_TYPE}/xgb_type_{safe_type_name}_fold{fold}.pkl\"\n","        if not (os.path.exists(json_path) or os.path.exists(pkl_path)):\n","            return False, fold  # 해당 fold부터 재시작\n","    return True, -1\n","\n","\n","def load_existing_type_models(building_type, n_folds=5):\n","    \"\"\"저장된 건물 유형별 모델들 로드\"\"\"\n","    safe_type_name = str(building_type).replace(' ', '_').replace('/', '_').replace('(', '').replace(')', '')\n","    models = []\n","    for fold in range(n_folds):\n","        json_path = f\"{MODEL_PATH_BUILDING_TYPE}/xgb_type_{safe_type_name}_fold{fold}.json\"\n","        pkl_path = f\"{MODEL_PATH_BUILDING_TYPE}/xgb_type_{safe_type_name}_fold{fold}.pkl\"\n","        if os.path.exists(json_path):\n","            model = xgb.Booster()\n","            model.load_model(json_path)\n","            models.append(model)\n","        elif os.path.exists(pkl_path):\n","            with open(pkl_path, 'rb') as f:\n","                model = pickle.load(f)\n","            models.append(model)\n","        else:\n","            raise FileNotFoundError(f\"모델 파일이 없습니다: {json_path}, {pkl_path}\")\n","    return models\n","\n","\n","def regenerate_oof_from_type_models(type_data, models, feature_cols, tscv):\n","    \"\"\"저장된 건물 유형별 모델로 OOF 재계산\"\"\"\n","    n_samples = len(type_data)\n","    oof_preds = np.zeros(n_samples)\n","    for fold, (train_idx, val_idx) in enumerate(tscv.split(type_data)):\n","        tr_df = type_data.iloc[train_idx].copy()\n","        va_df = type_data.iloc[val_idx].copy()\n","        stats = _build_time_stats(tr_df)\n","        va_df = attach_time_stats(va_df, stats)\n","        X_val_cv = va_df[feature_cols].copy().drop(columns=['building_number'], errors='ignore')\n","        dvalid = xgb.DMatrix(X_val_cv, feature_names=X_val_cv.columns.tolist())\n","        val_pred_log = models[fold].predict(dvalid)\n","        val_pred = np.expm1(val_pred_log)\n","        oof_preds[val_idx] = val_pred\n","    return oof_preds\n","\n","\n","#========================================\n","# 건물 유형별 하이퍼파라미터 (개별 모델과 동일하게 시작)\n","building_type_params = {\n","    \"max_depth\": 10,\n","    \"learning_rate\": 0.005,\n","    \"subsample\": 0.8,\n","    \"colsample_bytree\": 0.6,\n","    \"min_child_weight\": 4,\n","    \"gamma\": 0.05,\n","    \"lambda\": 1.2,\n","    \"alpha\": 0.4,\n","    \"tree_method\": \"hist\",\n","    \"device\": \"cuda\",\n","    \"max_bin\": 256,\n","    \"verbosity\": 0,\n","    \"random_state\": RANDOM_SEED,\n","    \"eval_metric\": \"mae\",\n","}\n","\n","N_BOOST_ROUND = 8000\n","ES_ROUNDS = 600\n","\n","print(f\"\\n건물 유형별 모델 학습/복원 시작...\")\n","\n","# 건물 유형별 데이터 및 결과 저장용 딕셔너리\n","building_type_models = {}\n","building_type_cv_results = {}\n","oof_preds_per_type = {}\n","\n","# 건물 유형 목록 확인\n","building_types = train['building'].unique()\n","print(f\"건물 유형 목록: {building_types}\")\n","\n","tscv = TimeSeriesSplit(n_splits=5, test_size=24*7, gap=24)\n","\n","for type_idx, building_type in enumerate(building_types):\n","    print(f\"\\n=== [{type_idx+1}/{len(building_types)}] {building_type} 유형 모델 학습 ===\")\n","\n","    # 해당 유형 데이터만 필터링\n","    type_data = train[train['building'] == building_type].copy()\n","    type_data = type_data.sort_values('date_time').reset_index(drop=True)\n","    n_samples = len(type_data)\n","    n_buildings = type_data['building_number'].nunique()\n","\n","    print(f\"  데이터 크기: {n_samples}행, {n_buildings}개 건물\")\n","\n","    if n_samples < 1000:  # 유형별 최소 데이터 기준\n","        print(f\"  데이터가 부족합니다 ({n_samples}행). 유형별 학습 스킵.\")\n","        continue\n","\n","    # 모델 완성 여부 확인\n","    is_complete, resume_fold = check_building_type_completion(building_type)\n","    fold_results = []\n","    safe_type_name = str(building_type).replace(' ', '_').replace('/', '_').replace('(', '').replace(')', '')\n","\n","    if is_complete:\n","        print(f\"  {building_type} 유형: 모델 모두 존재, OOF 재계산\")\n","        models = load_existing_type_models(building_type)\n","        building_type_models[building_type] = models\n","        oof_preds = regenerate_oof_from_type_models(type_data, models, feature_cols, tscv)\n","        oof_preds_per_type[building_type] = oof_preds\n","        continue\n","\n","    print(f\"  {building_type} 유형: fold {resume_fold}부터 학습 재개\")\n","    models = []\n","    oof_preds = np.zeros(n_samples)\n","\n","    for fold, (train_idx, val_idx) in enumerate(tscv.split(type_data)):\n","        if fold < resume_fold:\n","            # 이미 저장된 모델 불러오기\n","            model = None\n","            json_path = f\"{MODEL_PATH_BUILDING_TYPE}/xgb_type_{safe_type_name}_fold{fold}.json\"\n","            pkl_path = f\"{MODEL_PATH_BUILDING_TYPE}/xgb_type_{safe_type_name}_fold{fold}.pkl\"\n","            if os.path.exists(json_path):\n","                model = xgb.Booster()\n","                model.load_model(json_path)\n","            elif os.path.exists(pkl_path):\n","                with open(pkl_path, 'rb') as f:\n","                    model = pickle.load(f)\n","            if model is not None:\n","                models.append(model)\n","                print(f\"    Fold {fold+1}: 이미 저장된 모델 사용\")\n","            else:\n","                raise FileNotFoundError(f\"Fold {fold} 모델 파일이 없습니다.\")\n","            continue\n","\n","        print(f\"    Fold {fold+1}/{tscv.n_splits} 학습 중... \", end=\"\")\n","        tr_df = type_data.iloc[train_idx].copy()\n","        va_df = type_data.iloc[val_idx].copy()\n","\n","        # 통계 피처 생성 (해당 fold 훈련 데이터만 사용)\n","        stats = _build_time_stats(tr_df)\n","        tr_df = attach_time_stats(tr_df, stats)\n","        va_df = attach_time_stats(va_df, stats)\n","\n","        # 피처 준비\n","        X_train_cv = tr_df[feature_cols].copy().drop(columns=['building_number'], errors='ignore')\n","        X_val_cv = va_df[feature_cols].copy().drop(columns=['building_number'], errors='ignore')\n","        y_train_cv = tr_df['power_consumption_log']\n","        y_val_cv = va_df['power_consumption_log']\n","\n","        # XGBoost 데이터 준비\n","        dtrain = xgb.DMatrix(X_train_cv, label=y_train_cv, feature_names=X_train_cv.columns.tolist())\n","        dvalid = xgb.DMatrix(X_val_cv, label=y_val_cv, feature_names=X_train_cv.columns.tolist())\n","\n","        # 모델 학습\n","        evals_result = {}\n","        model = xgb.train(\n","            params=building_type_params,\n","            dtrain=dtrain,\n","            num_boost_round=N_BOOST_ROUND,\n","            evals=[(dtrain, \"train\"), (dvalid, \"valid\")],\n","            obj=weighted_mse(alpha=3.0),\n","            custom_metric=smape_eval,\n","            early_stopping_rounds=ES_ROUNDS,\n","            verbose_eval=False,\n","            evals_result=evals_result\n","        )\n","\n","        models.append(model)\n","\n","        # OOF 예측 및 성능 평가\n","        val_pred_log = model.predict(dvalid, iteration_range=(0, model.best_iteration+1))\n","        val_pred = np.expm1(val_pred_log)\n","        oof_preds[val_idx] = val_pred\n","\n","        y_val = np.expm1(y_val_cv)\n","        smape_score = smape(y_val, val_pred)\n","        rmse_score = np.sqrt(np.mean((val_pred - y_val) ** 2))\n","\n","        # 결과 저장\n","        fold_results.append({\n","            'fold': fold + 1,\n","            'smape': smape_score,\n","            'rmse': rmse_score,\n","            'best_iteration': model.best_iteration,\n","            'train_size': len(train_idx),\n","            'val_size': len(val_idx),\n","            'train_mae_final': evals_result['train']['mae'][model.best_iteration],\n","            'valid_mae_final': evals_result['valid']['mae'][model.best_iteration],\n","            'train_smape_final': evals_result['train']['smape'][model.best_iteration],\n","            'valid_smape_final': evals_result['valid']['smape'][model.best_iteration],\n","            'train_val_gap': evals_result['valid']['mae'][model.best_iteration] - evals_result['train']['mae'][model.best_iteration],\n","            'building_type': building_type,\n","            'n_buildings_in_fold': len(tr_df['building_number'].unique())\n","        })\n","\n","        print(f\"SMAPE: {smape_score:.4f}, best_iter: {model.best_iteration}, \"\n","              f\"train_mae: {evals_result['train']['mae'][model.best_iteration]:.4f}, \"\n","              f\"valid_mae: {evals_result['valid']['mae'][model.best_iteration]:.4f}\")\n","\n","        # 모델 저장\n","        model_file = f\"{MODEL_PATH_BUILDING_TYPE}/xgb_type_{safe_type_name}_fold{fold}.json\"\n","        try:\n","            model.save_model(model_file)\n","        except Exception as e:\n","            print(f\"\\n    JSON 저장 실패 (Fold {fold}), Pickle로 저장: {e}\")\n","            pickle_file = f\"{MODEL_PATH_BUILDING_TYPE}/xgb_type_{safe_type_name}_fold{fold}.pkl\"\n","            with open(pickle_file, 'wb') as f:\n","                pickle.dump(model, f)\n","\n","    # fold 루프 종료 후 결과 저장\n","    building_type_models[building_type] = models\n","    oof_preds_per_type[building_type] = oof_preds\n","    building_type_cv_results[building_type] = fold_results\n","\n","    # 유형별 성능 분석\n","    if fold_results:\n","        smape_list = [r['smape'] for r in fold_results]\n","        score, weighted_mean, weighted_std, weights = recent_weighted_score(smape_list, decay=0.5)\n","\n","        print(f\"\\n  === {building_type} 유형 상세 분석 ===\")\n","        print(f\"  시간순 SMAPE 추세: {' -> '.join([f'{s:.3f}' for s in smape_list])}\")\n","        print(f\"  최근성 가중평균 SMAPE: {weighted_mean:.4f}, 안정성 패널티: {weighted_std:.4f}, 최종 Score: {score:.4f}\")\n","        print(f\"  가중치: {weights}\")\n","\n","        avg_best_iter = np.mean([r['best_iteration'] for r in fold_results])\n","        avg_gap = np.mean([r['train_val_gap'] for r in fold_results])\n","        gap_std = np.std([r['train_val_gap'] for r in fold_results])\n","        avg_buildings_per_fold = np.mean([r['n_buildings_in_fold'] for r in fold_results])\n","\n","        print(f\"\\n  === 모델 진단 ===\")\n","        print(f\"  평균 best_iteration: {avg_best_iter:.0f} (목표: {N_BOOST_ROUND}의 10-50%)\")\n","        print(f\"  평균 train-valid gap: {avg_gap:+.4f} ± {gap_std:.4f}\")\n","        print(f\"  fold당 평균 건물 수: {avg_buildings_per_fold:.1f}개\")\n","\n","        if avg_best_iter < N_BOOST_ROUND * 0.1:\n","            print(\"  >> 과적합 의심: best_iteration이 너무 작음\")\n","        elif avg_best_iter > N_BOOST_ROUND * 0.8:\n","            print(\"  >> 과소적합 의심: early stopping이 거의 작동하지 않음\")\n","        else:\n","            print(\"  >> 정상 범위: 적절한 학습 종료\")\n","\n","        if avg_gap > 0.02:\n","            print(\"  >> 과적합 의심: train-valid 성능 차이가 큼\")\n","        elif avg_gap < -0.01:\n","            print(\"  >> 이상: valid가 train보다 좋음\")\n","        else:\n","            print(\"  >> 정상: train-valid 성능 차이 적절\")\n","\n","        smape_std = np.std(smape_list)\n","        if smape_std > np.mean(smape_list) * 0.1:\n","            print(f\"  >> 불안정: fold간 성능 차이 큼 (SMAPE std: {smape_std:.4f})\")\n","        else:\n","            print(f\"  >> 안정: fold간 성능 일관성 좋음 (SMAPE std: {smape_std:.4f})\")\n","\n","print(f\"\\n=== 건물 유형별 모델 학습 완료 요약 ===\")\n","\n","# 유형별 최종 성능 요약\n","type_performance_summary = {}\n","for building_type, results in building_type_cv_results.items():\n","    if not results:\n","        continue\n","\n","    smape_trend = [r['smape'] for r in results]\n","    best_iter_avg = np.mean([r['best_iteration'] for r in results])\n","    gap_avg = np.mean([r['train_val_gap'] for r in results])\n","    buildings_count = len(train[train['building'] == building_type]['building_number'].unique())\n","\n","    type_performance_summary[building_type] = {\n","        'final_smape': smape_trend[-1],\n","        'avg_smape': np.mean(smape_trend),\n","        'avg_iter': best_iter_avg,\n","        'avg_gap': gap_avg,\n","        'n_buildings': buildings_count,\n","        'data_size': len(train[train['building'] == building_type])\n","    }\n","\n","    print(f\"{building_type:>20} | \"\n","          f\"최종SMAPE: {smape_trend[-1]:.4f} | \"\n","          f\"평균SMAPE: {np.mean(smape_trend):.4f} | \"\n","          f\"평균iter: {best_iter_avg:.0f} | \"\n","          f\"평균gap: {gap_avg:+.4f} | \"\n","          f\"건물수: {buildings_count:>2}개 | \"\n","          f\"데이터: {len(train[train['building'] == building_type]):>4}행\")\n","\n","print(f\"\\n=== 건물 유형별 모델 성능 종합 요약 ===\")\n","smapes = [summary['final_smape'] for summary in type_performance_summary.values()]\n","if smapes:\n","    print(f\"전체 유형별 최종 SMAPE - 평균: {np.mean(smapes):.3f} ± {np.std(smapes):.3f} | \"\n","          f\"범위: {np.min(smapes):.3f} ~ {np.max(smapes):.3f}\")\n"],"metadata":{"id":"OQj8WxlsRj9M","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756061417742,"user_tz":-540,"elapsed":1256817,"user":{"displayName":"송상현","userId":"05825752637342282552"}},"outputId":"3b8e17e9-14b9-4049-9200-83ee18ef1693"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","건물 유형별 모델 학습/복원 시작...\n","건물 유형 목록: ['Hotel' 'Commercial' 'Hospital' 'University' 'Other Buildings'\n"," 'Apartment' 'Research Institute' 'Department Store' 'IDC' 'Public']\n","\n","=== [1/10] Hotel 유형 모델 학습 ===\n","  데이터 크기: 20400행, 10개 건물\n","  Hotel 유형: fold 0부터 학습 재개\n","    Fold 1/5 학습 중... SMAPE: 7.4005, best_iter: 1225, train_mae: 0.0428, valid_mae: 0.0742\n","    Fold 2/5 학습 중... SMAPE: 8.3624, best_iter: 1490, train_mae: 0.0415, valid_mae: 0.0845\n","    Fold 3/5 학습 중... SMAPE: 11.7773, best_iter: 1314, train_mae: 0.0417, valid_mae: 0.1195\n","    Fold 4/5 학습 중... SMAPE: 8.5224, best_iter: 2635, train_mae: 0.0414, valid_mae: 0.0855\n","    Fold 5/5 학습 중... SMAPE: 7.1946, best_iter: 2122, train_mae: 0.0416, valid_mae: 0.0721\n","\n","  === Hotel 유형 상세 분석 ===\n","  시간순 SMAPE 추세: 7.401 -> 8.362 -> 11.777 -> 8.522 -> 7.195\n","  최근성 가중평균 SMAPE: 8.2105, 안정성 패널티: 1.4907, 최종 Score: 9.7012\n","  가중치: [0.03225806 0.06451613 0.12903226 0.25806452 0.51612903]\n","\n","  === 모델 진단 ===\n","  평균 best_iteration: 1757 (목표: 8000의 10-50%)\n","  평균 train-valid gap: +0.0453 ± 0.0172\n","  fold당 평균 건물 수: 10.0개\n","  >> 정상 범위: 적절한 학습 종료\n","  >> 과적합 의심: train-valid 성능 차이가 큼\n","  >> 불안정: fold간 성능 차이 큼 (SMAPE std: 1.6467)\n","\n","=== [2/10] Commercial 유형 모델 학습 ===\n","  데이터 크기: 20400행, 10개 건물\n","  Commercial 유형: fold 0부터 학습 재개\n","    Fold 1/5 학습 중... SMAPE: 4.0817, best_iter: 1781, train_mae: 0.0223, valid_mae: 0.0410\n","    Fold 2/5 학습 중... SMAPE: 3.4461, best_iter: 6722, train_mae: 0.0227, valid_mae: 0.0345\n","    Fold 3/5 학습 중... SMAPE: 2.9782, best_iter: 1466, train_mae: 0.0217, valid_mae: 0.0298\n","    Fold 4/5 학습 중... SMAPE: 2.7749, best_iter: 1391, train_mae: 0.0221, valid_mae: 0.0278\n","    Fold 5/5 학습 중... SMAPE: 3.6201, best_iter: 1367, train_mae: 0.0223, valid_mae: 0.0362\n","\n","  === Commercial 유형 상세 분석 ===\n","  시간순 SMAPE 추세: 4.082 -> 3.446 -> 2.978 -> 2.775 -> 3.620\n","  최근성 가중평균 SMAPE: 3.3228, 안정성 패널티: 0.3974, 최종 Score: 3.7203\n","  가중치: [0.03225806 0.06451613 0.12903226 0.25806452 0.51612903]\n","\n","  === 모델 진단 ===\n","  평균 best_iteration: 2545 (목표: 8000의 10-50%)\n","  평균 train-valid gap: +0.0116 ± 0.0045\n","  fold당 평균 건물 수: 10.0개\n","  >> 정상 범위: 적절한 학습 종료\n","  >> 정상: train-valid 성능 차이 적절\n","  >> 불안정: fold간 성능 차이 큼 (SMAPE std: 0.4652)\n","\n","=== [3/10] Hospital 유형 모델 학습 ===\n","  데이터 크기: 18360행, 9개 건물\n","  Hospital 유형: fold 0부터 학습 재개\n","    Fold 1/5 학습 중... SMAPE: 2.1999, best_iter: 7815, train_mae: 0.0283, valid_mae: 0.0220\n","    Fold 2/5 학습 중... SMAPE: 2.8717, best_iter: 7784, train_mae: 0.0282, valid_mae: 0.0287\n","    Fold 3/5 학습 중... SMAPE: 2.3879, best_iter: 1454, train_mae: 0.0277, valid_mae: 0.0239\n","    Fold 4/5 학습 중... SMAPE: 2.4303, best_iter: 1230, train_mae: 0.0299, valid_mae: 0.0243\n","    Fold 5/5 학습 중... SMAPE: 3.0413, best_iter: 1322, train_mae: 0.0280, valid_mae: 0.0304\n","\n","  === Hospital 유형 상세 분석 ===\n","  시간순 SMAPE 추세: 2.200 -> 2.872 -> 2.388 -> 2.430 -> 3.041\n","  최근성 가중평균 SMAPE: 2.7612, 안정성 패널티: 0.3126, 최종 Score: 3.0738\n","  가중치: [0.03225806 0.06451613 0.12903226 0.25806452 0.51612903]\n","\n","  === 모델 진단 ===\n","  평균 best_iteration: 3921 (목표: 8000의 10-50%)\n","  평균 train-valid gap: -0.0026 ± 0.0034\n","  fold당 평균 건물 수: 9.0개\n","  >> 정상 범위: 적절한 학습 종료\n","  >> 정상: train-valid 성능 차이 적절\n","  >> 불안정: fold간 성능 차이 큼 (SMAPE std: 0.3167)\n","\n","=== [4/10] University 유형 모델 학습 ===\n","  데이터 크기: 20400행, 10개 건물\n","  University 유형: fold 0부터 학습 재개\n","    Fold 1/5 학습 중... SMAPE: 4.4853, best_iter: 1496, train_mae: 0.0266, valid_mae: 0.0449\n","    Fold 2/5 학습 중... SMAPE: 5.1401, best_iter: 7977, train_mae: 0.0273, valid_mae: 0.0514\n","    Fold 3/5 학습 중... SMAPE: 3.0194, best_iter: 1306, train_mae: 0.0273, valid_mae: 0.0302\n","    Fold 4/5 학습 중... SMAPE: 5.1700, best_iter: 1404, train_mae: 0.0266, valid_mae: 0.0518\n","    Fold 5/5 학습 중... SMAPE: 8.9030, best_iter: 4389, train_mae: 0.0274, valid_mae: 0.0906\n","\n","  === University 유형 상세 분석 ===\n","  시간순 SMAPE 추세: 4.485 -> 5.140 -> 3.019 -> 5.170 -> 8.903\n","  최근성 가중평균 SMAPE: 6.7952, 안정성 패널티: 2.2723, 최종 Score: 9.0675\n","  가중치: [0.03225806 0.06451613 0.12903226 0.25806452 0.51612903]\n","\n","  === 모델 진단 ===\n","  평균 best_iteration: 3314 (목표: 8000의 10-50%)\n","  평균 train-valid gap: +0.0267 ± 0.0199\n","  fold당 평균 건물 수: 10.0개\n","  >> 정상 범위: 적절한 학습 종료\n","  >> 과적합 의심: train-valid 성능 차이가 큼\n","  >> 불안정: fold간 성능 차이 큼 (SMAPE std: 1.9432)\n","\n","=== [5/10] Other Buildings 유형 모델 학습 ===\n","  데이터 크기: 20400행, 10개 건물\n","  Other Buildings 유형: fold 0부터 학습 재개\n","    Fold 1/5 학습 중... SMAPE: 5.2835, best_iter: 4214, train_mae: 0.0368, valid_mae: 0.0529\n","    Fold 2/5 학습 중... SMAPE: 5.4559, best_iter: 7889, train_mae: 0.0365, valid_mae: 0.0546\n","    Fold 3/5 학습 중... SMAPE: 4.9019, best_iter: 1318, train_mae: 0.0368, valid_mae: 0.0490\n","    Fold 4/5 학습 중... SMAPE: 5.3976, best_iter: 1219, train_mae: 0.0382, valid_mae: 0.0540\n","    Fold 5/5 학습 중... SMAPE: 5.9589, best_iter: 1709, train_mae: 0.0369, valid_mae: 0.0597\n","\n","  === Other Buildings 유형 상세 분석 ===\n","  시간순 SMAPE 추세: 5.283 -> 5.456 -> 4.902 -> 5.398 -> 5.959\n","  최근성 가중평균 SMAPE: 5.6234, 안정성 패널티: 0.3794, 최종 Score: 6.0028\n","  가중치: [0.03225806 0.06451613 0.12903226 0.25806452 0.51612903]\n","\n","  === 모델 진단 ===\n","  평균 best_iteration: 3270 (목표: 8000의 10-50%)\n","  평균 train-valid gap: +0.0170 ± 0.0034\n","  fold당 평균 건물 수: 10.0개\n","  >> 정상 범위: 적절한 학습 종료\n","  >> 정상: train-valid 성능 차이 적절\n","  >> 안정: fold간 성능 일관성 좋음 (SMAPE std: 0.3397)\n","\n","=== [6/10] Apartment 유형 모델 학습 ===\n","  데이터 크기: 18360행, 9개 건물\n","  Apartment 유형: fold 0부터 학습 재개\n","    Fold 1/5 학습 중... SMAPE: 5.4365, best_iter: 1387, train_mae: 0.0305, valid_mae: 0.0540\n","    Fold 2/5 학습 중... SMAPE: 5.9659, best_iter: 4978, train_mae: 0.0306, valid_mae: 0.0593\n","    Fold 3/5 학습 중... SMAPE: 4.0690, best_iter: 3555, train_mae: 0.0308, valid_mae: 0.0403\n","    Fold 4/5 학습 중... SMAPE: 3.6734, best_iter: 1280, train_mae: 0.0310, valid_mae: 0.0365\n","    Fold 5/5 학습 중... SMAPE: 5.0683, best_iter: 1351, train_mae: 0.0307, valid_mae: 0.0502\n","\n","  === Apartment 유형 상세 분석 ===\n","  시간순 SMAPE 추세: 5.437 -> 5.966 -> 4.069 -> 3.673 -> 5.068\n","  최근성 가중평균 SMAPE: 4.6492, 안정성 패널티: 0.7153, 최종 Score: 5.3645\n","  가중치: [0.03225806 0.06451613 0.12903226 0.25806452 0.51612903]\n","\n","  === 모델 진단 ===\n","  평균 best_iteration: 2510 (목표: 8000의 10-50%)\n","  평균 train-valid gap: +0.0173 ± 0.0086\n","  fold당 평균 건물 수: 9.0개\n","  >> 정상 범위: 적절한 학습 종료\n","  >> 정상: train-valid 성능 차이 적절\n","  >> 불안정: fold간 성능 차이 큼 (SMAPE std: 0.8522)\n","\n","=== [7/10] Research Institute 유형 모델 학습 ===\n","  데이터 크기: 18360행, 9개 건물\n","  Research Institute 유형: fold 0부터 학습 재개\n","    Fold 1/5 학습 중... SMAPE: 5.8937, best_iter: 4090, train_mae: 0.0340, valid_mae: 0.0590\n","    Fold 2/5 학습 중... SMAPE: 17.6536, best_iter: 3336, train_mae: 0.0342, valid_mae: 0.1804\n","    Fold 3/5 학습 중... SMAPE: 9.3174, best_iter: 1199, train_mae: 0.0362, valid_mae: 0.0938\n","    Fold 4/5 학습 중... SMAPE: 6.4469, best_iter: 1430, train_mae: 0.0337, valid_mae: 0.0647\n","    Fold 5/5 학습 중... SMAPE: 8.5949, best_iter: 1407, train_mae: 0.0338, valid_mae: 0.0866\n","\n","  === Research Institute 유형 상세 분석 ===\n","  시간순 SMAPE 추세: 5.894 -> 17.654 -> 9.317 -> 6.447 -> 8.595\n","  최근성 가중평균 SMAPE: 8.6311, 안정성 패널티: 2.6051, 최종 Score: 11.2361\n","  가중치: [0.03225806 0.06451613 0.12903226 0.25806452 0.51612903]\n","\n","  === 모델 진단 ===\n","  평균 best_iteration: 2292 (목표: 8000의 10-50%)\n","  평균 train-valid gap: +0.0625 ± 0.0436\n","  fold당 평균 건물 수: 9.0개\n","  >> 정상 범위: 적절한 학습 종료\n","  >> 과적합 의심: train-valid 성능 차이가 큼\n","  >> 불안정: fold간 성능 차이 큼 (SMAPE std: 4.2339)\n","\n","=== [8/10] Department Store 유형 모델 학습 ===\n","  데이터 크기: 32640행, 16개 건물\n","  Department Store 유형: fold 0부터 학습 재개\n","    Fold 1/5 학습 중... SMAPE: 6.5875, best_iter: 1419, train_mae: 0.0373, valid_mae: 0.0661\n","    Fold 2/5 학습 중... SMAPE: 7.7704, best_iter: 1330, train_mae: 0.0378, valid_mae: 0.1081\n","    Fold 3/5 학습 중... SMAPE: 5.9588, best_iter: 1166, train_mae: 0.0420, valid_mae: 0.0597\n","    Fold 4/5 학습 중... SMAPE: 8.0890, best_iter: 1376, train_mae: 0.0377, valid_mae: 0.0821\n","    Fold 5/5 학습 중... SMAPE: 4.0183, best_iter: 1419, train_mae: 0.0376, valid_mae: 0.0402\n","\n","  === Department Store 유형 상세 분석 ===\n","  시간순 SMAPE 추세: 6.588 -> 7.770 -> 5.959 -> 8.089 -> 4.018\n","  최근성 가중평균 SMAPE: 5.6441, 안정성 패널티: 1.8000, 최종 Score: 7.4442\n","  가중치: [0.03225806 0.06451613 0.12903226 0.25806452 0.51612903]\n","\n","  === 모델 진단 ===\n","  평균 best_iteration: 1342 (목표: 8000의 10-50%)\n","  평균 train-valid gap: +0.0328 ± 0.0232\n","  fold당 평균 건물 수: 16.0개\n","  >> 정상 범위: 적절한 학습 종료\n","  >> 과적합 의심: train-valid 성능 차이가 큼\n","  >> 불안정: fold간 성능 차이 큼 (SMAPE std: 1.4558)\n","\n","=== [9/10] IDC 유형 모델 학습 ===\n","  데이터 크기: 18360행, 9개 건물\n","  IDC 유형: fold 0부터 학습 재개\n","    Fold 1/5 학습 중... SMAPE: 4.5076, best_iter: 3545, train_mae: 0.0134, valid_mae: 0.0453\n","    Fold 2/5 학습 중... SMAPE: 1.7659, best_iter: 1922, train_mae: 0.0133, valid_mae: 0.0177\n","    Fold 3/5 학습 중... SMAPE: 1.5579, best_iter: 1833, train_mae: 0.0131, valid_mae: 0.0156\n","    Fold 4/5 학습 중... SMAPE: 3.2264, best_iter: 1559, train_mae: 0.0126, valid_mae: 0.0344\n","    Fold 5/5 학습 중... SMAPE: 2.0928, best_iter: 1425, train_mae: 0.0135, valid_mae: 0.0209\n","\n","  === IDC 유형 상세 분석 ===\n","  시간순 SMAPE 추세: 4.508 -> 1.766 -> 1.558 -> 3.226 -> 2.093\n","  최근성 가중평균 SMAPE: 2.3731, 안정성 패널티: 0.6964, 최종 Score: 3.0695\n","  가중치: [0.03225806 0.06451613 0.12903226 0.25806452 0.51612903]\n","\n","  === 모델 진단 ===\n","  평균 best_iteration: 2057 (목표: 8000의 10-50%)\n","  평균 train-valid gap: +0.0136 ± 0.0114\n","  fold당 평균 건물 수: 9.0개\n","  >> 정상 범위: 적절한 학습 종료\n","  >> 정상: train-valid 성능 차이 적절\n","  >> 불안정: fold간 성능 차이 큼 (SMAPE std: 1.1014)\n","\n","=== [10/10] Public 유형 모델 학습 ===\n","  데이터 크기: 16320행, 8개 건물\n","  Public 유형: fold 0부터 학습 재개\n","    Fold 1/5 학습 중... SMAPE: 5.9044, best_iter: 5221, train_mae: 0.0374, valid_mae: 0.0591\n","    Fold 2/5 학습 중... SMAPE: 5.7725, best_iter: 1899, train_mae: 0.0384, valid_mae: 0.0578\n","    Fold 3/5 학습 중... SMAPE: 5.1158, best_iter: 1132, train_mae: 0.0434, valid_mae: 0.0512\n","    Fold 4/5 학습 중... SMAPE: 8.2588, best_iter: 1096, train_mae: 0.0458, valid_mae: 0.0870\n","    Fold 5/5 학습 중... SMAPE: 7.2032, best_iter: 1767, train_mae: 0.0384, valid_mae: 0.0737\n","\n","  === Public 유형 상세 분석 ===\n","  시간순 SMAPE 추세: 5.904 -> 5.772 -> 5.116 -> 8.259 -> 7.203\n","  최근성 가중평균 SMAPE: 7.0721, 안정성 패널티: 1.0095, 최종 Score: 8.0815\n","  가중치: [0.03225806 0.06451613 0.12903226 0.25806452 0.51612903]\n","\n","  === 모델 진단 ===\n","  평균 best_iteration: 2223 (목표: 8000의 10-50%)\n","  평균 train-valid gap: +0.0251 ± 0.0119\n","  fold당 평균 건물 수: 8.0개\n","  >> 정상 범위: 적절한 학습 종료\n","  >> 과적합 의심: train-valid 성능 차이가 큼\n","  >> 불안정: fold간 성능 차이 큼 (SMAPE std: 1.1292)\n","\n","=== 건물 유형별 모델 학습 완료 요약 ===\n","               Hotel | 최종SMAPE: 7.1946 | 평균SMAPE: 8.6514 | 평균iter: 1757 | 평균gap: +0.0453 | 건물수: 10개 | 데이터: 20400행\n","          Commercial | 최종SMAPE: 3.6201 | 평균SMAPE: 3.3802 | 평균iter: 2545 | 평균gap: +0.0116 | 건물수: 10개 | 데이터: 20400행\n","            Hospital | 최종SMAPE: 3.0413 | 평균SMAPE: 2.5862 | 평균iter: 3921 | 평균gap: -0.0026 | 건물수:  9개 | 데이터: 18360행\n","          University | 최종SMAPE: 8.9030 | 평균SMAPE: 5.3436 | 평균iter: 3314 | 평균gap: +0.0267 | 건물수: 10개 | 데이터: 20400행\n","     Other Buildings | 최종SMAPE: 5.9589 | 평균SMAPE: 5.3996 | 평균iter: 3270 | 평균gap: +0.0170 | 건물수: 10개 | 데이터: 20400행\n","           Apartment | 최종SMAPE: 5.0683 | 평균SMAPE: 4.8426 | 평균iter: 2510 | 평균gap: +0.0173 | 건물수:  9개 | 데이터: 18360행\n","  Research Institute | 최종SMAPE: 8.5949 | 평균SMAPE: 9.5813 | 평균iter: 2292 | 평균gap: +0.0625 | 건물수:  9개 | 데이터: 18360행\n","    Department Store | 최종SMAPE: 4.0183 | 평균SMAPE: 6.4848 | 평균iter: 1342 | 평균gap: +0.0328 | 건물수: 16개 | 데이터: 32640행\n","                 IDC | 최종SMAPE: 2.0928 | 평균SMAPE: 2.6301 | 평균iter: 2057 | 평균gap: +0.0136 | 건물수:  9개 | 데이터: 18360행\n","              Public | 최종SMAPE: 7.2032 | 평균SMAPE: 6.4509 | 평균iter: 2223 | 평균gap: +0.0251 | 건물수:  8개 | 데이터: 16320행\n","\n","=== 건물 유형별 모델 성능 종합 요약 ===\n","전체 유형별 최종 SMAPE - 평균: 5.570 ± 2.251 | 범위: 2.093 ~ 8.903\n"]}]},{"cell_type":"markdown","source":["### 앙상블 - 소프트보팅"],"metadata":{"id":"nSL1r5hxuEfP"}},{"cell_type":"code","source":["def create_test_predictions_with_weighted_voting(test_data):\n","    \"\"\"테스트 데이터에 대한 가중 소프트 보팅 예측\"\"\"\n","    print(\"=== 테스트 데이터 가중 소프트 보팅 예측 ===\")\n","\n","    # 결과 저장용\n","    final_test_predictions = {}\n","\n","    # 테스트 데이터의 건물별로 처리\n","    test_buildings = test_data['building_number'].unique()\n","\n","    for building_num in test_buildings:\n","        print(f\"건물 {building_num} 테스트 예측 중...\")\n","\n","        # 1. 해당 건물의 테스트 데이터\n","        building_test = test_data[test_data['building_number'] == building_num].copy()\n","        building_test = building_test.sort_values('date_time').reset_index(drop=True)\n","\n","        if building_test.empty:\n","            continue\n","\n","        building_type = building_test['building'].iloc[0]\n","        n_test_samples = len(building_test)\n","\n","        # 2. 10개 모델의 예측값과 가중치 수집\n","        all_predictions = []  # shape: (n_models, n_test_samples)\n","        all_weights = []      # shape: (n_models,)\n","        model_info = []\n","\n","        # 2-1. 개별 모델 5폴드 예측\n","        if building_num in individual_models and building_num in individual_cv_results:\n","            models = individual_models[building_num]\n","            cv_results = individual_cv_results[building_num]\n","\n","            # 훈련 데이터로 통계 피처 생성 (전체 훈련 데이터 사용)\n","            building_train = train[train['building_number'] == building_num].copy()\n","            building_train = building_train.sort_values('date_time').reset_index(drop=True)\n","            train_stats = _build_time_stats(building_train)\n","\n","            # 테스트 데이터에 통계 피처 적용\n","            building_test_featured = attach_time_stats(building_test.copy(), train_stats)\n","\n","            for fold in range(5):\n","                if fold < len(models) and fold < len(cv_results):\n","                    try:\n","                        # 테스트 데이터 예측\n","                        X_test = building_test_featured[feature_cols].copy()\n","                        X_test = X_test.drop(columns=['building_number'], errors='ignore')\n","\n","                        dtest = xgb.DMatrix(X_test, feature_names=X_test.columns.tolist())\n","                        test_pred_log = models[fold].predict(dtest)\n","                        test_pred = np.expm1(test_pred_log)\n","\n","                        # 가중치 계산\n","                        fold_smape = cv_results[fold]['smape']\n","                        smape_weight = 1.0 / (fold_smape + 1e-8)\n","                        temporal_weight = (0.7) ** (4 - fold)  # 지수감쇠\n","                        final_weight = smape_weight * temporal_weight\n","\n","                        all_predictions.append(test_pred)\n","                        all_weights.append(final_weight)\n","                        model_info.append({\n","                            'type': 'individual',\n","                            'fold': fold,\n","                            'smape': fold_smape,\n","                            'final_weight': final_weight\n","                        })\n","\n","                        print(f\"  개별 Fold {fold}: 가중치 {final_weight:.4f}\")\n","\n","                    except Exception as e:\n","                        print(f\"  개별 Fold {fold} 예측 실패: {str(e)}\")\n","\n","        # 2-2. 유형별 모델 5폴드 예측\n","        if building_type in building_type_models and building_type in building_type_cv_results:\n","            models = building_type_models[building_type]\n","            cv_results = building_type_cv_results[building_type]\n","\n","            # 해당 유형의 전체 훈련 데이터로 통계 피처 생성\n","            type_train = train[train['building'] == building_type].copy()\n","            type_train = type_train.sort_values('date_time').reset_index(drop=True)\n","            type_train_stats = _build_time_stats(type_train)\n","\n","            # 테스트 데이터에 유형별 통계 피처 적용\n","            building_test_type_featured = attach_time_stats(building_test.copy(), type_train_stats)\n","\n","            for fold in range(5):\n","                if fold < len(models) and fold < len(cv_results):\n","                    try:\n","                        # 테스트 데이터 예측\n","                        X_test = building_test_type_featured[feature_cols].copy()\n","                        X_test = X_test.drop(columns=['building_number'], errors='ignore')\n","\n","                        dtest = xgb.DMatrix(X_test, feature_names=X_test.columns.tolist())\n","                        test_pred_log = models[fold].predict(dtest)\n","                        test_pred = np.expm1(test_pred_log)\n","\n","                        # 가중치 계산\n","                        fold_smape = cv_results[fold]['smape']\n","                        smape_weight = 1.0 / (fold_smape + 1e-8)\n","                        temporal_weight = (0.7) ** (4 - fold)\n","                        final_weight = smape_weight * temporal_weight\n","\n","                        all_predictions.append(test_pred)\n","                        all_weights.append(final_weight)\n","                        model_info.append({\n","                            'type': 'type',\n","                            'fold': fold,\n","                            'smape': fold_smape,\n","                            'final_weight': final_weight\n","                        })\n","\n","                        print(f\"  유형 Fold {fold}: 가중치 {final_weight:.4f}\")\n","\n","                    except Exception as e:\n","                        print(f\"  유형 Fold {fold} 예측 실패: {str(e)}\")\n","\n","        # 3. 가중 평균으로 최종 예측\n","        if len(all_predictions) > 0:\n","            # 가중치 정규화\n","            weights_array = np.array(all_weights)\n","            weights_normalized = weights_array / np.sum(weights_array)\n","\n","            # 가중 평균 계산\n","            predictions_array = np.array(all_predictions)  # (n_models, n_samples)\n","            final_pred = np.average(predictions_array, axis=0, weights=weights_normalized)\n","\n","            final_test_predictions[building_num] = final_pred\n","\n","            print(f\"  ✅ 완료: {len(all_predictions)}개 모델 결합, 테스트 샘플 {n_test_samples}개\")\n","            print(f\"      가중치 분포: 개별={np.sum([w for i, w in enumerate(weights_normalized) if model_info[i]['type']=='individual']):.3f}, \"\n","                  f\"유형={np.sum([w for i, w in enumerate(weights_normalized) if model_info[i]['type']=='type']):.3f}\")\n","        else:\n","            print(f\"  ❌ 건물 {building_num}: 사용 가능한 모델 없음\")\n","\n","    print(f\"\\n=== 테스트 예측 완료 ===\")\n","    print(f\"예측 완료 건물 수: {len(final_test_predictions)}\")\n","\n","    return final_test_predictions\n","\n","\n","def save_test_predictions(final_test_predictions, test_data, output_path='submission.csv'):\n","    \"\"\"테스트 예측 결과를 제출 형태로 저장 (num_date_answer 형식 with hour)\"\"\"\n","    print(\"\\n=== 제출 파일 생성 ===\")\n","\n","    # 제출 데이터프레임 준비\n","    submission_rows = []\n","\n","    for building_num in sorted(test_data['building_number'].unique()):\n","        if building_num in final_test_predictions:\n","            building_test = test_data[test_data['building_number'] == building_num].copy()\n","            building_test = building_test.sort_values('date_time').reset_index(drop=True)\n","            predictions = final_test_predictions[building_num]\n","\n","            for idx, (_, row) in enumerate(building_test.iterrows()):\n","                if idx < len(predictions):\n","                    # datetime을 파싱\n","                    dt = pd.to_datetime(row['date_time'])\n","\n","                    # YYYYMMDD 형식으로 날짜 변환\n","                    date_str = dt.strftime('%Y%m%d')\n","\n","                    # 시간을 2자리 형식으로 변환 (00, 01, 02, ...)\n","                    hour_str = dt.strftime('%H')\n","\n","                    # num_date 형식 생성 (building_num_YYYYMMDD HH)\n","                    num_date_id = f\"{building_num}_{date_str} {hour_str}\"\n","\n","                    submission_rows.append({\n","                        'num_date_time': num_date_id,\n","                        'answer': predictions[idx]\n","                    })\n","        else:\n","            print(f\"경고: 건물 {building_num}의 예측값이 없습니다\")\n","\n","    # DataFrame 생성\n","    submission_df = pd.DataFrame(submission_rows)\n","\n","    # 음수 예측값 처리\n","    negative_count = np.sum(submission_df['answer'] < 0)\n","    if negative_count > 0:\n","        print(f\"음수 예측값 {negative_count}개를 0으로 조정\")\n","        submission_df['answer'] = np.maximum(submission_df['answer'], 0)\n","\n","    # CSV 저장\n","    submission_df.to_csv(output_path, index=False)\n","\n","    print(f\"✅ 제출 파일 저장: {output_path}\")\n","    print(f\"   총 예측값 수: {len(submission_df)}\")\n","    print(f\"   예측값 범위: {submission_df['answer'].min():.2f} ~ {submission_df['answer'].max():.2f}\")\n","    print(f\"   예측값 평균: {submission_df['answer'].mean():.2f}\")\n","    print(f\"   샘플 ID 형식: {submission_df['num_date_answer'].iloc[0] if len(submission_df) > 0 else 'N/A'}\")\n","\n","    return submission_df\n","\n","# 🚀 최종 테스트 예측 실행\n","print(\"\\n\" + \"=\"*60)\n","print(\"가중 소프트 보팅 기반 테스트 예측\")\n","print(\"=\"*60)\n","\n","# 1. 테스트 예측 생성\n","final_test_predictions = create_test_predictions_with_weighted_voting(test)\n","\n","# 2. 제출 파일 저장\n","submission_df = save_test_predictions(final_test_predictions, test, 'weighted_soft_voting_submission.csv')\n","\n","# 3. 최종 요약\n","print(f\"\\n🎯 최종 요약:\")\n","print(f\"   - 사용된 가중치: SMAPE 역수 × 지수감쇠(0.7^(4-fold))\")\n","print(f\"   - 최대 모델 수: 10개 (개별 5폴드 + 유형 5폴드)\")\n","print(f\"   - 예측 완료 건물: {len(final_test_predictions)}개\")\n","print(f\"   - 제출 파일 형식: num_date_answer (건물번호_날짜 시간), answer (예측값)\")\n","print(f\"   - 샘플 형식: 1_20240825 00, 1_20240825 01, ...\")\n","print(f\"   - 제출 파일: weighted_soft_voting_submission.csv\")\n","print(f\"✅ 완료!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OD9xjHLCwf1I","executionInfo":{"status":"ok","timestamp":1756067924391,"user_tz":-540,"elapsed":38426,"user":{"displayName":"송상현","userId":"05825752637342282552"}},"outputId":"d1257144-96f6-4b7f-a9b4-1ec8a86d0036"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","가중 소프트 보팅 기반 테스트 예측\n","============================================================\n","=== 테스트 데이터 가중 소프트 보팅 예측 ===\n","건물 1 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0200\n","  개별 Fold 1: 가중치 0.0382\n","  개별 Fold 2: 가중치 0.0542\n","  개별 Fold 3: 가중치 0.0791\n","  개별 Fold 4: 가중치 0.1001\n","  유형 Fold 0: 가중치 0.0324\n","  유형 Fold 1: 가중치 0.0410\n","  유형 Fold 2: 가중치 0.0416\n","  유형 Fold 3: 가중치 0.0821\n","  유형 Fold 4: 가중치 0.1390\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.464, 유형=0.536\n","건물 2 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0446\n","  개별 Fold 1: 가중치 0.0474\n","  개별 Fold 2: 가중치 0.0828\n","  개별 Fold 3: 가중치 0.0996\n","  개별 Fold 4: 가중치 0.1816\n","  유형 Fold 0: 가중치 0.0588\n","  유형 Fold 1: 가중치 0.0995\n","  유형 Fold 2: 가중치 0.1645\n","  유형 Fold 3: 가중치 0.2523\n","  유형 Fold 4: 가중치 0.2762\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.349, 유형=0.651\n","건물 3 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0512\n","  개별 Fold 1: 가중치 0.1104\n","  개별 Fold 2: 가중치 0.1583\n","  개별 Fold 3: 가중치 0.1532\n","  개별 Fold 4: 가중치 0.2167\n","  유형 Fold 0: 가중치 0.1091\n","  유형 Fold 1: 가중치 0.1194\n","  유형 Fold 2: 가중치 0.2052\n","  유형 Fold 3: 가중치 0.2880\n","  유형 Fold 4: 가중치 0.3288\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.396, 유형=0.604\n","건물 4 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0403\n","  개별 Fold 1: 가중치 0.0637\n","  개별 Fold 2: 가중치 0.0993\n","  개별 Fold 3: 가중치 0.1390\n","  개별 Fold 4: 가중치 0.1707\n","  유형 Fold 0: 가중치 0.0324\n","  유형 Fold 1: 가중치 0.0410\n","  유형 Fold 2: 가중치 0.0416\n","  유형 Fold 3: 가중치 0.0821\n","  유형 Fold 4: 가중치 0.1390\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.604, 유형=0.396\n","건물 5 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0746\n","  개별 Fold 1: 가중치 0.1100\n","  개별 Fold 2: 가중치 0.1266\n","  개별 Fold 3: 가중치 0.2931\n","  개별 Fold 4: 가중치 0.2207\n","  유형 Fold 0: 가중치 0.0535\n","  유형 Fold 1: 가중치 0.0667\n","  유형 Fold 2: 가중치 0.1623\n","  유형 Fold 3: 가중치 0.1354\n","  유형 Fold 4: 가중치 0.1123\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.609, 유형=0.391\n","건물 6 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0230\n","  개별 Fold 1: 가중치 0.0391\n","  개별 Fold 2: 가중치 0.0642\n","  개별 Fold 3: 가중치 0.0421\n","  개별 Fold 4: 가중치 0.0789\n","  유형 Fold 0: 가중치 0.0588\n","  유형 Fold 1: 가중치 0.0995\n","  유형 Fold 2: 가중치 0.1645\n","  유형 Fold 3: 가중치 0.2523\n","  유형 Fold 4: 가중치 0.2762\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.225, 유형=0.775\n","건물 7 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0170\n","  개별 Fold 1: 가중치 0.0257\n","  개별 Fold 2: 가중치 0.0057\n","  개별 Fold 3: 가중치 0.0886\n","  개별 Fold 4: 가중치 0.2789\n","  유형 Fold 0: 가중치 0.0454\n","  유형 Fold 1: 가중치 0.0629\n","  유형 Fold 2: 가중치 0.1000\n","  유형 Fold 3: 가중치 0.1297\n","  유형 Fold 4: 가중치 0.1678\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.451, 유형=0.549\n","건물 8 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0295\n","  개별 Fold 1: 가중치 0.0210\n","  개별 Fold 2: 가중치 0.0516\n","  개별 Fold 3: 가중치 0.0544\n","  개별 Fold 4: 가중치 0.0966\n","  유형 Fold 0: 가중치 0.0535\n","  유형 Fold 1: 가중치 0.0667\n","  유형 Fold 2: 가중치 0.1623\n","  유형 Fold 3: 가중치 0.1354\n","  유형 Fold 4: 가중치 0.1123\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.323, 유형=0.677\n","건물 9 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0396\n","  개별 Fold 1: 가중치 0.0181\n","  개별 Fold 2: 가중치 0.0782\n","  개별 Fold 3: 가중치 0.1452\n","  개별 Fold 4: 가중치 0.1490\n","  유형 Fold 0: 가중치 0.0324\n","  유형 Fold 1: 가중치 0.0410\n","  유형 Fold 2: 가중치 0.0416\n","  유형 Fold 3: 가중치 0.0821\n","  유형 Fold 4: 가중치 0.1390\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.561, 유형=0.439\n","건물 10 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0451\n","  개별 Fold 1: 가중치 0.0178\n","  개별 Fold 2: 가중치 0.0840\n","  개별 Fold 3: 가중치 0.1142\n","  개별 Fold 4: 가중치 0.0296\n","  유형 Fold 0: 가중치 0.0324\n","  유형 Fold 1: 가중치 0.0410\n","  유형 Fold 2: 가중치 0.0416\n","  유형 Fold 3: 가중치 0.0821\n","  유형 Fold 4: 가중치 0.1390\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.464, 유형=0.536\n","건물 11 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0162\n","  개별 Fold 1: 가중치 0.0444\n","  개별 Fold 2: 가중치 0.0746\n","  개별 Fold 3: 가중치 0.1640\n","  개별 Fold 4: 가중치 0.2235\n","  유형 Fold 0: 가중치 0.0442\n","  유형 Fold 1: 가중치 0.0575\n","  유형 Fold 2: 가중치 0.1204\n","  유형 Fold 3: 가중치 0.1906\n","  유형 Fold 4: 가중치 0.1973\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.461, 유형=0.539\n","건물 12 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0338\n","  개별 Fold 1: 가중치 0.0596\n","  개별 Fold 2: 가중치 0.2025\n","  개별 Fold 3: 가중치 0.1564\n","  개별 Fold 4: 가중치 0.2291\n","  유형 Fold 0: 가중치 0.0535\n","  유형 Fold 1: 가중치 0.0667\n","  유형 Fold 2: 가중치 0.1623\n","  유형 Fold 3: 가중치 0.1354\n","  유형 Fold 4: 가중치 0.1123\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.562, 유형=0.438\n","건물 13 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0411\n","  개별 Fold 1: 가중치 0.0894\n","  개별 Fold 2: 가중치 0.0912\n","  개별 Fold 3: 가중치 0.0631\n","  개별 Fold 4: 가중치 0.1285\n","  유형 Fold 0: 가중치 0.0407\n","  유형 Fold 1: 가중치 0.0194\n","  유형 Fold 2: 가중치 0.0526\n","  유형 Fold 3: 가중치 0.1086\n","  유형 Fold 4: 가중치 0.1163\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.550, 유형=0.450\n","건물 14 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0336\n","  개별 Fold 1: 가중치 0.0756\n","  개별 Fold 2: 가중치 0.1632\n","  개별 Fold 3: 가중치 0.1478\n","  개별 Fold 4: 가중치 0.2290\n","  유형 Fold 0: 가중치 0.0535\n","  유형 Fold 1: 가중치 0.0667\n","  유형 Fold 2: 가중치 0.1623\n","  유형 Fold 3: 가중치 0.1354\n","  유형 Fold 4: 가중치 0.1123\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.550, 유형=0.450\n","건물 15 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0345\n","  개별 Fold 1: 가중치 0.0734\n","  개별 Fold 2: 가중치 0.1154\n","  개별 Fold 3: 가중치 0.0935\n","  개별 Fold 4: 가중치 0.1250\n","  유형 Fold 0: 가중치 0.0407\n","  유형 Fold 1: 가중치 0.0194\n","  유형 Fold 2: 가중치 0.0526\n","  유형 Fold 3: 가중치 0.1086\n","  유형 Fold 4: 가중치 0.1163\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.567, 유형=0.433\n","건물 16 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0666\n","  개별 Fold 1: 가중치 0.1181\n","  개별 Fold 2: 가중치 0.1097\n","  개별 Fold 3: 가중치 0.0969\n","  개별 Fold 4: 가중치 0.1952\n","  유형 Fold 0: 가중치 0.0588\n","  유형 Fold 1: 가중치 0.0995\n","  유형 Fold 2: 가중치 0.1645\n","  유형 Fold 3: 가중치 0.2523\n","  유형 Fold 4: 가중치 0.2762\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.408, 유형=0.592\n","건물 17 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0263\n","  개별 Fold 1: 가중치 0.0660\n","  개별 Fold 2: 가중치 0.1458\n","  개별 Fold 3: 가중치 0.1544\n","  개별 Fold 4: 가중치 0.3123\n","  유형 Fold 0: 가중치 0.1091\n","  유형 Fold 1: 가중치 0.1194\n","  유형 Fold 2: 가중치 0.2052\n","  유형 Fold 3: 가중치 0.2880\n","  유형 Fold 4: 가중치 0.3288\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.401, 유형=0.599\n","건물 18 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0557\n","  개별 Fold 1: 가중치 0.0534\n","  개별 Fold 2: 가중치 0.0886\n","  개별 Fold 3: 가중치 0.1555\n","  개별 Fold 4: 가중치 0.1883\n","  유형 Fold 0: 가중치 0.0364\n","  유형 Fold 1: 가중치 0.0441\n","  유형 Fold 2: 가중치 0.0822\n","  유형 Fold 3: 가중치 0.0865\n","  유형 Fold 4: 가중치 0.2489\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.521, 유형=0.479\n","건물 19 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0084\n","  개별 Fold 1: 가중치 0.0560\n","  개별 Fold 2: 가중치 0.0685\n","  개별 Fold 3: 가중치 0.0933\n","  개별 Fold 4: 가중치 0.0732\n","  유형 Fold 0: 가중치 0.0364\n","  유형 Fold 1: 가중치 0.0441\n","  유형 Fold 2: 가중치 0.0822\n","  유형 Fold 3: 가중치 0.0865\n","  유형 Fold 4: 가중치 0.2489\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.375, 유형=0.625\n","건물 20 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.1408\n","  개별 Fold 1: 가중치 0.2155\n","  개별 Fold 2: 가중치 0.3387\n","  개별 Fold 3: 가중치 0.2746\n","  개별 Fold 4: 가중치 0.3783\n","  유형 Fold 0: 가중치 0.0588\n","  유형 Fold 1: 가중치 0.0995\n","  유형 Fold 2: 가중치 0.1645\n","  유형 Fold 3: 가중치 0.2523\n","  유형 Fold 4: 가중치 0.2762\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.613, 유형=0.387\n","건물 21 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0467\n","  개별 Fold 1: 가중치 0.1192\n","  개별 Fold 2: 가중치 0.2187\n","  개별 Fold 3: 가중치 0.1612\n","  개별 Fold 4: 가중치 0.3629\n","  유형 Fold 0: 가중치 0.1091\n","  유형 Fold 1: 가중치 0.1194\n","  유형 Fold 2: 가중치 0.2052\n","  유형 Fold 3: 가중치 0.2880\n","  유형 Fold 4: 가중치 0.3288\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.464, 유형=0.536\n","건물 22 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0294\n","  개별 Fold 1: 가중치 0.0619\n","  개별 Fold 2: 가중치 0.0859\n","  개별 Fold 3: 가중치 0.0797\n","  개별 Fold 4: 가중치 0.2234\n","  유형 Fold 0: 가중치 0.0535\n","  유형 Fold 1: 가중치 0.0667\n","  유형 Fold 2: 가중치 0.1623\n","  유형 Fold 3: 가중치 0.1354\n","  유형 Fold 4: 가중치 0.1123\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.475, 유형=0.525\n","건물 23 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0127\n","  개별 Fold 1: 가중치 0.0341\n","  개별 Fold 2: 가중치 0.0395\n","  개별 Fold 3: 가중치 0.0222\n","  개별 Fold 4: 가중치 0.0366\n","  유형 Fold 0: 가중치 0.0407\n","  유형 Fold 1: 가중치 0.0194\n","  유형 Fold 2: 가중치 0.0526\n","  유형 Fold 3: 가중치 0.1086\n","  유형 Fold 4: 가중치 0.1163\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.300, 유형=0.700\n","건물 24 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0343\n","  개별 Fold 1: 가중치 0.0816\n","  개별 Fold 2: 가중치 0.1339\n","  개별 Fold 3: 가중치 0.0942\n","  개별 Fold 4: 가중치 0.1549\n","  유형 Fold 0: 가중치 0.0535\n","  유형 Fold 1: 가중치 0.0667\n","  유형 Fold 2: 가중치 0.1623\n","  유형 Fold 3: 가중치 0.1354\n","  유형 Fold 4: 가중치 0.1123\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.485, 유형=0.515\n","건물 25 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0082\n","  개별 Fold 1: 가중치 0.0172\n","  개별 Fold 2: 가중치 0.0486\n","  개별 Fold 3: 가중치 0.0743\n","  개별 Fold 4: 가중치 0.1436\n","  유형 Fold 0: 가중치 0.0442\n","  유형 Fold 1: 가중치 0.0575\n","  유형 Fold 2: 가중치 0.1204\n","  유형 Fold 3: 가중치 0.1906\n","  유형 Fold 4: 가중치 0.1973\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.324, 유형=0.676\n","건물 26 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0117\n","  개별 Fold 1: 가중치 0.0307\n","  개별 Fold 2: 가중치 0.0385\n","  개별 Fold 3: 가중치 0.0534\n","  개별 Fold 4: 가중치 0.0725\n","  유형 Fold 0: 가중치 0.0454\n","  유형 Fold 1: 가중치 0.0629\n","  유형 Fold 2: 가중치 0.1000\n","  유형 Fold 3: 가중치 0.1297\n","  유형 Fold 4: 가중치 0.1678\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.290, 유형=0.710\n","건물 27 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0180\n","  개별 Fold 1: 가중치 0.0188\n","  개별 Fold 2: 가중치 0.0402\n","  개별 Fold 3: 가중치 0.0462\n","  개별 Fold 4: 가중치 0.0908\n","  유형 Fold 0: 가중치 0.0364\n","  유형 Fold 1: 가중치 0.0441\n","  유형 Fold 2: 가중치 0.0822\n","  유형 Fold 3: 가중치 0.0865\n","  유형 Fold 4: 가중치 0.2489\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.300, 유형=0.700\n","건물 28 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0294\n","  개별 Fold 1: 가중치 0.0279\n","  개별 Fold 2: 가중치 0.0839\n","  개별 Fold 3: 가중치 0.0979\n","  개별 Fold 4: 가중치 0.2060\n","  유형 Fold 0: 가중치 0.0324\n","  유형 Fold 1: 가중치 0.0410\n","  유형 Fold 2: 가중치 0.0416\n","  유형 Fold 3: 가중치 0.0821\n","  유형 Fold 4: 가중치 0.1390\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.570, 유형=0.430\n","건물 29 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0376\n","  개별 Fold 1: 가중치 0.0264\n","  개별 Fold 2: 가중치 0.0416\n","  개별 Fold 3: 가중치 0.2278\n","  개별 Fold 4: 가중치 0.0718\n","  유형 Fold 0: 가중치 0.0364\n","  유형 Fold 1: 가중치 0.0441\n","  유형 Fold 2: 가중치 0.0822\n","  유형 Fold 3: 가중치 0.0865\n","  유형 Fold 4: 가중치 0.2489\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.448, 유형=0.552\n","건물 30 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.2631\n","  개별 Fold 1: 가중치 0.2341\n","  개별 Fold 2: 가중치 0.2325\n","  개별 Fold 3: 가중치 0.6901\n","  개별 Fold 4: 가중치 2.2119\n","  유형 Fold 0: 가중치 0.0533\n","  유형 Fold 1: 가중치 0.1942\n","  유형 Fold 2: 가중치 0.3145\n","  유형 Fold 3: 가중치 0.2170\n","  유형 Fold 4: 가중치 0.4778\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.743, 유형=0.257\n","건물 31 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0292\n","  개별 Fold 1: 가중치 0.0475\n","  개별 Fold 2: 가중치 0.0576\n","  개별 Fold 3: 가중치 0.1837\n","  개별 Fold 4: 가중치 0.2291\n","  유형 Fold 0: 가중치 0.0442\n","  유형 Fold 1: 가중치 0.0575\n","  유형 Fold 2: 가중치 0.1204\n","  유형 Fold 3: 가중치 0.1906\n","  유형 Fold 4: 가중치 0.1973\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.473, 유형=0.527\n","건물 32 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0156\n","  개별 Fold 1: 가중치 0.0192\n","  개별 Fold 2: 가중치 0.0791\n","  개별 Fold 3: 가중치 0.0512\n","  개별 Fold 4: 가중치 0.0780\n","  유형 Fold 0: 가중치 0.0364\n","  유형 Fold 1: 가중치 0.0441\n","  유형 Fold 2: 가중치 0.0822\n","  유형 Fold 3: 가중치 0.0865\n","  유형 Fold 4: 가중치 0.2489\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.328, 유형=0.672\n","건물 33 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0202\n","  개별 Fold 1: 가중치 0.0371\n","  개별 Fold 2: 가중치 0.0468\n","  개별 Fold 3: 가중치 0.0747\n","  개별 Fold 4: 가중치 0.0683\n","  유형 Fold 0: 가중치 0.0407\n","  유형 Fold 1: 가중치 0.0594\n","  유형 Fold 2: 가중치 0.0958\n","  유형 Fold 3: 가중치 0.0848\n","  유형 Fold 4: 가중치 0.1388\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.371, 유형=0.629\n","건물 34 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0435\n","  개별 Fold 1: 가중치 0.1032\n","  개별 Fold 2: 가중치 0.1340\n","  개별 Fold 3: 가중치 0.1877\n","  개별 Fold 4: 가중치 0.3845\n","  유형 Fold 0: 가중치 0.0364\n","  유형 Fold 1: 가중치 0.0441\n","  유형 Fold 2: 가중치 0.0822\n","  유형 Fold 3: 가중치 0.0865\n","  유형 Fold 4: 가중치 0.2489\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.631, 유형=0.369\n","건물 35 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.2206\n","  개별 Fold 1: 가중치 0.4312\n","  개별 Fold 2: 가중치 0.8703\n","  개별 Fold 3: 가중치 1.0781\n","  개별 Fold 4: 가중치 1.5999\n","  유형 Fold 0: 가중치 0.0533\n","  유형 Fold 1: 가중치 0.1942\n","  유형 Fold 2: 가중치 0.3145\n","  유형 Fold 3: 가중치 0.2170\n","  유형 Fold 4: 가중치 0.4778\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.770, 유형=0.230\n","건물 36 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.1133\n","  개별 Fold 1: 가중치 0.4715\n","  개별 Fold 2: 가중치 0.8368\n","  개별 Fold 3: 가중치 0.7700\n","  개별 Fold 4: 가중치 1.4724\n","  유형 Fold 0: 가중치 0.0533\n","  유형 Fold 1: 가중치 0.1942\n","  유형 Fold 2: 가중치 0.3145\n","  유형 Fold 3: 가중치 0.2170\n","  유형 Fold 4: 가중치 0.4778\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.745, 유형=0.255\n","건물 37 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0341\n","  개별 Fold 1: 가중치 0.0437\n","  개별 Fold 2: 가중치 0.0840\n","  개별 Fold 3: 가중치 0.0680\n","  개별 Fold 4: 가중치 0.0923\n","  유형 Fold 0: 가중치 0.0407\n","  유형 Fold 1: 가중치 0.0194\n","  유형 Fold 2: 가중치 0.0526\n","  유형 Fold 3: 가중치 0.1086\n","  유형 Fold 4: 가중치 0.1163\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.488, 유형=0.512\n","건물 38 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0468\n","  개별 Fold 1: 가중치 0.1179\n","  개별 Fold 2: 가중치 0.1423\n","  개별 Fold 3: 가중치 0.1133\n","  개별 Fold 4: 가중치 0.2342\n","  유형 Fold 0: 가중치 0.0407\n","  유형 Fold 1: 가중치 0.0594\n","  유형 Fold 2: 가중치 0.0958\n","  유형 Fold 3: 가중치 0.0848\n","  유형 Fold 4: 가중치 0.1388\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.609, 유형=0.391\n","건물 39 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0382\n","  개별 Fold 1: 가중치 0.0686\n","  개별 Fold 2: 가중치 0.1436\n","  개별 Fold 3: 가중치 0.1844\n","  개별 Fold 4: 가중치 0.2964\n","  유형 Fold 0: 가중치 0.1091\n","  유형 Fold 1: 가중치 0.1194\n","  유형 Fold 2: 가중치 0.2052\n","  유형 Fold 3: 가중치 0.2880\n","  유형 Fold 4: 가중치 0.3288\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.410, 유형=0.590\n","건물 40 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0254\n","  개별 Fold 1: 가중치 0.0266\n","  개별 Fold 2: 가중치 0.0741\n","  개별 Fold 3: 가중치 0.0722\n","  개별 Fold 4: 가중치 0.1416\n","  유형 Fold 0: 가중치 0.0364\n","  유형 Fold 1: 가중치 0.0441\n","  유형 Fold 2: 가중치 0.0822\n","  유형 Fold 3: 가중치 0.0865\n","  유형 Fold 4: 가중치 0.2489\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.406, 유형=0.594\n","건물 41 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0746\n","  개별 Fold 1: 가중치 0.1384\n","  개별 Fold 2: 가중치 0.4452\n","  개별 Fold 3: 가중치 0.4565\n","  개별 Fold 4: 가중치 0.5174\n","  유형 Fold 0: 가중치 0.0588\n","  유형 Fold 1: 가중치 0.0995\n","  유형 Fold 2: 가중치 0.1645\n","  유형 Fold 3: 가중치 0.2523\n","  유형 Fold 4: 가중치 0.2762\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.657, 유형=0.343\n","건물 42 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0455\n","  개별 Fold 1: 가중치 0.0992\n","  개별 Fold 2: 가중치 0.1503\n","  개별 Fold 3: 가중치 0.1902\n","  개별 Fold 4: 가중치 0.3033\n","  유형 Fold 0: 가중치 0.1091\n","  유형 Fold 1: 가중치 0.1194\n","  유형 Fold 2: 가중치 0.2052\n","  유형 Fold 3: 가중치 0.2880\n","  유형 Fold 4: 가중치 0.3288\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.429, 유형=0.571\n","건물 43 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0956\n","  개별 Fold 1: 가중치 0.2154\n","  개별 Fold 2: 가중치 0.2922\n","  개별 Fold 3: 가중치 0.2234\n","  개별 Fold 4: 가중치 0.2819\n","  유형 Fold 0: 가중치 0.0533\n","  유형 Fold 1: 가중치 0.1942\n","  유형 Fold 2: 가중치 0.3145\n","  유형 Fold 3: 가중치 0.2170\n","  유형 Fold 4: 가중치 0.4778\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.469, 유형=0.531\n","건물 44 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0398\n","  개별 Fold 1: 가중치 0.0678\n","  개별 Fold 2: 가중치 0.1787\n","  개별 Fold 3: 가중치 0.1854\n","  개별 Fold 4: 가중치 0.1872\n","  유형 Fold 0: 가중치 0.1091\n","  유형 Fold 1: 가중치 0.1194\n","  유형 Fold 2: 가중치 0.2052\n","  유형 Fold 3: 가중치 0.2880\n","  유형 Fold 4: 가중치 0.3288\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.385, 유형=0.615\n","건물 45 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0082\n","  개별 Fold 1: 가중치 0.0413\n","  개별 Fold 2: 가중치 0.0879\n","  개별 Fold 3: 가중치 0.1791\n","  개별 Fold 4: 가중치 0.1266\n","  유형 Fold 0: 가중치 0.0364\n","  유형 Fold 1: 가중치 0.0441\n","  유형 Fold 2: 가중치 0.0822\n","  유형 Fold 3: 가중치 0.0865\n","  유형 Fold 4: 가중치 0.2489\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.471, 유형=0.529\n","건물 46 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0486\n","  개별 Fold 1: 가중치 0.0657\n","  개별 Fold 2: 가중치 0.1203\n","  개별 Fold 3: 가중치 0.0702\n","  개별 Fold 4: 가중치 0.1040\n","  유형 Fold 0: 가중치 0.0535\n","  유형 Fold 1: 가중치 0.0667\n","  유형 Fold 2: 가중치 0.1623\n","  유형 Fold 3: 가중치 0.1354\n","  유형 Fold 4: 가중치 0.1123\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.435, 유형=0.565\n","건물 47 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0531\n","  개별 Fold 1: 가중치 0.1226\n","  개별 Fold 2: 가중치 0.1687\n","  개별 Fold 3: 가중치 0.1055\n","  개별 Fold 4: 가중치 0.1340\n","  유형 Fold 0: 가중치 0.0454\n","  유형 Fold 1: 가중치 0.0629\n","  유형 Fold 2: 가중치 0.1000\n","  유형 Fold 3: 가중치 0.1297\n","  유형 Fold 4: 가중치 0.1678\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.536, 유형=0.464\n","건물 48 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0516\n","  개별 Fold 1: 가중치 0.1071\n","  개별 Fold 2: 가중치 0.1500\n","  개별 Fold 3: 가중치 0.1156\n","  개별 Fold 4: 가중치 0.1432\n","  유형 Fold 0: 가중치 0.1091\n","  유형 Fold 1: 가중치 0.1194\n","  유형 Fold 2: 가중치 0.2052\n","  유형 Fold 3: 가중치 0.2880\n","  유형 Fold 4: 가중치 0.3288\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.351, 유형=0.649\n","건물 49 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0386\n","  개별 Fold 1: 가중치 0.0606\n","  개별 Fold 2: 가중치 0.1091\n","  개별 Fold 3: 가중치 0.0514\n","  개별 Fold 4: 가중치 0.0617\n","  유형 Fold 0: 가중치 0.0407\n","  유형 Fold 1: 가중치 0.0194\n","  유형 Fold 2: 가중치 0.0526\n","  유형 Fold 3: 가중치 0.1086\n","  유형 Fold 4: 가중치 0.1163\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.488, 유형=0.512\n","건물 50 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0448\n","  개별 Fold 1: 가중치 0.0532\n","  개별 Fold 2: 가중치 0.0816\n","  개별 Fold 3: 가중치 0.0847\n","  개별 Fold 4: 가중치 0.1064\n","  유형 Fold 0: 가중치 0.0407\n","  유형 Fold 1: 가중치 0.0594\n","  유형 Fold 2: 가중치 0.0958\n","  유형 Fold 3: 가중치 0.0848\n","  유형 Fold 4: 가중치 0.1388\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.469, 유형=0.531\n","건물 51 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.1313\n","  개별 Fold 1: 가중치 0.2567\n","  개별 Fold 2: 가중치 0.4744\n","  개별 Fold 3: 가중치 0.5141\n","  개별 Fold 4: 가중치 1.0497\n","  유형 Fold 0: 가중치 0.0588\n","  유형 Fold 1: 가중치 0.0995\n","  유형 Fold 2: 가중치 0.1645\n","  유형 Fold 3: 가중치 0.2523\n","  유형 Fold 4: 가중치 0.2762\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.740, 유형=0.260\n","건물 52 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.1224\n","  개별 Fold 1: 가중치 0.1297\n","  개별 Fold 2: 가중치 0.1058\n","  개별 Fold 3: 가중치 0.1867\n","  개별 Fold 4: 가중치 0.1703\n","  유형 Fold 0: 가중치 0.0533\n","  유형 Fold 1: 가중치 0.1942\n","  유형 Fold 2: 가중치 0.3145\n","  유형 Fold 3: 가중치 0.2170\n","  유형 Fold 4: 가중치 0.4778\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.363, 유형=0.637\n","건물 53 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0475\n","  개별 Fold 1: 가중치 0.0615\n","  개별 Fold 2: 가중치 0.0933\n","  개별 Fold 3: 가중치 0.1338\n","  개별 Fold 4: 가중치 0.1031\n","  유형 Fold 0: 가중치 0.0407\n","  유형 Fold 1: 가중치 0.0194\n","  유형 Fold 2: 가중치 0.0526\n","  유형 Fold 3: 가중치 0.1086\n","  유형 Fold 4: 가중치 0.1163\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.565, 유형=0.435\n","건물 54 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0249\n","  개별 Fold 1: 가중치 0.0224\n","  개별 Fold 2: 가중치 0.0318\n","  개별 Fold 3: 가중치 0.0735\n","  개별 Fold 4: 가중치 0.0537\n","  유형 Fold 0: 가중치 0.0364\n","  유형 Fold 1: 가중치 0.0441\n","  유형 Fold 2: 가중치 0.0822\n","  유형 Fold 3: 가중치 0.0865\n","  유형 Fold 4: 가중치 0.2489\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.293, 유형=0.707\n","건물 55 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0506\n","  개별 Fold 1: 가중치 0.1278\n","  개별 Fold 2: 가중치 0.2714\n","  개별 Fold 3: 가중치 0.2890\n","  개별 Fold 4: 가중치 0.6110\n","  유형 Fold 0: 가중치 0.0535\n","  유형 Fold 1: 가중치 0.0667\n","  유형 Fold 2: 가중치 0.1623\n","  유형 Fold 3: 가중치 0.1354\n","  유형 Fold 4: 가중치 0.1123\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.718, 유형=0.282\n","건물 56 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.2600\n","  개별 Fold 1: 가중치 0.3435\n","  개별 Fold 2: 가중치 0.4131\n","  개별 Fold 3: 가중치 0.5815\n","  개별 Fold 4: 가중치 0.8433\n","  유형 Fold 0: 가중치 0.0588\n","  유형 Fold 1: 가중치 0.0995\n","  유형 Fold 2: 가중치 0.1645\n","  유형 Fold 3: 가중치 0.2523\n","  유형 Fold 4: 가중치 0.2762\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.741, 유형=0.259\n","건물 57 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0855\n","  개별 Fold 1: 가중치 0.1540\n","  개별 Fold 2: 가중치 0.3891\n","  개별 Fold 3: 가중치 0.7110\n","  개별 Fold 4: 가중치 1.2685\n","  유형 Fold 0: 가중치 0.0533\n","  유형 Fold 1: 가중치 0.1942\n","  유형 Fold 2: 가중치 0.3145\n","  유형 Fold 3: 가중치 0.2170\n","  유형 Fold 4: 가중치 0.4778\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.675, 유형=0.325\n","건물 58 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0355\n","  개별 Fold 1: 가중치 0.0607\n","  개별 Fold 2: 가중치 0.0951\n","  개별 Fold 3: 가중치 0.1424\n","  개별 Fold 4: 가중치 0.1872\n","  유형 Fold 0: 가중치 0.0454\n","  유형 Fold 1: 가중치 0.0629\n","  유형 Fold 2: 가중치 0.1000\n","  유형 Fold 3: 가중치 0.1297\n","  유형 Fold 4: 가중치 0.1678\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.507, 유형=0.493\n","건물 59 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0129\n","  개별 Fold 1: 가중치 0.0241\n","  개별 Fold 2: 가중치 0.0269\n","  개별 Fold 3: 가중치 0.0440\n","  개별 Fold 4: 가중치 0.0898\n","  유형 Fold 0: 가중치 0.0364\n","  유형 Fold 1: 가중치 0.0441\n","  유형 Fold 2: 가중치 0.0822\n","  유형 Fold 3: 가중치 0.0865\n","  유형 Fold 4: 가중치 0.2489\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.284, 유형=0.716\n","건물 60 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0612\n","  개별 Fold 1: 가중치 0.0732\n","  개별 Fold 2: 가중치 0.1556\n","  개별 Fold 3: 가중치 0.1772\n","  개별 Fold 4: 가중치 0.3653\n","  유형 Fold 0: 가중치 0.0535\n","  유형 Fold 1: 가중치 0.0667\n","  유형 Fold 2: 가중치 0.1623\n","  유형 Fold 3: 가중치 0.1354\n","  유형 Fold 4: 가중치 0.1123\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.611, 유형=0.389\n","건물 61 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0292\n","  개별 Fold 1: 가중치 0.0217\n","  개별 Fold 2: 가중치 0.0859\n","  개별 Fold 3: 가중치 0.1574\n","  개별 Fold 4: 가중치 0.0493\n","  유형 Fold 0: 가중치 0.0454\n","  유형 Fold 1: 가중치 0.0629\n","  유형 Fold 2: 가중치 0.1000\n","  유형 Fold 3: 가중치 0.1297\n","  유형 Fold 4: 가중치 0.1678\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.404, 유형=0.596\n","건물 62 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0497\n","  개별 Fold 1: 가중치 0.1186\n","  개별 Fold 2: 가중치 0.2018\n","  개별 Fold 3: 가중치 0.1540\n","  개별 Fold 4: 가중치 0.2785\n","  유형 Fold 0: 가중치 0.0407\n","  유형 Fold 1: 가중치 0.0194\n","  유형 Fold 2: 가중치 0.0526\n","  유형 Fold 3: 가중치 0.1086\n","  유형 Fold 4: 가중치 0.1163\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.704, 유형=0.296\n","건물 63 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0204\n","  개별 Fold 1: 가중치 0.0229\n","  개별 Fold 2: 가중치 0.0643\n","  개별 Fold 3: 가중치 0.0514\n","  개별 Fold 4: 가중치 0.0786\n","  유형 Fold 0: 가중치 0.0364\n","  유형 Fold 1: 가중치 0.0441\n","  유형 Fold 2: 가중치 0.0822\n","  유형 Fold 3: 가중치 0.0865\n","  유형 Fold 4: 가중치 0.2489\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.323, 유형=0.677\n","건물 64 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0503\n","  개별 Fold 1: 가중치 0.1242\n","  개별 Fold 2: 가중치 0.1627\n","  개별 Fold 3: 가중치 0.3087\n","  개별 Fold 4: 가중치 0.4154\n","  유형 Fold 0: 가중치 0.0533\n","  유형 Fold 1: 가중치 0.1942\n","  유형 Fold 2: 가중치 0.3145\n","  유형 Fold 3: 가중치 0.2170\n","  유형 Fold 4: 가중치 0.4778\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.458, 유형=0.542\n","건물 65 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0392\n","  개별 Fold 1: 가중치 0.0436\n","  개별 Fold 2: 가중치 0.1127\n","  개별 Fold 3: 가중치 0.1229\n","  개별 Fold 4: 가중치 0.1280\n","  유형 Fold 0: 가중치 0.0442\n","  유형 Fold 1: 가중치 0.0575\n","  유형 Fold 2: 가중치 0.1204\n","  유형 Fold 3: 가중치 0.1906\n","  유형 Fold 4: 가중치 0.1973\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.423, 유형=0.577\n","건물 66 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0420\n","  개별 Fold 1: 가중치 0.0901\n","  개별 Fold 2: 가중치 0.1041\n","  개별 Fold 3: 가중치 0.1427\n","  개별 Fold 4: 가중치 0.1319\n","  유형 Fold 0: 가중치 0.0407\n","  유형 Fold 1: 가중치 0.0594\n","  유형 Fold 2: 가중치 0.0958\n","  유형 Fold 3: 가중치 0.0848\n","  유형 Fold 4: 가중치 0.1388\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.549, 유형=0.451\n","건물 67 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0119\n","  개별 Fold 1: 가중치 0.0061\n","  개별 Fold 2: 가중치 0.1621\n","  개별 Fold 3: 가중치 0.2827\n","  개별 Fold 4: 가중치 0.4995\n","  유형 Fold 0: 가중치 0.0533\n","  유형 Fold 1: 가중치 0.1942\n","  유형 Fold 2: 가중치 0.3145\n","  유형 Fold 3: 가중치 0.2170\n","  유형 Fold 4: 가중치 0.4778\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.434, 유형=0.566\n","건물 68 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0346\n","  개별 Fold 1: 가중치 0.0125\n","  개별 Fold 2: 가중치 0.0550\n","  개별 Fold 3: 가중치 0.0673\n","  개별 Fold 4: 가중치 0.0796\n","  유형 Fold 0: 가중치 0.0407\n","  유형 Fold 1: 가중치 0.0594\n","  유형 Fold 2: 가중치 0.0958\n","  유형 Fold 3: 가중치 0.0848\n","  유형 Fold 4: 가중치 0.1388\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.373, 유형=0.627\n","건물 69 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0818\n","  개별 Fold 1: 가중치 0.1401\n","  개별 Fold 2: 가중치 0.1549\n","  개별 Fold 3: 가중치 0.2221\n","  개별 Fold 4: 가중치 0.2798\n","  유형 Fold 0: 가중치 0.0454\n","  유형 Fold 1: 가중치 0.0629\n","  유형 Fold 2: 가중치 0.1000\n","  유형 Fold 3: 가중치 0.1297\n","  유형 Fold 4: 가중치 0.1678\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.635, 유형=0.365\n","건물 70 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0152\n","  개별 Fold 1: 가중치 0.0258\n","  개별 Fold 2: 가중치 0.1020\n","  개별 Fold 3: 가중치 0.1012\n","  개별 Fold 4: 가중치 0.2511\n","  유형 Fold 0: 가중치 0.0442\n","  유형 Fold 1: 가중치 0.0575\n","  유형 Fold 2: 가중치 0.1204\n","  유형 Fold 3: 가중치 0.1906\n","  유형 Fold 4: 가중치 0.1973\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.448, 유형=0.552\n","건물 71 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0162\n","  개별 Fold 1: 가중치 0.0459\n","  개별 Fold 2: 가중치 0.0916\n","  개별 Fold 3: 가중치 0.1687\n","  개별 Fold 4: 가중치 0.1867\n","  유형 Fold 0: 가중치 0.0442\n","  유형 Fold 1: 가중치 0.0575\n","  유형 Fold 2: 가중치 0.1204\n","  유형 Fold 3: 가중치 0.1906\n","  유형 Fold 4: 가중치 0.1973\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.455, 유형=0.545\n","건물 72 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0316\n","  개별 Fold 1: 가중치 0.0382\n","  개별 Fold 2: 가중치 0.0819\n","  개별 Fold 3: 가중치 0.0711\n","  개별 Fold 4: 가중치 0.1086\n","  유형 Fold 0: 가중치 0.0407\n","  유형 Fold 1: 가중치 0.0594\n","  유형 Fold 2: 가중치 0.0958\n","  유형 Fold 3: 가중치 0.0848\n","  유형 Fold 4: 가중치 0.1388\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.441, 유형=0.559\n","건물 73 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0334\n","  개별 Fold 1: 가중치 0.0449\n","  개별 Fold 2: 가중치 0.0728\n","  개별 Fold 3: 가중치 0.1201\n","  개별 Fold 4: 가중치 0.1727\n","  유형 Fold 0: 가중치 0.0364\n","  유형 Fold 1: 가중치 0.0441\n","  유형 Fold 2: 가중치 0.0822\n","  유형 Fold 3: 가중치 0.0865\n","  유형 Fold 4: 가중치 0.2489\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.471, 유형=0.529\n","건물 74 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0378\n","  개별 Fold 1: 가중치 0.0389\n","  개별 Fold 2: 가중치 0.0791\n","  개별 Fold 3: 가중치 0.0947\n","  개별 Fold 4: 가중치 0.1605\n","  유형 Fold 0: 가중치 0.0364\n","  유형 Fold 1: 가중치 0.0441\n","  유형 Fold 2: 가중치 0.0822\n","  유형 Fold 3: 가중치 0.0865\n","  유형 Fold 4: 가중치 0.2489\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.452, 유형=0.548\n","건물 75 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0526\n","  개별 Fold 1: 가중치 0.0736\n","  개별 Fold 2: 가중치 0.1135\n","  개별 Fold 3: 가중치 0.3328\n","  개별 Fold 4: 가중치 0.3117\n","  유형 Fold 0: 가중치 0.1091\n","  유형 Fold 1: 가중치 0.1194\n","  유형 Fold 2: 가중치 0.2052\n","  유형 Fold 3: 가중치 0.2880\n","  유형 Fold 4: 가중치 0.3288\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.457, 유형=0.543\n","건물 76 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0317\n","  개별 Fold 1: 가중치 0.2442\n","  개별 Fold 2: 가중치 0.0546\n","  개별 Fold 3: 가중치 0.3556\n","  개별 Fold 4: 가중치 0.7151\n","  유형 Fold 0: 가중치 0.0588\n","  유형 Fold 1: 가중치 0.0995\n","  유형 Fold 2: 가중치 0.1645\n","  유형 Fold 3: 가중치 0.2523\n","  유형 Fold 4: 가중치 0.2762\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.622, 유형=0.378\n","건물 77 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0141\n","  개별 Fold 1: 가중치 0.0278\n","  개별 Fold 2: 가중치 0.0462\n","  개별 Fold 3: 가중치 0.0960\n","  개별 Fold 4: 가중치 0.0687\n","  유형 Fold 0: 가중치 0.0324\n","  유형 Fold 1: 가중치 0.0410\n","  유형 Fold 2: 가중치 0.0416\n","  유형 Fold 3: 가중치 0.0821\n","  유형 Fold 4: 가중치 0.1390\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.429, 유형=0.571\n","건물 78 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0169\n","  개별 Fold 1: 가중치 0.0491\n","  개별 Fold 2: 가중치 0.0768\n","  개별 Fold 3: 가중치 0.1679\n","  개별 Fold 4: 가중치 0.2188\n","  유형 Fold 0: 가중치 0.0454\n","  유형 Fold 1: 가중치 0.0629\n","  유형 Fold 2: 가중치 0.1000\n","  유형 Fold 3: 가중치 0.1297\n","  유형 Fold 4: 가중치 0.1678\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.511, 유형=0.489\n","건물 79 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0355\n","  개별 Fold 1: 가중치 0.0388\n","  개별 Fold 2: 가중치 0.0912\n","  개별 Fold 3: 가중치 0.1630\n","  개별 Fold 4: 가중치 0.0828\n","  유형 Fold 0: 가중치 0.0364\n","  유형 Fold 1: 가중치 0.0441\n","  유형 Fold 2: 가중치 0.0822\n","  유형 Fold 3: 가중치 0.0865\n","  유형 Fold 4: 가중치 0.2489\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.452, 유형=0.548\n","건물 80 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0129\n","  개별 Fold 1: 가중치 0.0335\n","  개별 Fold 2: 가중치 0.0359\n","  개별 Fold 3: 가중치 0.0950\n","  개별 Fold 4: 가중치 0.1632\n","  유형 Fold 0: 가중치 0.0407\n","  유형 Fold 1: 가중치 0.0594\n","  유형 Fold 2: 가중치 0.0958\n","  유형 Fold 3: 가중치 0.0848\n","  유형 Fold 4: 가중치 0.1388\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.448, 유형=0.552\n","건물 81 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0688\n","  개별 Fold 1: 가중치 0.0724\n","  개별 Fold 2: 가중치 0.0479\n","  개별 Fold 3: 가중치 0.1027\n","  개별 Fold 4: 가중치 0.2165\n","  유형 Fold 0: 가중치 0.0533\n","  유형 Fold 1: 가중치 0.1942\n","  유형 Fold 2: 가중치 0.3145\n","  유형 Fold 3: 가중치 0.2170\n","  유형 Fold 4: 가중치 0.4778\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.288, 유형=0.712\n","건물 82 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0383\n","  개별 Fold 1: 가중치 0.0553\n","  개별 Fold 2: 가중치 0.1395\n","  개별 Fold 3: 가중치 0.1262\n","  개별 Fold 4: 가중치 0.1866\n","  유형 Fold 0: 가중치 0.0454\n","  유형 Fold 1: 가중치 0.0629\n","  유형 Fold 2: 가중치 0.1000\n","  유형 Fold 3: 가중치 0.1297\n","  유형 Fold 4: 가중치 0.1678\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.519, 유형=0.481\n","건물 83 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0691\n","  개별 Fold 1: 가중치 0.1382\n","  개별 Fold 2: 가중치 0.2268\n","  개별 Fold 3: 가중치 0.2253\n","  개별 Fold 4: 가중치 0.3368\n","  유형 Fold 0: 가중치 0.0407\n","  유형 Fold 1: 가중치 0.0194\n","  유형 Fold 2: 가중치 0.0526\n","  유형 Fold 3: 가중치 0.1086\n","  유형 Fold 4: 가중치 0.1163\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.747, 유형=0.253\n","건물 84 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0430\n","  개별 Fold 1: 가중치 0.0498\n","  개별 Fold 2: 가중치 0.1508\n","  개별 Fold 3: 가중치 0.1558\n","  개별 Fold 4: 가중치 0.1956\n","  유형 Fold 0: 가중치 0.0324\n","  유형 Fold 1: 가중치 0.0410\n","  유형 Fold 2: 가중치 0.0416\n","  유형 Fold 3: 가중치 0.0821\n","  유형 Fold 4: 가중치 0.1390\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.639, 유형=0.361\n","건물 85 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0384\n","  개별 Fold 1: 가중치 0.0318\n","  개별 Fold 2: 가중치 0.0899\n","  개별 Fold 3: 가중치 0.0921\n","  개별 Fold 4: 가중치 0.1526\n","  유형 Fold 0: 가중치 0.0442\n","  유형 Fold 1: 가중치 0.0575\n","  유형 Fold 2: 가중치 0.1204\n","  유형 Fold 3: 가중치 0.1906\n","  유형 Fold 4: 가중치 0.1973\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.399, 유형=0.601\n","건물 86 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0713\n","  개별 Fold 1: 가중치 0.1007\n","  개별 Fold 2: 가중치 0.1434\n","  개별 Fold 3: 가중치 0.0933\n","  개별 Fold 4: 가중치 0.0904\n","  유형 Fold 0: 가중치 0.0588\n","  유형 Fold 1: 가중치 0.0995\n","  유형 Fold 2: 가중치 0.1645\n","  유형 Fold 3: 가중치 0.2523\n","  유형 Fold 4: 가중치 0.2762\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.370, 유형=0.630\n","건물 87 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0327\n","  개별 Fold 1: 가중치 0.0197\n","  개별 Fold 2: 가중치 0.0544\n","  개별 Fold 3: 가중치 0.0605\n","  개별 Fold 4: 가중치 0.0468\n","  유형 Fold 0: 가중치 0.0535\n","  유형 Fold 1: 가중치 0.0667\n","  유형 Fold 2: 가중치 0.1623\n","  유형 Fold 3: 가중치 0.1354\n","  유형 Fold 4: 가중치 0.1123\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.288, 유형=0.712\n","건물 88 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0322\n","  개별 Fold 1: 가중치 0.0408\n","  개별 Fold 2: 가중치 0.1013\n","  개별 Fold 3: 가중치 0.1548\n","  개별 Fold 4: 가중치 0.1242\n","  유형 Fold 0: 가중치 0.0364\n","  유형 Fold 1: 가중치 0.0441\n","  유형 Fold 2: 가중치 0.0822\n","  유형 Fold 3: 가중치 0.0865\n","  유형 Fold 4: 가중치 0.2489\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.476, 유형=0.524\n","건물 89 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0481\n","  개별 Fold 1: 가중치 0.1812\n","  개별 Fold 2: 가중치 0.1488\n","  개별 Fold 3: 가중치 0.1845\n","  개별 Fold 4: 가중치 0.3147\n","  유형 Fold 0: 가중치 0.0324\n","  유형 Fold 1: 가중치 0.0410\n","  유형 Fold 2: 가중치 0.0416\n","  유형 Fold 3: 가중치 0.0821\n","  유형 Fold 4: 가중치 0.1390\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.723, 유형=0.277\n","건물 90 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0481\n","  개별 Fold 1: 가중치 0.0540\n","  개별 Fold 2: 가중치 0.0911\n","  개별 Fold 3: 가중치 0.1407\n","  개별 Fold 4: 가중치 0.2147\n","  유형 Fold 0: 가중치 0.1091\n","  유형 Fold 1: 가중치 0.1194\n","  유형 Fold 2: 가중치 0.2052\n","  유형 Fold 3: 가중치 0.2880\n","  유형 Fold 4: 가중치 0.3288\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.343, 유형=0.657\n","건물 91 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0193\n","  개별 Fold 1: 가중치 0.0504\n","  개별 Fold 2: 가중치 0.0929\n","  개별 Fold 3: 가중치 0.1582\n","  개별 Fold 4: 가중치 0.2672\n","  유형 Fold 0: 가중치 0.0442\n","  유형 Fold 1: 가중치 0.0575\n","  유형 Fold 2: 가중치 0.1204\n","  유형 Fold 3: 가중치 0.1906\n","  유형 Fold 4: 가중치 0.1973\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.491, 유형=0.509\n","건물 92 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0314\n","  개별 Fold 1: 가중치 0.0717\n","  개별 Fold 2: 가중치 0.1324\n","  개별 Fold 3: 가중치 0.1485\n","  개별 Fold 4: 가중치 0.2425\n","  유형 Fold 0: 가중치 0.0407\n","  유형 Fold 1: 가중치 0.0594\n","  유형 Fold 2: 가중치 0.0958\n","  유형 Fold 3: 가중치 0.0848\n","  유형 Fold 4: 가중치 0.1388\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.599, 유형=0.401\n","건물 93 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0266\n","  개별 Fold 1: 가중치 0.0465\n","  개별 Fold 2: 가중치 0.0937\n","  개별 Fold 3: 가중치 0.1687\n","  개별 Fold 4: 가중치 0.1616\n","  유형 Fold 0: 가중치 0.0442\n","  유형 Fold 1: 가중치 0.0575\n","  유형 Fold 2: 가중치 0.1204\n","  유형 Fold 3: 가중치 0.1906\n","  유형 Fold 4: 가중치 0.1973\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.449, 유형=0.551\n","건물 94 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0110\n","  개별 Fold 1: 가중치 0.0165\n","  개별 Fold 2: 가중치 0.0106\n","  개별 Fold 3: 가중치 0.0442\n","  개별 Fold 4: 가중치 0.0315\n","  유형 Fold 0: 가중치 0.0407\n","  유형 Fold 1: 가중치 0.0194\n","  유형 Fold 2: 가중치 0.0526\n","  유형 Fold 3: 가중치 0.1086\n","  유형 Fold 4: 가중치 0.1163\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.252, 유형=0.748\n","건물 95 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0478\n","  개별 Fold 1: 가중치 0.0515\n","  개별 Fold 2: 가중치 0.0271\n","  개별 Fold 3: 가중치 0.1092\n","  개별 Fold 4: 가중치 0.0772\n","  유형 Fold 0: 가중치 0.0364\n","  유형 Fold 1: 가중치 0.0441\n","  유형 Fold 2: 가중치 0.0822\n","  유형 Fold 3: 가중치 0.0865\n","  유형 Fold 4: 가중치 0.2489\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.386, 유형=0.614\n","건물 96 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0333\n","  개별 Fold 1: 가중치 0.0530\n","  개별 Fold 2: 가중치 0.0895\n","  개별 Fold 3: 가중치 0.1329\n","  개별 Fold 4: 가중치 0.2003\n","  유형 Fold 0: 가중치 0.0454\n","  유형 Fold 1: 가중치 0.0629\n","  유형 Fold 2: 가중치 0.1000\n","  유형 Fold 3: 가중치 0.1297\n","  유형 Fold 4: 가중치 0.1678\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.502, 유형=0.498\n","건물 97 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0100\n","  개별 Fold 1: 가중치 0.0591\n","  개별 Fold 2: 가중치 0.0970\n","  개별 Fold 3: 가중치 0.1490\n","  개별 Fold 4: 가중치 0.1975\n","  유형 Fold 0: 가중치 0.0454\n","  유형 Fold 1: 가중치 0.0629\n","  유형 Fold 2: 가중치 0.1000\n","  유형 Fold 3: 가중치 0.1297\n","  유형 Fold 4: 가중치 0.1678\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.503, 유형=0.497\n","건물 98 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0328\n","  개별 Fold 1: 가중치 0.0392\n","  개별 Fold 2: 가중치 0.0709\n","  개별 Fold 3: 가중치 0.1459\n","  개별 Fold 4: 가중치 0.2183\n","  유형 Fold 0: 가중치 0.0324\n","  유형 Fold 1: 가중치 0.0410\n","  유형 Fold 2: 가중치 0.0416\n","  유형 Fold 3: 가중치 0.0821\n","  유형 Fold 4: 가중치 0.1390\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.601, 유형=0.399\n","건물 99 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0935\n","  개별 Fold 1: 가중치 0.1014\n","  개별 Fold 2: 가중치 0.1135\n","  개별 Fold 3: 가중치 0.2576\n","  개별 Fold 4: 가중치 0.3584\n","  유형 Fold 0: 가중치 0.0588\n","  유형 Fold 1: 가중치 0.0995\n","  유형 Fold 2: 가중치 0.1645\n","  유형 Fold 3: 가중치 0.2523\n","  유형 Fold 4: 가중치 0.2762\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.521, 유형=0.479\n","건물 100 테스트 예측 중...\n","  개별 Fold 0: 가중치 0.0090\n","  개별 Fold 1: 가중치 0.0179\n","  개별 Fold 2: 가중치 0.0241\n","  개별 Fold 3: 가중치 0.0325\n","  개별 Fold 4: 가중치 0.0609\n","  유형 Fold 0: 가중치 0.0324\n","  유형 Fold 1: 가중치 0.0410\n","  유형 Fold 2: 가중치 0.0416\n","  유형 Fold 3: 가중치 0.0821\n","  유형 Fold 4: 가중치 0.1390\n","  ✅ 완료: 10개 모델 결합, 테스트 샘플 168개\n","      가중치 분포: 개별=0.301, 유형=0.699\n","\n","=== 테스트 예측 완료 ===\n","예측 완료 건물 수: 100\n","\n","=== 제출 파일 생성 ===\n","✅ 제출 파일 저장: weighted_soft_voting_submission.csv\n","   총 예측값 수: 16800\n","   예측값 범위: 12.30 ~ 25275.77\n","   예측값 평균: 3542.99\n","   샘플 ID 형식: 1_20240825 00\n","\n","🎯 최종 요약:\n","   - 사용된 가중치: SMAPE 역수 × 지수감쇠(0.7^(4-fold))\n","   - 최대 모델 수: 10개 (개별 5폴드 + 유형 5폴드)\n","   - 예측 완료 건물: 100개\n","   - 제출 파일 형식: num_date_answer (건물번호_날짜 시간), answer (예측값)\n","   - 샘플 형식: 1_20240825 00, 1_20240825 01, ...\n","   - 제출 파일: weighted_soft_voting_submission.csv\n","✅ 완료!\n"]}]},{"cell_type":"markdown","source":["###full train"],"metadata":{"id":"IvRbz6373M3j"}},{"cell_type":"code","source":["# 하이퍼파라미터 설정 (주어진 파라미터 사용)\n","building_type_params = {\n","    \"max_depth\": 10,\n","    \"learning_rate\": 0.005,\n","    \"subsample\": 0.8,\n","    \"colsample_bytree\": 0.6,\n","    \"min_child_weight\": 4,\n","    \"gamma\": 0.05,\n","    \"lambda\": 1.2,\n","    \"alpha\": 0.4,\n","    \"tree_method\": \"hist\",\n","    \"device\": \"cuda\",\n","    \"max_bin\": 256,\n","    \"verbosity\": 0,\n","    \"random_state\": 42,\n","    \"eval_metric\": \"mae\",\n","    \"objective\": \"reg:squarederror\"\n","}\n","\n","# 개별 건물용 파라미터 (유형별과 동일하게 설정)\n","individual_building_params = building_type_params.copy()\n","\n","N_BOOST_ROUND = 8000\n","ES_ROUNDS = 600\n","\n","def train_full_models_for_final_prediction(train_data):\n","    \"\"\"전체 train 데이터로 최종 모델 학습 (평가 없음)\"\"\"\n","    print(\"=== Full Train 데이터 기반 최종 모델 학습 ===\")\n","\n","    final_individual_models = {}\n","    final_building_type_models = {}\n","\n","    # 1. 개별 건물 모델 학습\n","    print(\"\\n1. 개별 건물 모델 학습\")\n","    buildings = train_data['building_number'].unique()\n","\n","    for building_num in buildings:\n","        print(f\"건물 {building_num} 학습 중...\")\n","\n","        # 해당 건물 데이터\n","        building_data = train_data[train_data['building_number'] == building_num].copy()\n","        building_data = building_data.sort_values('date_time').reset_index(drop=True)\n","\n","        if len(building_data) < 100:  # 최소 데이터 체크\n","            print(f\"  ⚠️ 건물 {building_num}: 데이터 부족 ({len(building_data)}개)\")\n","            continue\n","\n","        try:\n","            # 통계 피처 생성\n","            train_stats = _build_time_stats(building_data)\n","            building_featured = attach_time_stats(building_data.copy(), train_stats)\n","\n","            # 피처 및 타겟 준비\n","            X = building_featured[feature_cols].copy()\n","            X = X.drop(columns=['building_number'], errors='ignore')\n","            y = building_featured['power_consumption_log']  # 이미 log 변환된 것 사용\n","\n","            # XGBoost 데이터 준비\n","            dtrain = xgb.DMatrix(X, label=y, feature_names=X.columns.tolist())\n","\n","            # 모델 학습 (early stopping 없이)\n","            model = xgb.train(\n","                params=individual_building_params,\n","                dtrain=dtrain,\n","                num_boost_round=N_BOOST_ROUND,\n","                obj=weighted_mse(alpha=3.0),  # 기존 사용하던 custom objective\n","                verbose_eval=False\n","            )\n","\n","            final_individual_models[building_num] = {\n","                'model': model,\n","                'train_stats': train_stats,\n","                'data_count': len(building_data),\n","                'building_type': building_featured['building'].iloc[0]\n","            }\n","\n","            print(f\"  ✅ 건물 {building_num}: {len(building_data)}개 샘플로 학습 완료\")\n","\n","        except Exception as e:\n","            print(f\"  ❌ 건물 {building_num} 학습 실패: {str(e)}\")\n","\n","    # 2. 건물 유형별 모델 학습\n","    print(\"\\n2. 건물 유형별 모델 학습\")\n","    building_types = train_data['building'].unique()\n","\n","    for building_type in building_types:\n","        print(f\"유형 {building_type} 학습 중...\")\n","\n","        # 해당 유형 데이터\n","        type_data = train_data[train_data['building'] == building_type].copy()\n","        type_data = type_data.sort_values('date_time').reset_index(drop=True)\n","\n","        if len(type_data) < 200:  # 유형별 최소 데이터 체크\n","            print(f\"  ⚠️ 유형 {building_type}: 데이터 부족 ({len(type_data)}개)\")\n","            continue\n","\n","        try:\n","            # 통계 피처 생성\n","            type_train_stats = _build_time_stats(type_data)\n","            type_featured = attach_time_stats(type_data.copy(), type_train_stats)\n","\n","            # 피처 및 타겟 준비\n","            X = type_featured[feature_cols].copy()\n","            X = X.drop(columns=['building_number'], errors='ignore')\n","            y = type_featured['power_consumption_log']  # 이미 log 변환된 것 사용\n","\n","            # XGBoost 데이터 준비\n","            dtrain = xgb.DMatrix(X, label=y, feature_names=X.columns.tolist())\n","\n","            # 모델 학습 (early stopping 없이)\n","            model = xgb.train(\n","                params=building_type_params,\n","                dtrain=dtrain,\n","                num_boost_round=N_BOOST_ROUND,\n","                obj=weighted_mse(alpha=3.0),  # 기존 사용하던 custom objective\n","                verbose_eval=False\n","            )\n","\n","            final_building_type_models[building_type] = {\n","                'model': model,\n","                'train_stats': type_train_stats,\n","                'data_count': len(type_data),\n","                'n_buildings': type_data['building_number'].nunique()\n","            }\n","\n","            print(f\"  ✅ 유형 {building_type}: {len(type_data)}개 샘플 ({type_data['building_number'].nunique()}개 건물)로 학습 완료\")\n","\n","        except Exception as e:\n","            print(f\"  ❌ 유형 {building_type} 학습 실패: {str(e)}\")\n","\n","    print(f\"\\n=== Full Train 학습 완료 ===\")\n","    print(f\"개별 모델: {len(final_individual_models)}개\")\n","    print(f\"유형 모델: {len(final_building_type_models)}개\")\n","\n","    return final_individual_models, final_building_type_models\n","\n","\n","def create_full_train_predictions(test_data, individual_models, type_models):\n","    \"\"\"Full train 모델로 테스트 예측 (단순 평균)\"\"\"\n","    print(\"\\n=== Full Train 모델 기반 테스트 예측 ===\")\n","\n","    final_predictions = {}\n","\n","    for building_num in test_data['building_number'].unique():\n","        print(f\"건물 {building_num} 예측 중...\")\n","\n","        # 테스트 데이터 준비\n","        building_test = test_data[test_data['building_number'] == building_num].copy()\n","        building_test = building_test.sort_values('date_time').reset_index(drop=True)\n","\n","        if building_test.empty:\n","            continue\n","\n","        building_type = building_test['building'].iloc[0]\n","        predictions = []\n","        model_names = []\n","\n","        # 1. 개별 모델 예측\n","        if building_num in individual_models:\n","            try:\n","                model_info = individual_models[building_num]\n","                model = model_info['model']\n","                train_stats = model_info['train_stats']\n","\n","                # 테스트 데이터에 통계 피처 적용\n","                test_featured = attach_time_stats(building_test.copy(), train_stats)\n","                X_test = test_featured[feature_cols].copy()\n","                X_test = X_test.drop(columns=['building_number'], errors='ignore')\n","\n","                # 예측 (log scale에서 예측 후 역변환)\n","                dtest = xgb.DMatrix(X_test, feature_names=X_test.columns.tolist())\n","                pred_log = model.predict(dtest)\n","                pred = np.expm1(pred_log)  # log 역변환\n","\n","                predictions.append(pred)\n","                model_names.append('individual')\n","                print(f\"  ✅ 개별 모델 예측 완료\")\n","\n","            except Exception as e:\n","                print(f\"  ❌ 개별 모델 예측 실패: {str(e)}\")\n","\n","        # 2. 유형별 모델 예측\n","        if building_type in type_models:\n","            try:\n","                model_info = type_models[building_type]\n","                model = model_info['model']\n","                train_stats = model_info['train_stats']\n","\n","                # 테스트 데이터에 통계 피처 적용\n","                test_featured = attach_time_stats(building_test.copy(), train_stats)\n","                X_test = test_featured[feature_cols].copy()\n","                X_test = X_test.drop(columns=['building_number'], errors='ignore')\n","\n","                # 예측 (log scale에서 예측 후 역변환)\n","                dtest = xgb.DMatrix(X_test, feature_names=X_test.columns.tolist())\n","                pred_log = model.predict(dtest)\n","                pred = np.expm1(pred_log)  # log 역변환\n","\n","                predictions.append(pred)\n","                model_names.append('type')\n","                print(f\"  ✅ 유형 모델 예측 완료\")\n","\n","            except Exception as e:\n","                print(f\"  ❌ 유형 모델 예측 실패: {str(e)}\")\n","\n","        # 3. 단순 평균으로 최종 예측\n","        if len(predictions) > 0:\n","            if len(predictions) == 1:\n","                final_pred = predictions[0]\n","                print(f\"  ✅ 단일 모델 ({model_names[0]}) 사용\")\n","            else:\n","                final_pred = np.mean(predictions, axis=0)\n","                print(f\"  ✅ {len(predictions)}개 모델 평균: {', '.join(model_names)}\")\n","\n","            final_predictions[building_num] = final_pred\n","        else:\n","            print(f\"  ❌ 건물 {building_num}: 사용 가능한 모델 없음\")\n","\n","    print(f\"\\n=== 예측 완료 ===\")\n","    print(f\"예측 완료 건물: {len(final_predictions)}개\")\n","\n","    return final_predictions\n","\n","\n","def save_test_predictions(final_test_predictions, test_data, output_path='submission.csv'):\n","    \"\"\"테스트 예측 결과를 제출 형태로 저장 (num_date_answer 형식 with hour)\"\"\"\n","    print(\"\\n=== 제출 파일 생성 ===\")\n","\n","    # 제출 데이터프레임 준비\n","    submission_rows = []\n","\n","    for building_num in sorted(test_data['building_number'].unique()):\n","        if building_num in final_test_predictions:\n","            building_test = test_data[test_data['building_number'] == building_num].copy()\n","            building_test = building_test.sort_values('date_time').reset_index(drop=True)\n","            predictions = final_test_predictions[building_num]\n","\n","            for idx, (_, row) in enumerate(building_test.iterrows()):\n","                if idx < len(predictions):\n","                    # datetime을 파싱\n","                    dt = pd.to_datetime(row['date_time'])\n","\n","                    # YYYYMMDD 형식으로 날짜 변환\n","                    date_str = dt.strftime('%Y%m%d')\n","\n","                    # 시간을 2자리 형식으로 변환 (00, 01, 02, ...)\n","                    hour_str = dt.strftime('%H')\n","\n","                    # num_date 형식 생성 (building_num_YYYYMMDD HH)\n","                    num_date_id = f\"{building_num}_{date_str} {hour_str}\"\n","\n","                    submission_rows.append({\n","                        'num_date_time': num_date_id,\n","                        'answer': predictions[idx]\n","                    })\n","        else:\n","            print(f\"경고: 건물 {building_num}의 예측값이 없습니다\")\n","\n","    # DataFrame 생성\n","    submission_df = pd.DataFrame(submission_rows)\n","\n","    # 음수 예측값 처리\n","    negative_count = np.sum(submission_df['answer'] < 0)\n","    if negative_count > 0:\n","        print(f\"음수 예측값 {negative_count}개를 0으로 조정\")\n","        submission_df['answer'] = np.maximum(submission_df['answer'], 0)\n","\n","    # CSV 저장\n","    submission_df.to_csv(output_path, index=False)\n","\n","    print(f\"✅ 제출 파일 저장: {output_path}\")\n","    print(f\"   총 예측값 수: {len(submission_df)}\")\n","    print(f\"   예측값 범위: {submission_df['answer'].min():.2f} ~ {submission_df['answer'].max():.2f}\")\n","    print(f\"   예측값 평균: {submission_df['answer'].mean():.2f}\")\n","    print(f\"   샘플 ID 형식: {submission_df['num_date_answer'].iloc[0] if len(submission_df) > 0 else 'N/A'}\")\n","\n","    return submission_df\n","\n","# 🚀 Full Train 기반 최종 예측 실행\n","print(\"\\n\" + \"=\"*70)\n","print(\"High-Performance Full Train 기반 소프트 보팅 예측\")\n","print(\"=\"*70)\n","\n","print(f\"\\n📋 사용된 하이퍼파라미터:\")\n","print(f\"   - max_depth: {building_type_params['max_depth']}\")\n","print(f\"   - learning_rate: {building_type_params['learning_rate']}\")\n","print(f\"   - subsample: {building_type_params['subsample']}\")\n","print(f\"   - colsample_bytree: {building_type_params['colsample_bytree']}\")\n","print(f\"   - min_child_weight: {building_type_params['min_child_weight']}\")\n","print(f\"   - gamma: {building_type_params['gamma']}\")\n","print(f\"   - lambda: {building_type_params['lambda']}\")\n","print(f\"   - alpha: {building_type_params['alpha']}\")\n","print(f\"   - n_boost_round: {N_BOOST_ROUND}\")\n","print(f\"   - 사용 GPU: {building_type_params['device']}\")\n","\n","# 1. Full train 모델 학습\n","final_individual_models, final_type_models = train_full_models_for_final_prediction(train)\n","\n","# 2. 테스트 예측\n","full_train_predictions = create_full_train_predictions(test, final_individual_models, final_type_models)\n","\n","# 3. 제출 파일 저장\n","submission_df = save_test_predictions(full_train_predictions, test, 'high_performance_full_train_submission.csv')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"49DIlC9X25p5","outputId":"fef6201e-d95f-45d4-d6cb-55f4ec45bd29"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======================================================================\n","High-Performance Full Train 기반 소프트 보팅 예측\n","======================================================================\n","\n","📋 사용된 하이퍼파라미터:\n","   - max_depth: 10\n","   - learning_rate: 0.005\n","   - subsample: 0.8\n","   - colsample_bytree: 0.6\n","   - min_child_weight: 4\n","   - gamma: 0.05\n","   - lambda: 1.2\n","   - alpha: 0.4\n","   - n_boost_round: 8000\n","   - 사용 GPU: cuda\n","=== Full Train 데이터 기반 최종 모델 학습 ===\n","\n","1. 개별 건물 모델 학습\n","건물 1 학습 중...\n","  ✅ 건물 1: 2040개 샘플로 학습 완료\n","건물 2 학습 중...\n","  ✅ 건물 2: 2040개 샘플로 학습 완료\n","건물 3 학습 중...\n","  ✅ 건물 3: 2040개 샘플로 학습 완료\n","건물 4 학습 중...\n","  ✅ 건물 4: 2040개 샘플로 학습 완료\n","건물 5 학습 중...\n","  ✅ 건물 5: 2040개 샘플로 학습 완료\n","건물 6 학습 중...\n","  ✅ 건물 6: 2040개 샘플로 학습 완료\n","건물 7 학습 중...\n","  ✅ 건물 7: 2040개 샘플로 학습 완료\n","건물 8 학습 중...\n","  ✅ 건물 8: 2040개 샘플로 학습 완료\n","건물 9 학습 중...\n","  ✅ 건물 9: 2040개 샘플로 학습 완료\n","건물 10 학습 중...\n","  ✅ 건물 10: 2040개 샘플로 학습 완료\n","건물 11 학습 중...\n","  ✅ 건물 11: 2040개 샘플로 학습 완료\n","건물 12 학습 중...\n","  ✅ 건물 12: 2040개 샘플로 학습 완료\n","건물 13 학습 중...\n","  ✅ 건물 13: 2040개 샘플로 학습 완료\n","건물 14 학습 중...\n","  ✅ 건물 14: 2040개 샘플로 학습 완료\n","건물 15 학습 중...\n","  ✅ 건물 15: 2040개 샘플로 학습 완료\n","건물 16 학습 중...\n","  ✅ 건물 16: 2040개 샘플로 학습 완료\n","건물 17 학습 중...\n","  ✅ 건물 17: 2040개 샘플로 학습 완료\n","건물 18 학습 중...\n","  ✅ 건물 18: 2040개 샘플로 학습 완료\n","건물 19 학습 중...\n","  ✅ 건물 19: 2040개 샘플로 학습 완료\n","건물 20 학습 중...\n","  ✅ 건물 20: 2040개 샘플로 학습 완료\n","건물 21 학습 중...\n"]}]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":7900655,"sourceId":12516640,"sourceType":"datasetVersion"}],"dockerImageVersionId":31090,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"colab":{"provenance":[],"gpuType":"T4","collapsed_sections":["nSL1r5hxuEfP","IvRbz6373M3j"]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}